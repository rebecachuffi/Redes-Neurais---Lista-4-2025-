<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rebeca Chuffi Saccochi">

<title>Lista 4: Ajustando a rede com PyTorch</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="Lista_4_RebecaChuffi_files/libs/clipboard/clipboard.min.js"></script>
<script src="Lista_4_RebecaChuffi_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="Lista_4_RebecaChuffi_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="Lista_4_RebecaChuffi_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="Lista_4_RebecaChuffi_files/libs/quarto-html/popper.min.js"></script>
<script src="Lista_4_RebecaChuffi_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Lista_4_RebecaChuffi_files/libs/quarto-html/anchor.min.js"></script>
<link href="Lista_4_RebecaChuffi_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Lista_4_RebecaChuffi_files/libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Lista_4_RebecaChuffi_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Lista_4_RebecaChuffi_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Lista_4_RebecaChuffi_files/libs/bootstrap/bootstrap-93216f84ad7ccfb553c7e13a3406b94b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="Lista_4_RebecaChuffi_files/libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="Lista_4_RebecaChuffi_files/libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="Lista_4_RebecaChuffi_files/libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="Cod4-preview.html"><i class="bi bi-journal-code"></i>Conteúdos</a></li></ul></div></div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lista 4: Ajustando a rede com PyTorch</h1>
<p class="subtitle lead">Redes Neurais 2/2025</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Rebeca Chuffi Saccochi </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div class="quarto-embed-nb-cell">
<section id="conteúdos" class="level1">
<h1>Conteúdos</h1>
</section>
<section id="biblioteca" class="level1">
<h1>Biblioteca</h1>
<div id="cell-2" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="043163ca-d5ec-4eaf-81b7-1145c2881d89" data-execution_count="54">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install optuna</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader, TensorDataset</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'CUBLAS_WORKSPACE_CONFIG'</span>] <span class="op">=</span> <span class="st">':4096:8'</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> optuna</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.interpolate <span class="im">import</span> griddata</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)
Requirement already satisfied: alembic&gt;=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)
Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)
Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)
Requirement already satisfied: sqlalchemy&gt;=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)
Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)
Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)
Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic&gt;=1.5.0-&gt;optuna) (1.3.10)
Requirement already satisfied: typing-extensions&gt;=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic&gt;=1.5.0-&gt;optuna) (4.15.0)
Requirement already satisfied: greenlet&gt;=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy&gt;=1.4.2-&gt;optuna) (3.2.4)
Requirement already satisfied: MarkupSafe&gt;=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako-&gt;alembic&gt;=1.5.0-&gt;optuna) (3.0.3)</code></pre>
</div>
</div>
</section>
<section id="item-a." class="level1">
<h1>ITEM A.</h1>
<p>Ajuste a rede neural especificada na Lista 2 usando o PyTorch. Compare com sua implementação (Lista 2, item e) quanto ao tempo computacional e ao custo obtido no conjunto de teste. Use o mesmo algoritmo de otimização (full gradient descent) e ponto de partida.</p>
<section id="reprodutibilidade" class="level2">
<h2 class="anchored" data-anchor-id="reprodutibilidade">Reprodutibilidade</h2>
<div id="cell-6" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed<span class="op">=</span><span class="dv">42</span>, deterministic<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1) python built-in random</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2) numpy</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3) torch (CPU)</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4) torch (todas as GPUs, se houver)</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(seed)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5) controle de comportamento determinístico/dispositivo</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> deterministic:</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># para PyTorch &gt;= 1.8: força algoritmos determinísticos quando possível</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>            torch.use_deterministic_algorithms(<span class="va">False</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">AttributeError</span>:</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>            torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">False</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6) Variáveis de ambiente úteis</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    os.environ[<span class="st">'PYTHONHASHSEED'</span>] <span class="op">=</span> <span class="bu">str</span>(seed)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>, deterministic<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Algumas explicações sobre o código acima:</p>
<ol type="1">
<li><code>torch.cuda.manual_seed_all</code> (seed): garante que todas GPUs usem a mesma seed (útil em múltiplas GPUs).</li>
<li><code>torch.use_deterministic_algorithms(True)</code>: instrui PyTorch a lançar erro quando operações não-determinísticas forem chamadas, e escolher variantes determinísticas quando disponíveis. Disponível em versões recentes.</li>
</ol>
</section>
<section id="carregamento-dos-dados" class="level2">
<h2 class="anchored" data-anchor-id="carregamento-dos-dados">Carregamento dos dados</h2>
<div id="cell-9" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ba58b7a9-3c48-423a-86d7-ce3dcce5cc4b" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Carregamento dos dados</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Instalar o git-lfs</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>apt<span class="op">-</span>get install git<span class="op">-</span>lfs</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Inicializar o LFS</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>git lfs install</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Clonar o repositório (substitua pelo link do repo onde está seu CSV)</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>rebecachuffi<span class="op">/</span>Redes<span class="op">-</span>Neurais<span class="op">-</span><span class="dv">1</span><span class="op">---</span><span class="fl">2025.</span><span class="er">git</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrar na pasta clonada</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>cd Redes<span class="op">-</span>Neurais<span class="op">-</span><span class="dv">1</span><span class="op">---</span><span class="dv">2025</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Baixar os arquivos grandes via LFS</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>git lfs pull</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
git-lfs is already the newest version (3.0.2-1ubuntu0.3).
0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.
Updated git hooks.
Git LFS initialized.
Cloning into 'Redes-Neurais-1---2025'...
remote: Enumerating objects: 25, done.
remote: Counting objects: 100% (25/25), done.
remote: Compressing objects: 100% (24/24), done.
remote: Total 25 (delta 5), reused 0 (delta 0), pack-reused 0 (from 0)
Receiving objects: 100% (25/25), 8.80 MiB | 11.59 MiB/s, done.
Resolving deltas: 100% (5/5), done.
/content/Redes-Neurais-1---2025/Redes-Neurais-1---2025</code></pre>
</div>
</div>
<div id="cell-10" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="ba613266-3b46-4132-e7e7-5a3574584c8c" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>dados <span class="op">=</span> pd.read_csv(<span class="st">"dados.csv"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>dados.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div id="df-dd2eb957-545a-49a8-9fd9-bb5bc339bc7f" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x1.obs</th>
<th data-quarto-table-cell-role="th">x2.obs</th>
<th data-quarto-table-cell-role="th">mu</th>
<th data-quarto-table-cell-role="th">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1.363870</td>
<td>-0.833639</td>
<td>34.748472</td>
<td>35.120982</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>1.960455</td>
<td>0.463564</td>
<td>4.120608</td>
<td>4.331141</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>-1.848304</td>
<td>0.110323</td>
<td>0.382789</td>
<td>0.596088</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>-2.036404</td>
<td>-2.115443</td>
<td>27.214465</td>
<td>27.625098</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>1.812387</td>
<td>-1.917255</td>
<td>44.170668</td>
<td>43.690597</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-dd2eb957-545a-49a8-9fd9-bb5bc339bc7f')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-dd2eb957-545a-49a8-9fd9-bb5bc339bc7f button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-dd2eb957-545a-49a8-9fd9-bb5bc339bc7f');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-b43672de-0877-432b-8a45-5bfc31ae2a9a">
      <button class="colab-df-quickchart" onclick="quickchart('df-b43672de-0877-432b-8a45-5bfc31ae2a9a')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-b43672de-0877-432b-8a45-5bfc31ae2a9a button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<p>##Dividir Treino e Teste</p>
<div id="cell-12" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>x_cols <span class="op">=</span> [<span class="st">'x1.obs'</span>, <span class="st">'x2.obs'</span>]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>y_col  <span class="op">=</span> <span class="st">'y'</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dados[x_cols].values.astype(np.float64)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> dados[[y_col]].values.astype(np.float64)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-13" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>train_set <span class="op">=</span> dados.iloc[:<span class="dv">80000</span>]</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>validation_set <span class="op">=</span> dados.iloc[<span class="dv">80000</span>:<span class="dv">90000</span>]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>test_set <span class="op">=</span> dados.iloc[<span class="dv">90000</span>:<span class="dv">100000</span>]</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>x_treino <span class="op">=</span> train_set[[<span class="st">'x1.obs'</span>, <span class="st">'x2.obs'</span>]].values</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>x_val <span class="op">=</span> validation_set[[<span class="st">'x1.obs'</span>, <span class="st">'x2.obs'</span>]].values</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>x_teste <span class="op">=</span> test_set[[<span class="st">'x1.obs'</span>, <span class="st">'x2.obs'</span>]].values</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>y_treino <span class="op">=</span> train_set[<span class="st">'y'</span>].values</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>y_val <span class="op">=</span> validation_set[<span class="st">'y'</span>].values</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>y_teste <span class="op">=</span> test_set[<span class="st">'y'</span>].values</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="converter-para-tensor-e-dataloader" class="level2">
<h2 class="anchored" data-anchor-id="converter-para-tensor-e-dataloader">Converter para tensor e DataLoader</h2>
<div id="cell-15" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> torch.tensor(x_treino, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>y_train_tensor <span class="op">=</span> torch.tensor(y_treino, dtype<span class="op">=</span>torch.float64).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>X_val_tensor <span class="op">=</span> torch.tensor(x_val, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>y_val_tensor <span class="op">=</span> torch.tensor(y_val, dtype<span class="op">=</span>torch.float64).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-16" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_dataset, batch_size<span class="op">=</span><span class="bu">len</span>(train_dataset), shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> torch.utils.data.DataLoader(val_dataset, batch_size<span class="op">=</span><span class="bu">len</span>(val_dataset), shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-17" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Tamanho treino:", len(X_train))</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Tamanho validação:", len(X_val))</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Tamanho teste:", len(X_test))</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="criando-a-estrutura-da-rede" class="level2">
<h2 class="anchored" data-anchor-id="criando-a-estrutura-da-rede">Criando a estrutura da Rede</h2>
<p>Lembrando que temos uma estrutura de rede com entrada de tamanho dois, duas camadas escondidas (das quais a primeira função de ativação é sigmóide e a segunda é a identidade). Temos dois neurônios na primeira camada e um na segunda (que já é a camada de saída).</p>
<div id="cell-20" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9731e79e-3a40-49da-e041-2b60104c0d52" data-execution_count="46">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#device</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Device:"</span>, device)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Device: cuda</code></pre>
</div>
</div>
<div id="cell-21" class="cell" data-execution_count="47">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Definir a arquitetura: feed-forward</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TinyNet(nn.Module):</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">#2 entradas -&gt; 2 neurônios ocultos</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">2</span>, <span class="dv">2</span>, bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ativação da camada oculta: sigmoide</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act <span class="op">=</span> nn.Sigmoid()</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">#2 ocultos -&gt; 1 saída (linear)</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">2</span>, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x: tensor shape (batch_size, 2)</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        z1 <span class="op">=</span> <span class="va">self</span>.fc1(x)       <span class="co"># operação linear</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        h  <span class="op">=</span> <span class="va">self</span>.act(z1)      <span class="co"># sigmoide</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        y_hat <span class="op">=</span> <span class="va">self</span>.fc2(h)    <span class="co"># saída linear</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> y_hat</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-22" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e04f1dce-2649-4cb9-beff-abe057fd1c94" data-execution_count="48">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Criando modelo + inicialização específica</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TinyNet().double().to(device)   <span class="co"># .double() converte pesos/params para float64</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> inicializar_fixo(model, w1, b1, w2, b2, device):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    dtype <span class="op">=</span> torch.float64</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    dev <span class="op">=</span> device <span class="cf">if</span> device <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="bu">next</span>(model.parameters()).device</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    model.fc1.weight.data <span class="op">=</span> torch.tensor(w1, dtype<span class="op">=</span>torch.float64, device<span class="op">=</span>dev)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    model.fc1.bias.data <span class="op">=</span> torch.tensor(b1, dtype<span class="op">=</span>torch.float64, device<span class="op">=</span>dev)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    model.fc2.weight.data <span class="op">=</span> torch.tensor(w2, dtype<span class="op">=</span>torch.float64, device<span class="op">=</span>dev)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    model.fc2.bias.data <span class="op">=</span> torch.tensor(b2, dtype<span class="op">=</span>torch.float64, device<span class="op">=</span>dev)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Parâmetros iniciais:"</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(name, param.data.view(<span class="op">-</span><span class="dv">1</span>)[:<span class="dv">6</span>].cpu().numpy())</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>w1 <span class="op">=</span> [[<span class="dv">0</span>,<span class="dv">0</span>],</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>      [<span class="dv">0</span>,<span class="dv">0</span>]]        <span class="co"># 2×2</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">0</span>]         <span class="co"># 2</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>w2 <span class="op">=</span> [[<span class="dv">0</span>,<span class="dv">0</span>]]       <span class="co"># 1×2</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>inicializar_fixo(model, w1, b1, w2, b2, device)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Parâmetros iniciais:"</span>)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(name, param.data.view(<span class="op">-</span><span class="dv">1</span>)[:<span class="dv">6</span>].cpu().numpy())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parâmetros iniciais:
fc1.weight [0. 0. 0. 0.]
fc1.bias [0. 0.]
fc2.weight [0. 0.]
fc2.bias [0.]
Parâmetros iniciais:
fc1.weight [0. 0. 0. 0.]
fc1.bias [0. 0.]
fc2.weight [0. 0.]
fc2.bias [0.]</code></pre>
</div>
</div>
<div id="cell-23" class="cell" data-execution_count="49">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Definir função de perda</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.MSELoss() <span class="co">#MSE igual na lista 2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-24" class="cell" data-execution_count="50">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Definir otimizador (sem momentum, gradiente normal, igual lista 2)</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Algumas observações sobre o código acima:</p>
<p><code>class TinyNet(nn.Module)</code>: define a arquitetura e o forward (feed-forward).</p>
<p><code>model.double():</code> coloca pesos e operações em float64 (precisão dupla) para corresponder ao NumPy.</p>
<p><code>criterion</code> = nn.MSELoss(): função de perda de erro quadrático médio.</p>
<p><code>optimizer = optim.SGD(model.parameters(), lr=η, momentum=0)</code>: gradiente descentente normal</p>
<div id="cell-26" class="cell" data-execution_count="51">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Função para extrair parâmetros como Vetor na ordem correta:</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extrair_parametros_na_ordem(model):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Ordem: [w1, w2, w3, w4, w5, w6, b1, b2, b3]</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        params <span class="op">=</span> []</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># fc1.weight (2x2) - [w1, w2, w3, w4]</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        fc1_w <span class="op">=</span> model.fc1.weight.data.cpu().numpy()</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        params.extend(fc1_w[<span class="dv">0</span>])  <span class="co"># w1, w2</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        params.extend(fc1_w[<span class="dv">1</span>])  <span class="co"># w3, w4</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># fc2.weight (1x2) - [w5, w6]</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        fc2_w <span class="op">=</span> model.fc2.weight.data.cpu().numpy()</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        params.extend(fc2_w[<span class="dv">0</span>])  <span class="co"># w5, w6</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># fc1.bias (2,) - [b1, b2]</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        fc1_b <span class="op">=</span> model.fc1.bias.data.cpu().numpy()</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        params.extend(fc1_b)  <span class="co"># b1, b2</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># fc2.bias (1,) - [b3]</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        fc2_b <span class="op">=</span> model.fc2.bias.data.cpu().numpy()</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        params.extend(fc2_b)  <span class="co"># b3</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.array(params)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-27" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="69a61644-9feb-4297-e8ea-a2bf144a87c4" data-execution_count="53">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># TREINO DO MODELO</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>set_seed(<span class="dv">42</span>, deterministic<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TinyNet().double().to(device)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># inicializar com zeros</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>w1 <span class="op">=</span> [[<span class="dv">0</span>,<span class="dv">0</span>],</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>      [<span class="dv">0</span>,<span class="dv">0</span>]]        <span class="co"># 2×2</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">0</span>]         <span class="co"># 2</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>w2 <span class="op">=</span> [[<span class="dv">0</span>,<span class="dv">0</span>]]       <span class="co"># 1×2</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>inicializar_fixo(model, w1, b1, w2, b2, device)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIALIZANDO COM OS PARAMETROS DEFINIDOS ACIMA"</span>)</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar loss inicial</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">VERIFICAÇÃO DO LOSS INICIAL"</span>)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular loss inicial</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pegar um batch para teste</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>        initial_loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Loss inicial: </span><span class="sc">{</span>initial_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Verificar previsões (devem ser zero)</span></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeira previsão: </span><span class="sc">{</span>y_pred[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeiro target: </span><span class="sc">{</span>y_batch[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Treinamento</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIANDO TREINO"</span>)</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>num_iters <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>best_val_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>best_val_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a>best_val_state_cpu <span class="op">=</span> <span class="va">None</span></span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR TREINO (apenas para informação)</span></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a>best_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a>best_train_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a>best_train_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a>    train_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a>    n_samples_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- TREINO ---</span></span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch <span class="op">+=</span> loss.item() <span class="op">*</span> batch_size</span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>        n_samples_train <span class="op">+=</span> batch_size</span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a>    train_loss_avg <span class="op">=</span> train_loss_epoch <span class="op">/</span> n_samples_train</span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- VALIDAÇÃO ---</span></span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>    val_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>    n_samples_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> Xv, yv <span class="kw">in</span> val_loader:</span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a>            Xv <span class="op">=</span> Xv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a>            yv <span class="op">=</span> yv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a>            batch_size_val <span class="op">=</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a>            val_pred <span class="op">=</span> model(Xv)</span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a>            vloss <span class="op">=</span> criterion(val_pred, yv)</span>
<span id="cb20-98"><a href="#cb20-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-99"><a href="#cb20-99" aria-hidden="true" tabindex="-1"></a>            val_loss_epoch <span class="op">+=</span> vloss.item() <span class="op">*</span> batch_size_val</span>
<span id="cb20-100"><a href="#cb20-100" aria-hidden="true" tabindex="-1"></a>            n_samples_val <span class="op">+=</span> batch_size_val</span>
<span id="cb20-101"><a href="#cb20-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-102"><a href="#cb20-102" aria-hidden="true" tabindex="-1"></a>    val_loss_avg <span class="op">=</span> val_loss_epoch <span class="op">/</span> n_samples_val</span>
<span id="cb20-103"><a href="#cb20-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-104"><a href="#cb20-104" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb20-105"><a href="#cb20-105" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_loss_avg <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb20-106"><a href="#cb20-106" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb20-107"><a href="#cb20-107" aria-hidden="true" tabindex="-1"></a>        best_val_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb20-108"><a href="#cb20-108" aria-hidden="true" tabindex="-1"></a>        best_val_iter <span class="op">=</span> it</span>
<span id="cb20-109"><a href="#cb20-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Salvar cópia dos parâmetros para validação</span></span>
<span id="cb20-110"><a href="#cb20-110" aria-hidden="true" tabindex="-1"></a>        best_val_state_cpu <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb20-111"><a href="#cb20-111" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mover para CPU</span></span>
<span id="cb20-112"><a href="#cb20-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key <span class="kw">in</span> best_val_state_cpu:</span>
<span id="cb20-113"><a href="#cb20-113" aria-hidden="true" tabindex="-1"></a>            best_val_state_cpu[key] <span class="op">=</span> best_val_state_cpu[key].cpu()</span>
<span id="cb20-114"><a href="#cb20-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-115"><a href="#cb20-115" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR TREINO (apenas para informação)</span></span>
<span id="cb20-116"><a href="#cb20-116" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_loss_avg <span class="op">&lt;</span> best_train_loss:</span>
<span id="cb20-117"><a href="#cb20-117" aria-hidden="true" tabindex="-1"></a>        best_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb20-118"><a href="#cb20-118" aria-hidden="true" tabindex="-1"></a>        best_train_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb20-119"><a href="#cb20-119" aria-hidden="true" tabindex="-1"></a>        best_train_iter <span class="op">=</span> it</span>
<span id="cb20-120"><a href="#cb20-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-121"><a href="#cb20-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print das iterações importantes</span></span>
<span id="cb20-122"><a href="#cb20-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> it <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> it <span class="kw">in</span> [<span class="dv">16</span>, <span class="dv">17</span>] <span class="kw">or</span> it <span class="op">==</span> num_iters<span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb20-123"><a href="#cb20-123" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Iteração </span><span class="sc">{</span>it<span class="sc">:3d}</span><span class="ss"> | Treino = </span><span class="sc">{</span>train_loss_avg<span class="sc">:.6f}</span><span class="ss"> | Val = </span><span class="sc">{</span>val_loss_avg<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb20-124"><a href="#cb20-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-125"><a href="#cb20-125" aria-hidden="true" tabindex="-1"></a><span class="co"># --- RESULTADO FINAL ---</span></span>
<span id="cb20-126"><a href="#cb20-126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb20-127"><a href="#cb20-127" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESULTADO FINAL"</span>)</span>
<span id="cb20-128"><a href="#cb20-128" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb20-129"><a href="#cb20-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-130"><a href="#cb20-130" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)"</span>)</span>
<span id="cb20-131"><a href="#cb20-131" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de validação: </span><span class="sc">{</span>best_val_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-132"><a href="#cb20-132" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino nessa iteração:  </span><span class="sc">{</span>best_val_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb20-133"><a href="#cb20-133" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação: </span><span class="sc">{</span>best_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb20-134"><a href="#cb20-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-135"><a href="#cb20-135" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR TREINO (APENAS INFORMAÇÃO)"</span>)</span>
<span id="cb20-136"><a href="#cb20-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de treino: </span><span class="sc">{</span>best_train_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-137"><a href="#cb20-137" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino: </span><span class="sc">{</span>best_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb20-138"><a href="#cb20-138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação nessa iteração: </span><span class="sc">{</span>best_train_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb20-139"><a href="#cb20-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-140"><a href="#cb20-140" aria-hidden="true" tabindex="-1"></a><span class="co"># Carregar os parâmetros da MELHOR VALIDAÇÃO no modelo</span></span>
<span id="cb20-141"><a href="#cb20-141" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_val_state_cpu <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb20-142"><a href="#cb20-142" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_val_state_cpu)</span>
<span id="cb20-143"><a href="#cb20-143" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros da MELHOR VALIDAÇÃO carregados no modelo"</span>)</span>
<span id="cb20-144"><a href="#cb20-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-145"><a href="#cb20-145" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar parâmetros finais (da melhor validação) na ORDEM CORRETA</span></span>
<span id="cb20-146"><a href="#cb20-146" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:"</span>)</span>
<span id="cb20-147"><a href="#cb20-147" aria-hidden="true" tabindex="-1"></a>melhores_parametros <span class="op">=</span> extrair_parametros_na_ordem(model)</span>
<span id="cb20-148"><a href="#cb20-148" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"["</span> <span class="op">+</span> <span class="st">" "</span>.join(<span class="ss">f"</span><span class="sc">{</span>p<span class="sc">:.8f}</span><span class="ss">"</span> <span class="cf">for</span> p <span class="kw">in</span> melhores_parametros) <span class="op">+</span> <span class="st">"]"</span>)</span>
<span id="cb20-149"><a href="#cb20-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-150"><a href="#cb20-150" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar formato detalhado</span></span>
<span id="cb20-151"><a href="#cb20-151" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detalhado:"</span>)</span>
<span id="cb20-152"><a href="#cb20-152" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w1, w2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">0</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">1</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb20-153"><a href="#cb20-153" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w3, w4: </span><span class="sc">{</span>melhores_parametros[<span class="dv">2</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">3</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb20-154"><a href="#cb20-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w5, w6: </span><span class="sc">{</span>melhores_parametros[<span class="dv">4</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">5</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb20-155"><a href="#cb20-155" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b1, b2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">6</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">7</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb20-156"><a href="#cb20-156" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b3:     </span><span class="sc">{</span>melhores_parametros[<span class="dv">8</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parâmetros iniciais:
fc1.weight [0. 0. 0. 0.]
fc1.bias [0. 0.]
fc2.weight [0. 0.]
fc2.bias [0.]

INICIALIZANDO COM OS PARAMETROS DEFINIDOS ACIMA

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 682.638968
Primeira previsão: 0.000000
Primeiro target: 22.760891

INICIANDO TREINO
Iteração   0 | Treino = 106.026459 | Val = 105.752121
Iteração  10 | Treino = 103.625894 | Val = 104.391762
Iteração  16 | Treino = 103.661522 | Val = 107.437523
Iteração  17 | Treino = 103.539356 | Val = 105.105963
Iteração  20 | Treino = 103.604392 | Val = 104.691986
Iteração  30 | Treino = 103.591400 | Val = 106.258370
Iteração  40 | Treino = 103.669009 | Val = 105.785965
Iteração  50 | Treino = 103.626332 | Val = 108.668482
Iteração  60 | Treino = 103.679275 | Val = 105.033536
Iteração  70 | Treino = 103.607564 | Val = 107.012367
Iteração  80 | Treino = 103.650919 | Val = 105.006675
Iteração  90 | Treino = 103.619814 | Val = 105.279305
Iteração  99 | Treino = 103.626206 | Val = 105.065683

============================================================
RESULTADO FINAL
============================================================

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 18
Loss de treino nessa iteração:  103.673622
Loss de validação: 104.203704

MELHOR TREINO (APENAS INFORMAÇÃO)
Melhor iteração de treino: 17
Loss de treino: 103.539356
Loss de validação nessa iteração: 105.105963

Parâmetros da MELHOR VALIDAÇÃO carregados no modelo

Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:
[1.70627724 -7.71539141 1.70627724 -7.71539141 10.25186745 10.25186745 -3.93217536 -3.93217536 13.55865465]

Detalhado:
  w1, w2: 1.70627724, -7.71539141
  w3, w4: 1.70627724, -7.71539141
  w5, w6: 10.25186745, 10.25186745
  b1, b2: -3.93217536, -3.93217536
  b3:     13.55865465</code></pre>
</div>
</div>
<p>Note que conseguimos chegar ao mesmo resultado da <strong>Lista 2</strong>, porém usando PyTorch. Agora vamos fazer uma comparação temporal entre a execução com CPU e GPU do Google Colab:</p>
<div id="cell-29" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ccb492f5-6cf3-4aeb-99a8-f9c3eb424594" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> treinar_modelo_com_tempo(device_name<span class="op">=</span><span class="st">'cuda'</span>):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Treina o modelo e retorna tempo de execução</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Configurar device</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(device_name <span class="cf">if</span> torch.cuda.is_available() <span class="kw">and</span> device_name <span class="op">==</span> <span class="st">'cuda'</span> <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"TREINANDO NO DISPOSITIVO: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iniciar contagem de tempo</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> TinyNet().double().to(device)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># inicializar com zeros</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    w1 <span class="op">=</span> [[<span class="dv">0</span>,<span class="dv">0</span>], [<span class="dv">0</span>,<span class="dv">0</span>]]</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">0</span>]</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    w2 <span class="op">=</span> [[<span class="dv">0</span>,<span class="dv">0</span>]]</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    inicializar_fixo(model, w1, b1, w2, b2, device)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"INICIALIZANDO COM OS PARAMETROS DEFINIDOS ACIMA"</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>    num_iters <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Variáveis para melhores parâmetros</span></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>    best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>    best_val_state <span class="op">=</span> <span class="va">None</span></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LOOP DE TREINAMENTO</span></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>        n_samples_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># TREINO</span></span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>            X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>            train_loss_epoch <span class="op">+=</span> loss.item() <span class="op">*</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>            n_samples_train <span class="op">+=</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>        train_loss_avg <span class="op">=</span> train_loss_epoch <span class="op">/</span> n_samples_train</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># VALIDAÇÃO</span></span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>        val_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>        n_samples_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> Xv, yv <span class="kw">in</span> val_loader:</span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a>                Xv <span class="op">=</span> Xv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a>                yv <span class="op">=</span> yv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>                val_pred <span class="op">=</span> model(Xv)</span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a>                vloss <span class="op">=</span> criterion(val_pred, yv)</span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>                val_loss_epoch <span class="op">+=</span> vloss.item() <span class="op">*</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>                n_samples_val <span class="op">+=</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>        val_loss_avg <span class="op">=</span> val_loss_epoch <span class="op">/</span> n_samples_val</span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Atualizar melhor validação</span></span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_loss_avg <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>            best_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>            best_val_state <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tempo final</span></span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a>    training_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">TEMPO DE EXECUÇÃO NO </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>training_time<span class="sc">:.4f}</span><span class="ss"> segundos"</span>)</span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Melhor loss de validação: </span><span class="sc">{</span>best_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> training_time, best_val_loss, best_val_state</span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Treinar na GPU (se disponível)</span></span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a>    gpu_time, gpu_loss, gpu_state <span class="op">=</span> treinar_modelo_com_tempo(<span class="st">'cuda'</span>)</span>
<span id="cb22-90"><a href="#cb22-90" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb22-91"><a href="#cb22-91" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"GPU não disponível"</span>)</span>
<span id="cb22-92"><a href="#cb22-92" aria-hidden="true" tabindex="-1"></a>    gpu_time, gpu_loss, gpu_state <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb22-93"><a href="#cb22-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-94"><a href="#cb22-94" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Treinar na CPU</span></span>
<span id="cb22-95"><a href="#cb22-95" aria-hidden="true" tabindex="-1"></a>cpu_time, cpu_loss, cpu_state <span class="op">=</span> treinar_modelo_com_tempo(<span class="st">'cpu'</span>)</span>
<span id="cb22-96"><a href="#cb22-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-97"><a href="#cb22-97" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPARAÇÃO FINAL</span></span>
<span id="cb22-98"><a href="#cb22-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-99"><a href="#cb22-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAÇÃO FINAL - CPU vs GPU"</span>)</span>
<span id="cb22-100"><a href="#cb22-100" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-101"><a href="#cb22-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-102"><a href="#cb22-102" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb22-103"><a href="#cb22-103" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Tempo GPU: </span><span class="sc">{</span>gpu_time<span class="sc">:.4f}</span><span class="ss"> segundos"</span>)</span>
<span id="cb22-104"><a href="#cb22-104" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Tempo CPU: </span><span class="sc">{</span>cpu_time<span class="sc">:.4f}</span><span class="ss"> segundos"</span>)</span>
<span id="cb22-105"><a href="#cb22-105" aria-hidden="true" tabindex="-1"></a>    speedup <span class="op">=</span> cpu_time <span class="op">/</span> gpu_time <span class="cf">if</span> gpu_time <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb22-106"><a href="#cb22-106" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Speedup (GPU vs CPU): </span><span class="sc">{</span>speedup<span class="sc">:.2f}</span><span class="ss">x"</span>)</span>
<span id="cb22-107"><a href="#cb22-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-108"><a href="#cb22-108" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Loss GPU: </span><span class="sc">{</span>gpu_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb22-109"><a href="#cb22-109" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Loss CPU: </span><span class="sc">{</span>cpu_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb22-110"><a href="#cb22-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-111"><a href="#cb22-111" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb22-112"><a href="#cb22-112" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Tempo CPU: </span><span class="sc">{</span>cpu_time<span class="sc">:.4f}</span><span class="ss"> segundos"</span>)</span>
<span id="cb22-113"><a href="#cb22-113" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"GPU não disponível para comparação"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
============================================================
TREINANDO NO DISPOSITIVO: cuda
============================================================
Parâmetros iniciais:
fc1.weight [0. 0. 0. 0.]
fc1.bias [0. 0.]
fc2.weight [0. 0.]
fc2.bias [0.]
INICIALIZANDO COM OS PARAMETROS DEFINIDOS ACIMA

TEMPO DE EXECUÇÃO NO cuda: 98.3011 segundos
Melhor loss de validação: 149.400522

============================================================
TREINANDO NO DISPOSITIVO: cpu
============================================================
Parâmetros iniciais:
fc1.weight [0. 0. 0. 0.]
fc1.bias [0. 0.]
fc2.weight [0. 0.]
fc2.bias [0.]
INICIALIZANDO COM OS PARAMETROS DEFINIDOS ACIMA

TEMPO DE EXECUÇÃO NO cpu: 96.2571 segundos
Melhor loss de validação: 149.400522

============================================================
COMPARAÇÃO FINAL - CPU vs GPU
============================================================
Tempo GPU: 98.3011 segundos
Tempo CPU: 96.2571 segundos
Speedup (GPU vs CPU): 0.98x

Loss GPU: 149.400522
Loss CPU: 149.400522</code></pre>
</div>
</div>
</section>
</section>
<section id="item-b." class="level1">
<h1>ITEM B.</h1>
<p>Ajuste a rede neural mais precisa (medida pelo MSE calculado sobre o conjunto de validação) que conseguir, com a arquitetura que quiser. Use todos os artifícios de regularização que desejar (weight decay, Bagging, droupout, Early stopping). Faça otimização dos hiperparâmetros. Reporte a precisão obtida para essa rede no conjunto de teste.</p>
<section id="inicialização" class="level2">
<h2 class="anchored" data-anchor-id="inicialização">Inicialização</h2>
<p>Vamos começar modificando a inicialização de parâmetros. Vimos inicialmente que melhor que começar de maneira aleatória (ou zero), é usar <strong>He Inicialization</strong>, porém esse tipo de processo é específico para ativações do tipo <code>ReLU</code>, que não é o nosso caso. Para <code>Sigmoide</code> vamos usar a <strong>inicialização de Xavier/Glorot</strong>, também indicada em <em>Understanding Deep Learning </em>(113):</p>
<div id="cell-33" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Inicializando com Xavier/Glorot</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> inicializar_xavier(model):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> module <span class="kw">in</span> model.modules():</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(module, nn.Linear):</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>            nn.init.xavier_uniform_(module.weight)  <span class="co"># ±√(6/(fan_in + fan_out))</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> module.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>                nn.init.zeros_(module.bias)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-34" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="36b6e983-1e84-4eff-ac0f-e7681121c760" data-execution_count="55">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">#COM INICIALIZAÇÃO XAVIER:</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TREINO DO MODELO</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TinyNet().double().to(device)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Inicialização Xavier</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>inicializar_xavier(model)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIALIZAÇÃO XAVIER"</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar loss inicial</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">VERIFICAÇÃO DO LOSS INICIAL"</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular loss inicial</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pegar um batch para teste</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>        initial_loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Loss inicial: </span><span class="sc">{</span>initial_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Verificar previsões (devem ser zero)</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeira previsão: </span><span class="sc">{</span>y_pred[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeiro target: </span><span class="sc">{</span>y_batch[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Treinamento</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIANDO TREINO"</span>)</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>num_iters <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>best_val_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>best_val_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>best_val_state_cpu <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR TREINO (apenas para informação)</span></span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>best_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>best_train_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>best_train_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>    train_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>    n_samples_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- TREINO ---</span></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch <span class="op">+=</span> loss.item() <span class="op">*</span> batch_size</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a>        n_samples_train <span class="op">+=</span> batch_size</span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a>    train_loss_avg <span class="op">=</span> train_loss_epoch <span class="op">/</span> n_samples_train</span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- VALIDAÇÃO ---</span></span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>    val_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>    n_samples_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> Xv, yv <span class="kw">in</span> val_loader:</span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a>            Xv <span class="op">=</span> Xv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a>            yv <span class="op">=</span> yv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a>            batch_size_val <span class="op">=</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a>            val_pred <span class="op">=</span> model(Xv)</span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a>            vloss <span class="op">=</span> criterion(val_pred, yv)</span>
<span id="cb25-86"><a href="#cb25-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-87"><a href="#cb25-87" aria-hidden="true" tabindex="-1"></a>            val_loss_epoch <span class="op">+=</span> vloss.item() <span class="op">*</span> batch_size_val</span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a>            n_samples_val <span class="op">+=</span> batch_size_val</span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a>    val_loss_avg <span class="op">=</span> val_loss_epoch <span class="op">/</span> n_samples_val</span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_loss_avg <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a>        best_val_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb25-96"><a href="#cb25-96" aria-hidden="true" tabindex="-1"></a>        best_val_iter <span class="op">=</span> it</span>
<span id="cb25-97"><a href="#cb25-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Salvar cópia dos parâmetros para validação</span></span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a>        best_val_state_cpu <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mover para CPU</span></span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key <span class="kw">in</span> best_val_state_cpu:</span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a>            best_val_state_cpu[key] <span class="op">=</span> best_val_state_cpu[key].cpu()</span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR TREINO (apenas para informação)</span></span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_loss_avg <span class="op">&lt;</span> best_train_loss:</span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a>        best_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a>        best_train_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a>        best_train_iter <span class="op">=</span> it</span>
<span id="cb25-108"><a href="#cb25-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-109"><a href="#cb25-109" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print das iterações importantes</span></span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> it <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> it <span class="kw">in</span> [<span class="dv">16</span>, <span class="dv">17</span>] <span class="kw">or</span> it <span class="op">==</span> num_iters<span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Iteração </span><span class="sc">{</span>it<span class="sc">:3d}</span><span class="ss"> | Treino = </span><span class="sc">{</span>train_loss_avg<span class="sc">:.6f}</span><span class="ss"> | Val = </span><span class="sc">{</span>val_loss_avg<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a><span class="co"># --- RESULTADO FINAL ---</span></span>
<span id="cb25-114"><a href="#cb25-114" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb25-115"><a href="#cb25-115" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESULTADO FINAL"</span>)</span>
<span id="cb25-116"><a href="#cb25-116" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb25-117"><a href="#cb25-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-118"><a href="#cb25-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)"</span>)</span>
<span id="cb25-119"><a href="#cb25-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de validação: </span><span class="sc">{</span>best_val_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-120"><a href="#cb25-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino nessa iteração:  </span><span class="sc">{</span>best_val_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb25-121"><a href="#cb25-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação: </span><span class="sc">{</span>best_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb25-122"><a href="#cb25-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-123"><a href="#cb25-123" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR TREINO (APENAS INFORMAÇÃO)"</span>)</span>
<span id="cb25-124"><a href="#cb25-124" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de treino: </span><span class="sc">{</span>best_train_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-125"><a href="#cb25-125" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino: </span><span class="sc">{</span>best_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb25-126"><a href="#cb25-126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação nessa iteração: </span><span class="sc">{</span>best_train_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb25-127"><a href="#cb25-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-128"><a href="#cb25-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Carregar os parâmetros da MELHOR VALIDAÇÃO no modelo</span></span>
<span id="cb25-129"><a href="#cb25-129" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_val_state_cpu <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-130"><a href="#cb25-130" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_val_state_cpu)</span>
<span id="cb25-131"><a href="#cb25-131" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros da MELHOR VALIDAÇÃO carregados no modelo"</span>)</span>
<span id="cb25-132"><a href="#cb25-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-133"><a href="#cb25-133" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar parâmetros finais (da melhor validação) na ORDEM CORRETA</span></span>
<span id="cb25-134"><a href="#cb25-134" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:"</span>)</span>
<span id="cb25-135"><a href="#cb25-135" aria-hidden="true" tabindex="-1"></a>melhores_parametros <span class="op">=</span> extrair_parametros_na_ordem(model)</span>
<span id="cb25-136"><a href="#cb25-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"["</span> <span class="op">+</span> <span class="st">" "</span>.join(<span class="ss">f"</span><span class="sc">{</span>p<span class="sc">:.8f}</span><span class="ss">"</span> <span class="cf">for</span> p <span class="kw">in</span> melhores_parametros) <span class="op">+</span> <span class="st">"]"</span>)</span>
<span id="cb25-137"><a href="#cb25-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-138"><a href="#cb25-138" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar formato detalhado</span></span>
<span id="cb25-139"><a href="#cb25-139" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detalhado:"</span>)</span>
<span id="cb25-140"><a href="#cb25-140" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w1, w2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">0</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">1</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb25-141"><a href="#cb25-141" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w3, w4: </span><span class="sc">{</span>melhores_parametros[<span class="dv">2</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">3</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb25-142"><a href="#cb25-142" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w5, w6: </span><span class="sc">{</span>melhores_parametros[<span class="dv">4</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">5</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb25-143"><a href="#cb25-143" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b1, b2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">6</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">7</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb25-144"><a href="#cb25-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b3:     </span><span class="sc">{</span>melhores_parametros[<span class="dv">8</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
INICIALIZAÇÃO XAVIER

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 624.372657
Primeira previsão: 0.520377
Primeiro target: 14.842103

INICIANDO TREINO
Iteração   0 | Treino = 98.700980 | Val = 99.468605
Iteração  10 | Treino = 97.201188 | Val = 98.366057
Iteração  16 | Treino = 97.264202 | Val = 102.055486
Iteração  17 | Treino = 97.290864 | Val = 97.926780
Iteração  20 | Treino = 97.225810 | Val = 105.024908
Iteração  30 | Treino = 97.182034 | Val = 101.018182
Iteração  40 | Treino = 97.308165 | Val = 97.947701
Iteração  50 | Treino = 97.190497 | Val = 97.780899
Iteração  60 | Treino = 97.225403 | Val = 98.111870
Iteração  70 | Treino = 97.187589 | Val = 98.434784
Iteração  80 | Treino = 97.170588 | Val = 102.663168
Iteração  90 | Treino = 97.258074 | Val = 99.220562
Iteração  99 | Treino = 97.235316 | Val = 98.419207

============================================================
RESULTADO FINAL
============================================================

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 36
Loss de treino nessa iteração:  97.208400
Loss de validação: 97.510509

MELHOR TREINO (APENAS INFORMAÇÃO)
Melhor iteração de treino: 76
Loss de treino: 97.117772
Loss de validação nessa iteração: 99.440844

Parâmetros da MELHOR VALIDAÇÃO carregados no modelo

Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:
[1.99823136 -8.76371022 -3.17027469 -10.82479463 18.50852825 8.82134448 -5.21532909 24.01452399 6.88315933]

Detalhado:
  w1, w2: 1.99823136, -8.76371022
  w3, w4: -3.17027469, -10.82479463
  w5, w6: 18.50852825, 8.82134448
  b1, b2: -5.21532909, 24.01452399
  b3:     6.88315933</code></pre>
</div>
</div>
<div id="cell-35" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="cdc5d188-5a8c-4016-e785-437bab45e77a">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">#COM INICIALIZAÇÃO XAVIER:</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TREINO DO MODELO</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TinyNet().double().to(device)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Inicialização Xavier</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>inicializar_xavier(model)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIALIZAÇÃO XAVIER"</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar loss inicial</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">VERIFICAÇÃO DO LOSS INICIAL"</span>)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular loss inicial</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pegar um batch para teste</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>        initial_loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Loss inicial: </span><span class="sc">{</span>initial_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Verificar previsões (devem ser zero)</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeira previsão: </span><span class="sc">{</span>y_pred[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeiro target: </span><span class="sc">{</span>y_batch[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Treinamento</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIANDO TREINO"</span>)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate, momentum<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>num_iters <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>best_val_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>best_val_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>best_val_state_cpu <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR TREINO (apenas para informação)</span></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>best_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>best_train_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>best_train_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>    train_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>    n_samples_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- TREINO ---</span></span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch <span class="op">+=</span> loss.item() <span class="op">*</span> batch_size</span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>        n_samples_train <span class="op">+=</span> batch_size</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a>    train_loss_avg <span class="op">=</span> train_loss_epoch <span class="op">/</span> n_samples_train</span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- VALIDAÇÃO ---</span></span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a>    val_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a>    n_samples_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> Xv, yv <span class="kw">in</span> val_loader:</span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a>            Xv <span class="op">=</span> Xv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb27-81"><a href="#cb27-81" aria-hidden="true" tabindex="-1"></a>            yv <span class="op">=</span> yv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb27-82"><a href="#cb27-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-83"><a href="#cb27-83" aria-hidden="true" tabindex="-1"></a>            batch_size_val <span class="op">=</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb27-84"><a href="#cb27-84" aria-hidden="true" tabindex="-1"></a>            val_pred <span class="op">=</span> model(Xv)</span>
<span id="cb27-85"><a href="#cb27-85" aria-hidden="true" tabindex="-1"></a>            vloss <span class="op">=</span> criterion(val_pred, yv)</span>
<span id="cb27-86"><a href="#cb27-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-87"><a href="#cb27-87" aria-hidden="true" tabindex="-1"></a>            val_loss_epoch <span class="op">+=</span> vloss.item() <span class="op">*</span> batch_size_val</span>
<span id="cb27-88"><a href="#cb27-88" aria-hidden="true" tabindex="-1"></a>            n_samples_val <span class="op">+=</span> batch_size_val</span>
<span id="cb27-89"><a href="#cb27-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-90"><a href="#cb27-90" aria-hidden="true" tabindex="-1"></a>    val_loss_avg <span class="op">=</span> val_loss_epoch <span class="op">/</span> n_samples_val</span>
<span id="cb27-91"><a href="#cb27-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-92"><a href="#cb27-92" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb27-93"><a href="#cb27-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_loss_avg <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb27-94"><a href="#cb27-94" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb27-95"><a href="#cb27-95" aria-hidden="true" tabindex="-1"></a>        best_val_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb27-96"><a href="#cb27-96" aria-hidden="true" tabindex="-1"></a>        best_val_iter <span class="op">=</span> it</span>
<span id="cb27-97"><a href="#cb27-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Salvar cópia dos parâmetros para validação</span></span>
<span id="cb27-98"><a href="#cb27-98" aria-hidden="true" tabindex="-1"></a>        best_val_state_cpu <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb27-99"><a href="#cb27-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mover para CPU</span></span>
<span id="cb27-100"><a href="#cb27-100" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key <span class="kw">in</span> best_val_state_cpu:</span>
<span id="cb27-101"><a href="#cb27-101" aria-hidden="true" tabindex="-1"></a>            best_val_state_cpu[key] <span class="op">=</span> best_val_state_cpu[key].cpu()</span>
<span id="cb27-102"><a href="#cb27-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-103"><a href="#cb27-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR TREINO (apenas para informação)</span></span>
<span id="cb27-104"><a href="#cb27-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_loss_avg <span class="op">&lt;</span> best_train_loss:</span>
<span id="cb27-105"><a href="#cb27-105" aria-hidden="true" tabindex="-1"></a>        best_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb27-106"><a href="#cb27-106" aria-hidden="true" tabindex="-1"></a>        best_train_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb27-107"><a href="#cb27-107" aria-hidden="true" tabindex="-1"></a>        best_train_iter <span class="op">=</span> it</span>
<span id="cb27-108"><a href="#cb27-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-109"><a href="#cb27-109" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print das iterações importantes</span></span>
<span id="cb27-110"><a href="#cb27-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> it <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> it <span class="kw">in</span> [<span class="dv">16</span>, <span class="dv">17</span>] <span class="kw">or</span> it <span class="op">==</span> num_iters<span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb27-111"><a href="#cb27-111" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Iteração </span><span class="sc">{</span>it<span class="sc">:3d}</span><span class="ss"> | Treino = </span><span class="sc">{</span>train_loss_avg<span class="sc">:.6f}</span><span class="ss"> | Val = </span><span class="sc">{</span>val_loss_avg<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb27-112"><a href="#cb27-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-113"><a href="#cb27-113" aria-hidden="true" tabindex="-1"></a><span class="co"># --- RESULTADO FINAL ---</span></span>
<span id="cb27-114"><a href="#cb27-114" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb27-115"><a href="#cb27-115" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESULTADO FINAL"</span>)</span>
<span id="cb27-116"><a href="#cb27-116" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb27-117"><a href="#cb27-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-118"><a href="#cb27-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)"</span>)</span>
<span id="cb27-119"><a href="#cb27-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de validação: </span><span class="sc">{</span>best_val_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-120"><a href="#cb27-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino nessa iteração:  </span><span class="sc">{</span>best_val_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb27-121"><a href="#cb27-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação: </span><span class="sc">{</span>best_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb27-122"><a href="#cb27-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-123"><a href="#cb27-123" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR TREINO (APENAS INFORMAÇÃO)"</span>)</span>
<span id="cb27-124"><a href="#cb27-124" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de treino: </span><span class="sc">{</span>best_train_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-125"><a href="#cb27-125" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino: </span><span class="sc">{</span>best_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb27-126"><a href="#cb27-126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação nessa iteração: </span><span class="sc">{</span>best_train_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb27-127"><a href="#cb27-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-128"><a href="#cb27-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Carregar os parâmetros da MELHOR VALIDAÇÃO no modelo</span></span>
<span id="cb27-129"><a href="#cb27-129" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_val_state_cpu <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb27-130"><a href="#cb27-130" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_val_state_cpu)</span>
<span id="cb27-131"><a href="#cb27-131" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros da MELHOR VALIDAÇÃO carregados no modelo"</span>)</span>
<span id="cb27-132"><a href="#cb27-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-133"><a href="#cb27-133" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar parâmetros finais (da melhor validação) na ORDEM CORRETA</span></span>
<span id="cb27-134"><a href="#cb27-134" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:"</span>)</span>
<span id="cb27-135"><a href="#cb27-135" aria-hidden="true" tabindex="-1"></a>melhores_parametros <span class="op">=</span> extrair_parametros_na_ordem(model)</span>
<span id="cb27-136"><a href="#cb27-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"["</span> <span class="op">+</span> <span class="st">" "</span>.join(<span class="ss">f"</span><span class="sc">{</span>p<span class="sc">:.8f}</span><span class="ss">"</span> <span class="cf">for</span> p <span class="kw">in</span> melhores_parametros) <span class="op">+</span> <span class="st">"]"</span>)</span>
<span id="cb27-137"><a href="#cb27-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-138"><a href="#cb27-138" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar formato detalhado</span></span>
<span id="cb27-139"><a href="#cb27-139" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detalhado:"</span>)</span>
<span id="cb27-140"><a href="#cb27-140" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w1, w2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">0</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">1</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb27-141"><a href="#cb27-141" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w3, w4: </span><span class="sc">{</span>melhores_parametros[<span class="dv">2</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">3</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb27-142"><a href="#cb27-142" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w5, w6: </span><span class="sc">{</span>melhores_parametros[<span class="dv">4</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">5</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb27-143"><a href="#cb27-143" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b1, b2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">6</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">7</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb27-144"><a href="#cb27-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b3:     </span><span class="sc">{</span>melhores_parametros[<span class="dv">8</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
INICIALIZAÇÃO XAVIER

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 657.709023
Primeira previsão: 0.434711
Primeiro target: 35.120982

INICIANDO TREINO
Iteração   0 | Treino = 657.709023 | Val = 387.070625
Iteração  10 | Treino = 120.455094 | Val = 121.432553
Iteração  16 | Treino = 110.860361 | Val = 111.892444
Iteração  17 | Treino = 109.873882 | Val = 111.143083
Iteração  20 | Treino = 107.399247 | Val = 108.634214
Iteração  30 | Treino = 102.536147 | Val = 104.025638
Iteração  40 | Treino = 100.022471 | Val = 101.548778
Iteração  50 | Treino = 98.561763 | Val = 100.088354
Iteração  60 | Treino = 97.701923 | Val = 99.215404
Iteração  70 | Treino = 97.192059 | Val = 98.687910
Iteração  80 | Treino = 96.887213 | Val = 98.365326
Iteração  90 | Treino = 96.702588 | Val = 98.164853
Iteração  99 | Treino = 96.597687 | Val = 98.047906

============================================================
RESULTADO FINAL
============================================================

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 99
Loss de treino nessa iteração:  96.597687
Loss de validação: 98.047906

MELHOR TREINO (APENAS INFORMAÇÃO)
Melhor iteração de treino: 99
Loss de treino: 96.597687
Loss de validação nessa iteração: 98.047906

Parâmetros da MELHOR VALIDAÇÃO carregados no modelo

Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:
[1.71651571 -6.81702601 -1.61371955 -2.89382036 17.37388061 9.09587648 -4.12289796 5.78382848 7.62424542]

Detalhado:
  w1, w2: 1.71651571, -6.81702601
  w3, w4: -1.61371955, -2.89382036
  w5, w6: 17.37388061, 9.09587648
  b1, b2: -4.12289796, 5.78382848
  b3:     7.62424542</code></pre>
</div>
</div>
<p>Tracking de resultados até o momento:</p>
<ul>
<li>Inicialização com zeros e Full Gradiente Descendente</li>
</ul>
<pre><code>Melhor loss de validação: 149.400522  

Parâmetros
w1, w2: -0.75778832, -2.40989992
w3, w4: -0.75778832, -2.40989992
w5, w6: 8.22808010, 8.22808010
b1, b2: 2.17300733, 2.17300733
b3:     11.38825398</code></pre>
<ul>
<li>Inicialização Xavier e Full Gradiente Descendente</li>
</ul>
<pre><code>Melhor loss de validação: 96.597687

w1, w2: 1.71651571, -6.81702601
w3, w4: -1.61371955, -2.89382036
w5, w6: 17.37388061, 9.09587648
b1, b2: -4.12289796, 5.78382848
b3:     7.62424542</code></pre>
</section>
<section id="l2-regularization-adam-ou-sgd" class="level2">
<h2 class="anchored" data-anchor-id="l2-regularization-adam-ou-sgd">L2 Regularization + ADAM (ou SGD)</h2>
<p>Vamos testar alguns pesos para regularização L2 (primeiro vamos tentar uma aproximação para esse peso, e se necessários tentamos otimizar mais para frente):</p>
<div id="cell-39" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7ace7220-6bd3-403c-ad48-d4da6631edfd">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">#COM INICIALIZAÇÃO XAVIER + L2REG</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TREINO DO MODELO</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TinyNet().double().to(device)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Inicialização Xavier</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>inicializar_xavier(model)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIALIZAÇÃO XAVIER"</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar loss inicial</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">VERIFICAÇÃO DO LOSS INICIAL"</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular loss inicial</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pegar um batch para teste</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>        initial_loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Loss inicial: </span><span class="sc">{</span>initial_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Verificar previsões (devem ser zero)</span></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeira previsão: </span><span class="sc">{</span>y_pred[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeiro target: </span><span class="sc">{</span>y_batch[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Treinamento</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIANDO TREINO COM L2_REG"</span>)</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>weight_decay <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>    model.parameters(),</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>learning_rate,</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>    momentum<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span>weight_decay  <span class="co"># L2</span></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Usando weight_decay = </span><span class="sc">{</span>weight_decay<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>num_iters <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>best_val_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>best_val_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>best_val_state_cpu <span class="op">=</span> <span class="va">None</span></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR TREINO (apenas para informação)</span></span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>best_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>best_train_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>best_train_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>    train_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a>    n_samples_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- TREINO ---</span></span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch <span class="op">+=</span> loss.item() <span class="op">*</span> batch_size</span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>        n_samples_train <span class="op">+=</span> batch_size</span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>    train_loss_avg <span class="op">=</span> train_loss_epoch <span class="op">/</span> n_samples_train</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- VALIDAÇÃO ---</span></span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a>    val_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a>    n_samples_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> Xv, yv <span class="kw">in</span> val_loader:</span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>            Xv <span class="op">=</span> Xv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>            yv <span class="op">=</span> yv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>            batch_size_val <span class="op">=</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>            val_pred <span class="op">=</span> model(Xv)</span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>            vloss <span class="op">=</span> criterion(val_pred, yv)</span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a>            val_loss_epoch <span class="op">+=</span> vloss.item() <span class="op">*</span> batch_size_val</span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a>            n_samples_val <span class="op">+=</span> batch_size_val</span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>    val_loss_avg <span class="op">=</span> val_loss_epoch <span class="op">/</span> n_samples_val</span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_loss_avg <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a>        best_val_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a>        best_val_iter <span class="op">=</span> it</span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Salvar cópia dos parâmetros para validação</span></span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a>        best_val_state_cpu <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mover para CPU</span></span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key <span class="kw">in</span> best_val_state_cpu:</span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a>            best_val_state_cpu[key] <span class="op">=</span> best_val_state_cpu[key].cpu()</span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR TREINO (apenas para informação)</span></span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_loss_avg <span class="op">&lt;</span> best_train_loss:</span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a>        best_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a>        best_train_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a>        best_train_iter <span class="op">=</span> it</span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print das iterações importantes</span></span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> it <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> it <span class="kw">in</span> [<span class="dv">16</span>, <span class="dv">17</span>] <span class="kw">or</span> it <span class="op">==</span> num_iters<span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb31-119"><a href="#cb31-119" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Iteração </span><span class="sc">{</span>it<span class="sc">:3d}</span><span class="ss"> | Treino = </span><span class="sc">{</span>train_loss_avg<span class="sc">:.6f}</span><span class="ss"> | Val = </span><span class="sc">{</span>val_loss_avg<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb31-120"><a href="#cb31-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-121"><a href="#cb31-121" aria-hidden="true" tabindex="-1"></a><span class="co"># --- RESULTADO FINAL ---</span></span>
<span id="cb31-122"><a href="#cb31-122" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESULTADO FINAL (XAVIER E L2-REG)"</span>)</span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)"</span>)</span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de validação: </span><span class="sc">{</span>best_val_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-128"><a href="#cb31-128" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino nessa iteração:  </span><span class="sc">{</span>best_val_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb31-129"><a href="#cb31-129" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação: </span><span class="sc">{</span>best_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR TREINO (APENAS INFORMAÇÃO)"</span>)</span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de treino: </span><span class="sc">{</span>best_train_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino: </span><span class="sc">{</span>best_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação nessa iteração: </span><span class="sc">{</span>best_train_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb31-135"><a href="#cb31-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-136"><a href="#cb31-136" aria-hidden="true" tabindex="-1"></a><span class="co"># Carregar os parâmetros da MELHOR VALIDAÇÃO no modelo</span></span>
<span id="cb31-137"><a href="#cb31-137" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_val_state_cpu <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb31-138"><a href="#cb31-138" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_val_state_cpu)</span>
<span id="cb31-139"><a href="#cb31-139" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros da MELHOR VALIDAÇÃO carregados no modelo"</span>)</span>
<span id="cb31-140"><a href="#cb31-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-141"><a href="#cb31-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar parâmetros finais (da melhor validação) na ORDEM CORRETA</span></span>
<span id="cb31-142"><a href="#cb31-142" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:"</span>)</span>
<span id="cb31-143"><a href="#cb31-143" aria-hidden="true" tabindex="-1"></a>melhores_parametros <span class="op">=</span> extrair_parametros_na_ordem(model)</span>
<span id="cb31-144"><a href="#cb31-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"["</span> <span class="op">+</span> <span class="st">" "</span>.join(<span class="ss">f"</span><span class="sc">{</span>p<span class="sc">:.8f}</span><span class="ss">"</span> <span class="cf">for</span> p <span class="kw">in</span> melhores_parametros) <span class="op">+</span> <span class="st">"]"</span>)</span>
<span id="cb31-145"><a href="#cb31-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-146"><a href="#cb31-146" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar formato detalhado</span></span>
<span id="cb31-147"><a href="#cb31-147" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detalhado:"</span>)</span>
<span id="cb31-148"><a href="#cb31-148" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w1, w2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">0</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">1</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb31-149"><a href="#cb31-149" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w3, w4: </span><span class="sc">{</span>melhores_parametros[<span class="dv">2</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">3</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb31-150"><a href="#cb31-150" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w5, w6: </span><span class="sc">{</span>melhores_parametros[<span class="dv">4</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">5</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb31-151"><a href="#cb31-151" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b1, b2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">6</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">7</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb31-152"><a href="#cb31-152" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b3:     </span><span class="sc">{</span>melhores_parametros[<span class="dv">8</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
INICIALIZAÇÃO XAVIER

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 655.515577
Primeira previsão: 0.773777
Primeiro target: 35.120982

INICIANDO TREINO COM L2_REG
Usando weight_decay = 0.001
Iteração   0 | Treino = 655.515577 | Val = 410.153256
Iteração  10 | Treino = 124.312047 | Val = 126.548536
Iteração  16 | Treino = 117.601446 | Val = 117.732668
Iteração  17 | Treino = 115.193510 | Val = 117.016508
Iteração  20 | Treino = 112.693064 | Val = 113.679433
Iteração  30 | Treino = 104.956251 | Val = 106.401164
Iteração  40 | Treino = 101.288616 | Val = 102.808403
Iteração  50 | Treino = 99.312874 | Val = 100.846739
Iteração  60 | Treino = 98.155725 | Val = 99.682212
Iteração  70 | Treino = 97.471410 | Val = 98.981723
Iteração  80 | Treino = 97.063231 | Val = 98.555316
Iteração  90 | Treino = 96.816952 | Val = 98.291889
Iteração  99 | Treino = 96.677879 | Val = 98.139389

============================================================
RESULTADO FINAL (XAVIER E L2-REG)
============================================================

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 99
Loss de treino nessa iteração:  96.677879
Loss de validação: 98.139389

MELHOR TREINO (APENAS INFORMAÇÃO)
Melhor iteração de treino: 99
Loss de treino: 96.677879
Loss de validação nessa iteração: 98.139389

Parâmetros da MELHOR VALIDAÇÃO carregados no modelo

Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:
[1.71089519 -6.75561705 -1.60693919 -2.85966318 17.20766028 9.09830805 -4.08691726 5.65675803 7.72281733]

Detalhado:
  w1, w2: 1.71089519, -6.75561705
  w3, w4: -1.60693919, -2.85966318
  w5, w6: 17.20766028, 9.09830805
  b1, b2: -4.08691726, 5.65675803
  b3:     7.72281733</code></pre>
</div>
</div>
<p>Note que não houve melhora usando o weight decay indicado, então vamos fazer outros testes:</p>
<div id="cell-41" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="59744673-7f2a-42ab-b8b2-6eb1768b2aac">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COM INICIALIZAÇÃO XAVIER + L2REG + SGD COM MOMENTUM - TESTANDO DIFERENTES VALORES</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TESTAR DIFERENTES VALORES DE WEIGHT DECAY</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>weight_decay_values <span class="op">=</span> [<span class="fl">0.0001</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>]</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>resultados <span class="op">=</span> []</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> wd <span class="kw">in</span> weight_decay_values:</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"TESTANDO weight_decay = </span><span class="sc">{</span>wd<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TREINO DO MODELO</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> TinyNet().double().to(device)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Inicialização Xavier</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    inicializar_xavier(model)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIALIZAÇÃO XAVIER"</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verificar loss inicial</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">VERIFICAÇÃO DO LOSS INICIAL"</span>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcular loss inicial</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pegar um batch para teste</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>            X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>            initial_loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Loss inicial: </span><span class="sc">{</span>initial_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Verificar previsões</span></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Primeira previsão: </span><span class="sc">{</span>y_pred[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Primeiro target: </span><span class="sc">{</span>y_batch[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Treinamento</span></span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIANDO TREINO COM L2_REG"</span>)</span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.SGD(</span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>    model.parameters(),</span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>learning_rate,</span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>    momentum<span class="op">=</span><span class="fl">0.9</span>,      <span class="co"># Adicionar momentum</span></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span>wd    <span class="co"># L2 continua</span></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Usando weight_decay = </span><span class="sc">{</span>wd<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>    num_iters <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Variáveis para MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a>    best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>    best_val_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>    best_val_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a>    best_val_state_cpu <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Variáveis para MELHOR TREINO (apenas para informação)</span></span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a>    best_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>    best_train_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>    best_train_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a>        n_samples_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- TREINO ---</span></span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a>            X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a>            batch_size <span class="op">=</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-84"><a href="#cb33-84" aria-hidden="true" tabindex="-1"></a>            train_loss_epoch <span class="op">+=</span> loss.item() <span class="op">*</span> batch_size</span>
<span id="cb33-85"><a href="#cb33-85" aria-hidden="true" tabindex="-1"></a>            n_samples_train <span class="op">+=</span> batch_size</span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a>        train_loss_avg <span class="op">=</span> train_loss_epoch <span class="op">/</span> n_samples_train</span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-89"><a href="#cb33-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- VALIDAÇÃO ---</span></span>
<span id="cb33-90"><a href="#cb33-90" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb33-91"><a href="#cb33-91" aria-hidden="true" tabindex="-1"></a>        val_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb33-92"><a href="#cb33-92" aria-hidden="true" tabindex="-1"></a>        n_samples_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-93"><a href="#cb33-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-94"><a href="#cb33-94" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb33-95"><a href="#cb33-95" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> Xv, yv <span class="kw">in</span> val_loader:</span>
<span id="cb33-96"><a href="#cb33-96" aria-hidden="true" tabindex="-1"></a>                Xv <span class="op">=</span> Xv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb33-97"><a href="#cb33-97" aria-hidden="true" tabindex="-1"></a>                yv <span class="op">=</span> yv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb33-98"><a href="#cb33-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-99"><a href="#cb33-99" aria-hidden="true" tabindex="-1"></a>                batch_size_val <span class="op">=</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb33-100"><a href="#cb33-100" aria-hidden="true" tabindex="-1"></a>                val_pred <span class="op">=</span> model(Xv)</span>
<span id="cb33-101"><a href="#cb33-101" aria-hidden="true" tabindex="-1"></a>                vloss <span class="op">=</span> criterion(val_pred, yv)</span>
<span id="cb33-102"><a href="#cb33-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-103"><a href="#cb33-103" aria-hidden="true" tabindex="-1"></a>                val_loss_epoch <span class="op">+=</span> vloss.item() <span class="op">*</span> batch_size_val</span>
<span id="cb33-104"><a href="#cb33-104" aria-hidden="true" tabindex="-1"></a>                n_samples_val <span class="op">+=</span> batch_size_val</span>
<span id="cb33-105"><a href="#cb33-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-106"><a href="#cb33-106" aria-hidden="true" tabindex="-1"></a>        val_loss_avg <span class="op">=</span> val_loss_epoch <span class="op">/</span> n_samples_val</span>
<span id="cb33-107"><a href="#cb33-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-108"><a href="#cb33-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ATUALIZAR MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb33-109"><a href="#cb33-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_loss_avg <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb33-110"><a href="#cb33-110" aria-hidden="true" tabindex="-1"></a>            best_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb33-111"><a href="#cb33-111" aria-hidden="true" tabindex="-1"></a>            best_val_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb33-112"><a href="#cb33-112" aria-hidden="true" tabindex="-1"></a>            best_val_iter <span class="op">=</span> it</span>
<span id="cb33-113"><a href="#cb33-113" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Salvar cópia dos parâmetros para validação</span></span>
<span id="cb33-114"><a href="#cb33-114" aria-hidden="true" tabindex="-1"></a>            best_val_state_cpu <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb33-115"><a href="#cb33-115" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mover para CPU</span></span>
<span id="cb33-116"><a href="#cb33-116" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> key <span class="kw">in</span> best_val_state_cpu:</span>
<span id="cb33-117"><a href="#cb33-117" aria-hidden="true" tabindex="-1"></a>                best_val_state_cpu[key] <span class="op">=</span> best_val_state_cpu[key].cpu()</span>
<span id="cb33-118"><a href="#cb33-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-119"><a href="#cb33-119" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ATUALIZAR MELHOR TREINO (apenas para informação)</span></span>
<span id="cb33-120"><a href="#cb33-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> train_loss_avg <span class="op">&lt;</span> best_train_loss:</span>
<span id="cb33-121"><a href="#cb33-121" aria-hidden="true" tabindex="-1"></a>            best_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb33-122"><a href="#cb33-122" aria-hidden="true" tabindex="-1"></a>            best_train_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb33-123"><a href="#cb33-123" aria-hidden="true" tabindex="-1"></a>            best_train_iter <span class="op">=</span> it</span>
<span id="cb33-124"><a href="#cb33-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-125"><a href="#cb33-125" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print das iterações importantes</span></span>
<span id="cb33-126"><a href="#cb33-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> it <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> it <span class="kw">in</span> [<span class="dv">16</span>, <span class="dv">17</span>] <span class="kw">or</span> it <span class="op">==</span> num_iters<span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb33-127"><a href="#cb33-127" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Iteração </span><span class="sc">{</span>it<span class="sc">:3d}</span><span class="ss"> | Treino = </span><span class="sc">{</span>train_loss_avg<span class="sc">:.6f}</span><span class="ss"> | Val = </span><span class="sc">{</span>val_loss_avg<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-128"><a href="#cb33-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-129"><a href="#cb33-129" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- RESULTADO DESTE WD ---</span></span>
<span id="cb33-130"><a href="#cb33-130" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb33-131"><a href="#cb33-131" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"RESULTADO weight_decay = </span><span class="sc">{</span>wd<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-132"><a href="#cb33-132" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb33-133"><a href="#cb33-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-134"><a href="#cb33-134" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)"</span>)</span>
<span id="cb33-135"><a href="#cb33-135" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Melhor iteração de validação: </span><span class="sc">{</span>best_val_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-136"><a href="#cb33-136" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Loss de treino nessa iteração:  </span><span class="sc">{</span>best_val_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-137"><a href="#cb33-137" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Loss de validação: </span><span class="sc">{</span>best_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-138"><a href="#cb33-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-139"><a href="#cb33-139" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Salvar resultados para comparação</span></span>
<span id="cb33-140"><a href="#cb33-140" aria-hidden="true" tabindex="-1"></a>    resultados.append({</span>
<span id="cb33-141"><a href="#cb33-141" aria-hidden="true" tabindex="-1"></a>        <span class="st">'weight_decay'</span>: wd,</span>
<span id="cb33-142"><a href="#cb33-142" aria-hidden="true" tabindex="-1"></a>        <span class="st">'best_val_loss'</span>: best_val_loss,</span>
<span id="cb33-143"><a href="#cb33-143" aria-hidden="true" tabindex="-1"></a>        <span class="st">'best_iter'</span>: best_val_iter</span>
<span id="cb33-144"><a href="#cb33-144" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb33-145"><a href="#cb33-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-146"><a href="#cb33-146" aria-hidden="true" tabindex="-1"></a><span class="co"># --- COMPARAÇÃO FINAL DE TODOS OS WD ---</span></span>
<span id="cb33-147"><a href="#cb33-147" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-148"><a href="#cb33-148" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAÇÃO FINAL - TODOS OS WEIGHT DECAY (l2_REG + SGD)"</span>)</span>
<span id="cb33-149"><a href="#cb33-149" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'='</span><span class="op">*</span><span class="dv">60</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-150"><a href="#cb33-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-151"><a href="#cb33-151" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordenar por melhor loss de validação</span></span>
<span id="cb33-152"><a href="#cb33-152" aria-hidden="true" tabindex="-1"></a>resultados_ordenados <span class="op">=</span> <span class="bu">sorted</span>(resultados, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">'best_val_loss'</span>])</span>
<span id="cb33-153"><a href="#cb33-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-154"><a href="#cb33-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">RANKING (do melhor para o pior):"</span>)</span>
<span id="cb33-155"><a href="#cb33-155" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, res <span class="kw">in</span> <span class="bu">enumerate</span>(resultados_ordenados, <span class="dv">1</span>):</span>
<span id="cb33-156"><a href="#cb33-156" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">º - WD=</span><span class="sc">{</span>res[<span class="st">'weight_decay'</span>]<span class="sc">}</span><span class="ss">: val_loss = </span><span class="sc">{</span>res[<span class="st">'best_val_loss'</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb33-157"><a href="#cb33-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-158"><a href="#cb33-158" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar o melhor</span></span>
<span id="cb33-159"><a href="#cb33-159" aria-hidden="true" tabindex="-1"></a>melhor <span class="op">=</span> resultados_ordenados[<span class="dv">0</span>]</span>
<span id="cb33-160"><a href="#cb33-160" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">MELHOR CONFIGURAÇÃO: weight_decay = </span><span class="sc">{</span>melhor[<span class="st">'weight_decay'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-161"><a href="#cb33-161" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação: </span><span class="sc">{</span>melhor[<span class="st">'best_val_loss'</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
============================================================
TESTANDO weight_decay = 0.0001
============================================================

INICIALIZAÇÃO XAVIER

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 657.709023
Primeira previsão: 0.434711
Primeiro target: 35.120982

INICIANDO TREINO COM L2_REG
Usando weight_decay = 0.0001
Iteração   0 | Treino = 657.709023 | Val = 387.070944
Iteração  10 | Treino = 182.007381 | Val = 168.110998
Iteração  16 | Treino = 139.557291 | Val = 132.237415
Iteração  17 | Treino = 130.192780 | Val = 123.682784
Iteração  20 | Treino = 126.754056 | Val = 134.459892
Iteração  30 | Treino = 112.814247 | Val = 117.364418
Iteração  40 | Treino = 110.614732 | Val = 112.551430
Iteração  50 | Treino = 107.880810 | Val = 109.778736
Iteração  60 | Treino = 104.527270 | Val = 106.838684
Iteração  70 | Treino = 100.480471 | Val = 102.363952
Iteração  80 | Treino = 96.584823 | Val = 98.195788
Iteração  90 | Treino = 94.598638 | Val = 96.321307
Iteração  99 | Treino = 93.404591 | Val = 94.999955

============================================================
RESULTADO weight_decay = 0.0001
============================================================

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 99
Loss de treino nessa iteração:  93.404591
Loss de validação: 94.999955

============================================================
TESTANDO weight_decay = 0.001
============================================================

INICIALIZAÇÃO XAVIER

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 655.020521
Primeira previsão: 0.489309
Primeiro target: 35.120982

INICIANDO TREINO COM L2_REG
Usando weight_decay = 0.001
Iteração   0 | Treino = 655.020521 | Val = 418.540785
Iteração  10 | Treino = 194.741201 | Val = 169.606847
Iteração  16 | Treino = 150.917813 | Val = 128.892991
Iteração  17 | Treino = 128.641337 | Val = 112.125473
Iteração  20 | Treino = 127.657840 | Val = 135.797516
Iteração  30 | Treino = 105.247861 | Val = 111.466230
Iteração  40 | Treino = 104.696176 | Val = 105.548228
Iteração  50 | Treino = 104.533314 | Val = 104.870183
Iteração  60 | Treino = 103.934151 | Val = 104.784439
Iteração  70 | Treino = 103.448995 | Val = 104.520686
Iteração  80 | Treino = 103.254619 | Val = 104.367994
Iteração  90 | Treino = 103.190388 | Val = 104.289756
Iteração  99 | Treino = 103.146015 | Val = 104.230928

============================================================
RESULTADO weight_decay = 0.001
============================================================

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 99
Loss de treino nessa iteração:  103.146015
Loss de validação: 104.230928

============================================================
TESTANDO weight_decay = 0.01
============================================================

INICIALIZAÇÃO XAVIER

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 655.515577
Primeira previsão: 0.773777
Primeiro target: 35.120982

INICIANDO TREINO COM L2_REG
Usando weight_decay = 0.01
Iteração   0 | Treino = 655.515577 | Val = 410.170505
Iteração  10 | Treino = 184.574176 | Val = 177.284225
Iteração  16 | Treino = 135.899318 | Val = 123.119344
Iteração  17 | Treino = 122.899699 | Val = 104.288000
Iteração  20 | Treino = 98.359544 | Val = 110.406608
Iteração  30 | Treino = 97.409718 | Val = 97.504979
Iteração  40 | Treino = 94.678867 | Val = 94.772591
Iteração  50 | Treino = 90.719298 | Val = 91.529130
Iteração  60 | Treino = 87.891588 | Val = 88.232809
Iteração  70 | Treino = 87.062138 | Val = 87.144418
Iteração  80 | Treino = 86.637586 | Val = 86.794915
Iteração  90 | Treino = 86.320064 | Val = 86.534323
Iteração  99 | Treino = 86.069863 | Val = 86.270252

============================================================
RESULTADO weight_decay = 0.01
============================================================

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 99
Loss de treino nessa iteração:  86.069863
Loss de validação: 86.270252

============================================================
TESTANDO weight_decay = 0.1
============================================================

INICIALIZAÇÃO XAVIER

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 693.934868
Primeira previsão: -0.491056
Primeiro target: 35.120982

INICIANDO TREINO COM L2_REG
Usando weight_decay = 0.1
Iteração   0 | Treino = 693.934868 | Val = 456.470333
Iteração  10 | Treino = 228.481881 | Val = 211.585989
Iteração  16 | Treino = 148.910500 | Val = 130.328171
Iteração  17 | Treino = 130.998187 | Val = 108.095150
Iteração  20 | Treino = 119.244941 | Val = 138.070220
Iteração  30 | Treino = 104.388225 | Val = 110.621792
Iteração  40 | Treino = 106.523448 | Val = 107.351606
Iteração  50 | Treino = 104.677582 | Val = 106.001346
Iteração  60 | Treino = 104.932893 | Val = 106.743987
Iteração  70 | Treino = 104.332582 | Val = 106.098580
Iteração  80 | Treino = 104.228556 | Val = 105.526358
Iteração  90 | Treino = 104.396900 | Val = 105.720492
Iteração  99 | Treino = 104.291719 | Val = 105.718998

============================================================
RESULTADO weight_decay = 0.1
============================================================

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 24
Loss de treino nessa iteração:  102.929398
Loss de validação: 100.163982

============================================================
COMPARAÇÃO FINAL - TODOS OS WEIGHT DECAY
============================================================

RANKING (do melhor para o pior):
1º - WD=0.01: val_loss = 86.270252
2º - WD=0.0001: val_loss = 94.999955
3º - WD=0.1: val_loss = 100.163982
4º - WD=0.001: val_loss = 104.230928

MELHOR CONFIGURAÇÃO: weight_decay = 0.01
Loss de validação: 86.270252</code></pre>
</div>
</div>
<p>Tracking de resultados até o momento:</p>
<ul>
<li>Inicialização com zeros e Full Gradiente Descendente</li>
</ul>
<pre><code>Melhor loss de validação: 149.400522  

Parâmetros
w1, w2: -0.75778832, -2.40989992
w3, w4: -0.75778832, -2.40989992
w5, w6: 8.22808010, 8.22808010
b1, b2: 2.17300733, 2.17300733
b3:     11.38825398</code></pre>
<ul>
<li>Inicialização Xavier e Full Gradiente Descendente</li>
</ul>
<pre><code>Melhor loss de validação: 96.597687

w1, w2: 1.71651571, -6.81702601
w3, w4: -1.61371955, -2.89382036
w5, w6: 17.37388061, 9.09587648
b1, b2: -4.12289796, 5.78382848
b3:     7.62424542</code></pre>
<ul>
<li>Inicialização Xavier + SGD (0.01)</li>
</ul>
<pre><code>Melhor loss de validação: 86.270252</code></pre>
<div id="cell-43" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="af826b0a-d76f-4cb1-b97d-93e5be1a7eda">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COM INICIALIZAÇÃO XAVIER + ADAM + EARLY STOPPING</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TREINO DO MODELO</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TinyNet().double().to(device)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Inicialização Xavier</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>inicializar_xavier(model)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIALIZAÇÃO XAVIER"</span>)</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar loss inicial</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">VERIFICAÇÃO DO LOSS INICIAL"</span>)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular loss inicial</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pegar um batch para teste</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>        initial_loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Loss inicial: </span><span class="sc">{</span>initial_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Verificar previsões</span></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeira previsão: </span><span class="sc">{</span>y_pred[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Primeiro target: </span><span class="sc">{</span>y_batch[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Treinamento com ADAM</span></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIANDO TREINO COM ADAM + EARLY STOPPING"</span>)</span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.7</span>  <span class="co"># Adam geralmente funciona melhor com LR menor</span></span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>weight_decay <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a><span class="co"># OPTIMIZER ADAM</span></span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(</span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a>    model.parameters(),</span>
<span id="cb38-40"><a href="#cb38-40" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>learning_rate,</span>
<span id="cb38-41"><a href="#cb38-41" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span>weight_decay  <span class="co"># L2</span></span>
<span id="cb38-42"><a href="#cb38-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-43"><a href="#cb38-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Usando Adam com learning_rate = </span><span class="sc">{</span>learning_rate<span class="sc">}</span><span class="ss">, weight_decay = </span><span class="sc">{</span>weight_decay<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-44"><a href="#cb38-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-45"><a href="#cb38-45" aria-hidden="true" tabindex="-1"></a><span class="co"># CONFIGURAÇÃO EARLY STOPPING</span></span>
<span id="cb38-46"><a href="#cb38-46" aria-hidden="true" tabindex="-1"></a>num_iters <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb38-47"><a href="#cb38-47" aria-hidden="true" tabindex="-1"></a>patience <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb38-48"><a href="#cb38-48" aria-hidden="true" tabindex="-1"></a>no_improvement_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-49"><a href="#cb38-49" aria-hidden="true" tabindex="-1"></a>best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb38-50"><a href="#cb38-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-51"><a href="#cb38-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR VALIDAÇÃO (parâmetros finais)</span></span>
<span id="cb38-52"><a href="#cb38-52" aria-hidden="true" tabindex="-1"></a>best_val_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb38-53"><a href="#cb38-53" aria-hidden="true" tabindex="-1"></a>best_val_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb38-54"><a href="#cb38-54" aria-hidden="true" tabindex="-1"></a>best_val_state_cpu <span class="op">=</span> <span class="va">None</span></span>
<span id="cb38-55"><a href="#cb38-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-56"><a href="#cb38-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Variáveis para MELHOR TREINO (apenas para informação)</span></span>
<span id="cb38-57"><a href="#cb38-57" aria-hidden="true" tabindex="-1"></a>best_train_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb38-58"><a href="#cb38-58" aria-hidden="true" tabindex="-1"></a>best_train_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb38-59"><a href="#cb38-59" aria-hidden="true" tabindex="-1"></a>best_train_iter <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb38-60"><a href="#cb38-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-61"><a href="#cb38-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Early Stopping: parará após </span><span class="sc">{</span>patience<span class="sc">}</span><span class="ss"> iterações sem melhoria"</span>)</span>
<span id="cb38-62"><a href="#cb38-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Máximo de iterações: </span><span class="sc">{</span>num_iters<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-63"><a href="#cb38-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-64"><a href="#cb38-64" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb38-65"><a href="#cb38-65" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb38-66"><a href="#cb38-66" aria-hidden="true" tabindex="-1"></a>    train_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb38-67"><a href="#cb38-67" aria-hidden="true" tabindex="-1"></a>    n_samples_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-68"><a href="#cb38-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-69"><a href="#cb38-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- TREINO ---</span></span>
<span id="cb38-70"><a href="#cb38-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb38-71"><a href="#cb38-71" aria-hidden="true" tabindex="-1"></a>        X_batch <span class="op">=</span> X_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb38-72"><a href="#cb38-72" aria-hidden="true" tabindex="-1"></a>        y_batch <span class="op">=</span> y_batch.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb38-73"><a href="#cb38-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-74"><a href="#cb38-74" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb38-75"><a href="#cb38-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-76"><a href="#cb38-76" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb38-77"><a href="#cb38-77" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb38-78"><a href="#cb38-78" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb38-79"><a href="#cb38-79" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb38-80"><a href="#cb38-80" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb38-81"><a href="#cb38-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-82"><a href="#cb38-82" aria-hidden="true" tabindex="-1"></a>        train_loss_epoch <span class="op">+=</span> loss.item() <span class="op">*</span> batch_size</span>
<span id="cb38-83"><a href="#cb38-83" aria-hidden="true" tabindex="-1"></a>        n_samples_train <span class="op">+=</span> batch_size</span>
<span id="cb38-84"><a href="#cb38-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-85"><a href="#cb38-85" aria-hidden="true" tabindex="-1"></a>    train_loss_avg <span class="op">=</span> train_loss_epoch <span class="op">/</span> n_samples_train</span>
<span id="cb38-86"><a href="#cb38-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-87"><a href="#cb38-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- VALIDAÇÃO ---</span></span>
<span id="cb38-88"><a href="#cb38-88" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb38-89"><a href="#cb38-89" aria-hidden="true" tabindex="-1"></a>    val_loss_epoch <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb38-90"><a href="#cb38-90" aria-hidden="true" tabindex="-1"></a>    n_samples_val <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-91"><a href="#cb38-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-92"><a href="#cb38-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb38-93"><a href="#cb38-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> Xv, yv <span class="kw">in</span> val_loader:</span>
<span id="cb38-94"><a href="#cb38-94" aria-hidden="true" tabindex="-1"></a>            Xv <span class="op">=</span> Xv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb38-95"><a href="#cb38-95" aria-hidden="true" tabindex="-1"></a>            yv <span class="op">=</span> yv.to(device, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb38-96"><a href="#cb38-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-97"><a href="#cb38-97" aria-hidden="true" tabindex="-1"></a>            batch_size_val <span class="op">=</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb38-98"><a href="#cb38-98" aria-hidden="true" tabindex="-1"></a>            val_pred <span class="op">=</span> model(Xv)</span>
<span id="cb38-99"><a href="#cb38-99" aria-hidden="true" tabindex="-1"></a>            vloss <span class="op">=</span> criterion(val_pred, yv)</span>
<span id="cb38-100"><a href="#cb38-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-101"><a href="#cb38-101" aria-hidden="true" tabindex="-1"></a>            val_loss_epoch <span class="op">+=</span> vloss.item() <span class="op">*</span> batch_size_val</span>
<span id="cb38-102"><a href="#cb38-102" aria-hidden="true" tabindex="-1"></a>            n_samples_val <span class="op">+=</span> batch_size_val</span>
<span id="cb38-103"><a href="#cb38-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-104"><a href="#cb38-104" aria-hidden="true" tabindex="-1"></a>    val_loss_avg <span class="op">=</span> val_loss_epoch <span class="op">/</span> n_samples_val</span>
<span id="cb38-105"><a href="#cb38-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-106"><a href="#cb38-106" aria-hidden="true" tabindex="-1"></a>    <span class="co"># EARLY STOPPING</span></span>
<span id="cb38-107"><a href="#cb38-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_loss_avg <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb38-108"><a href="#cb38-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Melhoria encontrada</span></span>
<span id="cb38-109"><a href="#cb38-109" aria-hidden="true" tabindex="-1"></a>        improvement <span class="op">=</span> best_val_loss <span class="op">-</span> val_loss_avg</span>
<span id="cb38-110"><a href="#cb38-110" aria-hidden="true" tabindex="-1"></a>        best_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb38-111"><a href="#cb38-111" aria-hidden="true" tabindex="-1"></a>        best_val_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb38-112"><a href="#cb38-112" aria-hidden="true" tabindex="-1"></a>        best_val_iter <span class="op">=</span> it</span>
<span id="cb38-113"><a href="#cb38-113" aria-hidden="true" tabindex="-1"></a>        no_improvement_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb38-114"><a href="#cb38-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-115"><a href="#cb38-115" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Salvar cópia dos parâmetros para validação</span></span>
<span id="cb38-116"><a href="#cb38-116" aria-hidden="true" tabindex="-1"></a>        best_val_state_cpu <span class="op">=</span> copy.deepcopy(model.state_dict())</span>
<span id="cb38-117"><a href="#cb38-117" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mover para CPU</span></span>
<span id="cb38-118"><a href="#cb38-118" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key <span class="kw">in</span> best_val_state_cpu:</span>
<span id="cb38-119"><a href="#cb38-119" aria-hidden="true" tabindex="-1"></a>            best_val_state_cpu[key] <span class="op">=</span> best_val_state_cpu[key].cpu()</span>
<span id="cb38-120"><a href="#cb38-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-121"><a href="#cb38-121" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Iteração </span><span class="sc">{</span>it<span class="sc">:3d}</span><span class="ss"> | Treino = </span><span class="sc">{</span>train_loss_avg<span class="sc">:.6f}</span><span class="ss"> | Val = </span><span class="sc">{</span>val_loss_avg<span class="sc">:.6f}</span><span class="ss"> | ★ MELHOROU </span><span class="sc">{</span>improvement<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb38-122"><a href="#cb38-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb38-123"><a href="#cb38-123" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sem melhoria</span></span>
<span id="cb38-124"><a href="#cb38-124" aria-hidden="true" tabindex="-1"></a>        no_improvement_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb38-125"><a href="#cb38-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> it <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span>:  <span class="co"># Print a cada 5 iterações sem melhoria</span></span>
<span id="cb38-126"><a href="#cb38-126" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Iteração </span><span class="sc">{</span>it<span class="sc">:3d}</span><span class="ss"> | Treino = </span><span class="sc">{</span>train_loss_avg<span class="sc">:.6f}</span><span class="ss"> | Val = </span><span class="sc">{</span>val_loss_avg<span class="sc">:.6f}</span><span class="ss"> | Sem melhoria há </span><span class="sc">{</span>no_improvement_count<span class="sc">}</span><span class="ss"> iterações"</span>)</span>
<span id="cb38-127"><a href="#cb38-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-128"><a href="#cb38-128" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ATUALIZAR MELHOR TREINO (apenas para informação)</span></span>
<span id="cb38-129"><a href="#cb38-129" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train_loss_avg <span class="op">&lt;</span> best_train_loss:</span>
<span id="cb38-130"><a href="#cb38-130" aria-hidden="true" tabindex="-1"></a>        best_train_loss <span class="op">=</span> train_loss_avg</span>
<span id="cb38-131"><a href="#cb38-131" aria-hidden="true" tabindex="-1"></a>        best_train_val_loss <span class="op">=</span> val_loss_avg</span>
<span id="cb38-132"><a href="#cb38-132" aria-hidden="true" tabindex="-1"></a>        best_train_iter <span class="op">=</span> it</span>
<span id="cb38-133"><a href="#cb38-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-134"><a href="#cb38-134" aria-hidden="true" tabindex="-1"></a>    <span class="co"># VERIFICAR EARLY STOPPING</span></span>
<span id="cb38-135"><a href="#cb38-135" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> no_improvement_count <span class="op">&gt;=</span> patience:</span>
<span id="cb38-136"><a href="#cb38-136" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">EARLY STOPPING ATIVADO - Sem melhoria há </span><span class="sc">{</span>patience<span class="sc">}</span><span class="ss"> iterações"</span>)</span>
<span id="cb38-137"><a href="#cb38-137" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"   Melhor loss: </span><span class="sc">{</span>best_val_loss<span class="sc">:.6f}</span><span class="ss"> na iteração </span><span class="sc">{</span>best_val_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-138"><a href="#cb38-138" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb38-139"><a href="#cb38-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-140"><a href="#cb38-140" aria-hidden="true" tabindex="-1"></a><span class="co"># Se completou todas as iterações sem early stopping</span></span>
<span id="cb38-141"><a href="#cb38-141" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> no_improvement_count <span class="op">&lt;</span> patience:</span>
<span id="cb38-142"><a href="#cb38-142" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Treinamento completo - </span><span class="sc">{</span>num_iters<span class="sc">}</span><span class="ss"> iterações realizadas"</span>)</span>
<span id="cb38-143"><a href="#cb38-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-144"><a href="#cb38-144" aria-hidden="true" tabindex="-1"></a><span class="co"># --- RESULTADO FINAL ---</span></span>
<span id="cb38-145"><a href="#cb38-145" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb38-146"><a href="#cb38-146" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESULTADO FINAL (XAVIER + ADAM + EARLY STOPPING)"</span>)</span>
<span id="cb38-147"><a href="#cb38-147" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb38-148"><a href="#cb38-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-149"><a href="#cb38-149" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Configuração: Adam(lr=</span><span class="sc">{</span>learning_rate<span class="sc">}</span><span class="ss">, wd=</span><span class="sc">{</span>weight_decay<span class="sc">}</span><span class="ss">), Early Stopping(patience=</span><span class="sc">{</span>patience<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb38-150"><a href="#cb38-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-151"><a href="#cb38-151" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)"</span>)</span>
<span id="cb38-152"><a href="#cb38-152" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de validação: </span><span class="sc">{</span>best_val_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-153"><a href="#cb38-153" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino nessa iteração:  </span><span class="sc">{</span>best_val_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb38-154"><a href="#cb38-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação: </span><span class="sc">{</span>best_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb38-155"><a href="#cb38-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-156"><a href="#cb38-156" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MELHOR TREINO (APENAS INFORMAÇÃO)"</span>)</span>
<span id="cb38-157"><a href="#cb38-157" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor iteração de treino: </span><span class="sc">{</span>best_train_iter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-158"><a href="#cb38-158" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de treino: </span><span class="sc">{</span>best_train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb38-159"><a href="#cb38-159" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss de validação nessa iteração: </span><span class="sc">{</span>best_train_val_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb38-160"><a href="#cb38-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-161"><a href="#cb38-161" aria-hidden="true" tabindex="-1"></a><span class="co"># Carregar os parâmetros da MELHOR VALIDAÇÃO no modelo</span></span>
<span id="cb38-162"><a href="#cb38-162" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_val_state_cpu <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb38-163"><a href="#cb38-163" aria-hidden="true" tabindex="-1"></a>    model.load_state_dict(best_val_state_cpu)</span>
<span id="cb38-164"><a href="#cb38-164" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros da MELHOR VALIDAÇÃO carregados no modelo"</span>)</span>
<span id="cb38-165"><a href="#cb38-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-166"><a href="#cb38-166" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar parâmetros finais (da melhor validação) na ORDEM CORRETA</span></span>
<span id="cb38-167"><a href="#cb38-167" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:"</span>)</span>
<span id="cb38-168"><a href="#cb38-168" aria-hidden="true" tabindex="-1"></a>melhores_parametros <span class="op">=</span> extrair_parametros_na_ordem(model)</span>
<span id="cb38-169"><a href="#cb38-169" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"["</span> <span class="op">+</span> <span class="st">" "</span>.join(<span class="ss">f"</span><span class="sc">{</span>p<span class="sc">:.8f}</span><span class="ss">"</span> <span class="cf">for</span> p <span class="kw">in</span> melhores_parametros) <span class="op">+</span> <span class="st">"]"</span>)</span>
<span id="cb38-170"><a href="#cb38-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-171"><a href="#cb38-171" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar formato detalhado</span></span>
<span id="cb38-172"><a href="#cb38-172" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Detalhado:"</span>)</span>
<span id="cb38-173"><a href="#cb38-173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w1, w2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">0</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">1</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb38-174"><a href="#cb38-174" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w3, w4: </span><span class="sc">{</span>melhores_parametros[<span class="dv">2</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">3</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb38-175"><a href="#cb38-175" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  w5, w6: </span><span class="sc">{</span>melhores_parametros[<span class="dv">4</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">5</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb38-176"><a href="#cb38-176" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b1, b2: </span><span class="sc">{</span>melhores_parametros[<span class="dv">6</span>]<span class="sc">:.8f}</span><span class="ss">, </span><span class="sc">{</span>melhores_parametros[<span class="dv">7</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span>
<span id="cb38-177"><a href="#cb38-177" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  b3:     </span><span class="sc">{</span>melhores_parametros[<span class="dv">8</span>]<span class="sc">:.8f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
INICIALIZAÇÃO XAVIER

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial: 707.134098
Primeira previsão: -0.531267
Primeiro target: 35.120982

INICIANDO TREINO COM ADAM + EARLY STOPPING
Usando Adam com learning_rate = 0.7, weight_decay = 0.001
Early Stopping: parará após 15 iterações sem melhoria
Máximo de iterações: 200
Iteração   0 | Treino = 707.134098 | Val = 656.897154 | ★ MELHOROU inf
Iteração   1 | Treino = 645.501222 | Val = 604.225076 | ★ MELHOROU 52.672078
Iteração   2 | Treino = 593.317315 | Val = 554.323129 | ★ MELHOROU 49.901947
Iteração   3 | Treino = 544.051605 | Val = 506.484504 | ★ MELHOROU 47.838625
Iteração   4 | Treino = 496.893113 | Val = 459.831088 | ★ MELHOROU 46.653416
Iteração   5 | Treino = 450.815550 | Val = 413.811468 | ★ MELHOROU 46.019621
Iteração   6 | Treino = 405.359450 | Val = 370.459376 | ★ MELHOROU 43.352091
Iteração   7 | Treino = 362.490745 | Val = 333.725185 | ★ MELHOROU 36.734191
Iteração   8 | Treino = 326.266658 | Val = 304.873630 | ★ MELHOROU 28.851556
Iteração   9 | Treino = 297.916121 | Val = 280.875971 | ★ MELHOROU 23.997659
Iteração  10 | Treino = 274.320831 | Val = 260.500513 | ★ MELHOROU 20.375457
Iteração  11 | Treino = 254.249578 | Val = 243.587806 | ★ MELHOROU 16.912707
Iteração  12 | Treino = 237.574732 | Val = 229.852391 | ★ MELHOROU 13.735415
Iteração  13 | Treino = 224.123144 | Val = 218.682713 | ★ MELHOROU 11.169678
Iteração  14 | Treino = 213.382002 | Val = 209.628202 | ★ MELHOROU 9.054511
Iteração  15 | Treino = 204.806475 | Val = 202.563602 | ★ MELHOROU 7.064601
Iteração  16 | Treino = 198.165398 | Val = 197.570936 | ★ MELHOROU 4.992665
Iteração  17 | Treino = 193.408294 | Val = 194.769498 | ★ MELHOROU 2.801438
Iteração  18 | Treino = 190.612749 | Val = 193.802219 | ★ MELHOROU 0.967279
Iteração  20 | Treino = 190.044681 | Val = 193.868310 | Sem melhoria há 2 iterações
Iteração  21 | Treino = 190.167215 | Val = 192.865620 | ★ MELHOROU 0.936599
Iteração  22 | Treino = 189.301872 | Val = 190.847417 | ★ MELHOROU 2.018203
Iteração  23 | Treino = 187.445203 | Val = 188.201997 | ★ MELHOROU 2.645420
Iteração  24 | Treino = 184.946548 | Val = 185.267496 | ★ MELHOROU 2.934501
Iteração  25 | Treino = 182.131299 | Val = 182.229760 | ★ MELHOROU 3.037736
Iteração  26 | Treino = 179.192101 | Val = 179.216727 | ★ MELHOROU 3.013033
Iteração  27 | Treino = 176.178814 | Val = 176.197410 | ★ MELHOROU 3.019317
Iteração  28 | Treino = 173.065244 | Val = 173.065530 | ★ MELHOROU 3.131880
Iteração  29 | Treino = 169.843498 | Val = 169.814672 | ★ MELHOROU 3.250858
Iteração  30 | Treino = 166.565084 | Val = 166.524602 | ★ MELHOROU 3.290070
Iteração  31 | Treino = 163.291878 | Val = 163.296485 | ★ MELHOROU 3.228117
Iteração  32 | Treino = 160.063515 | Val = 160.196666 | ★ MELHOROU 3.099819
Iteração  33 | Treino = 156.900794 | Val = 157.175173 | ★ MELHOROU 3.021493
Iteração  34 | Treino = 153.798938 | Val = 154.102599 | ★ MELHOROU 3.072574
Iteração  35 | Treino = 150.732831 | Val = 150.916971 | ★ MELHOROU 3.185628
Iteração  36 | Treino = 147.657875 | Val = 147.660891 | ★ MELHOROU 3.256080
Iteração  37 | Treino = 144.522462 | Val = 144.283727 | ★ MELHOROU 3.377165
Iteração  38 | Treino = 141.275947 | Val = 140.758815 | ★ MELHOROU 3.524911
Iteração  39 | Treino = 137.906861 | Val = 137.256861 | ★ MELHOROU 3.501955
Iteração  40 | Treino = 134.458005 | Val = 133.724311 | ★ MELHOROU 3.532550
Iteração  41 | Treino = 130.938946 | Val = 130.123232 | ★ MELHOROU 3.601079
Iteração  42 | Treino = 127.448306 | Val = 126.649507 | ★ MELHOROU 3.473725
Iteração  43 | Treino = 124.144718 | Val = 123.577504 | ★ MELHOROU 3.072003
Iteração  44 | Treino = 121.264854 | Val = 121.247538 | ★ MELHOROU 2.329966
Iteração  45 | Treino = 119.000584 | Val = 119.613455 | ★ MELHOROU 1.634083
Iteração  46 | Treino = 117.346131 | Val = 118.490832 | ★ MELHOROU 1.122623
Iteração  47 | Treino = 116.162283 | Val = 117.616243 | ★ MELHOROU 0.874589
Iteração  48 | Treino = 115.262596 | Val = 116.813313 | ★ MELHOROU 0.802931
Iteração  49 | Treino = 114.463869 | Val = 115.934418 | ★ MELHOROU 0.878894
Iteração  50 | Treino = 113.641436 | Val = 114.924043 | ★ MELHOROU 1.010375
Iteração  51 | Treino = 112.729857 | Val = 113.794645 | ★ MELHOROU 1.129399
Iteração  52 | Treino = 111.716776 | Val = 112.590320 | ★ MELHOROU 1.204325
Iteração  53 | Treino = 110.629711 | Val = 111.373454 | ★ MELHOROU 1.216866
Iteração  54 | Treino = 109.523955 | Val = 110.213438 | ★ MELHOROU 1.160016
Iteração  55 | Treino = 108.466783 | Val = 109.177026 | ★ MELHOROU 1.036411
Iteração  56 | Treino = 107.523009 | Val = 108.320356 | ★ MELHOROU 0.856671
Iteração  57 | Treino = 106.746047 | Val = 107.676605 | ★ MELHOROU 0.643751
Iteração  58 | Treino = 106.171475 | Val = 107.249475 | ★ MELHOROU 0.427129
Iteração  59 | Treino = 105.808917 | Val = 107.017590 | ★ MELHOROU 0.231885
Iteração  60 | Treino = 105.639928 | Val = 106.942895 | ★ MELHOROU 0.074695
Iteração  65 | Treino = 106.115413 | Val = 107.272517 | Sem melhoria há 5 iterações
Iteração  69 | Treino = 105.955794 | Val = 106.839616 | ★ MELHOROU 0.103278
Iteração  70 | Treino = 105.778174 | Val = 106.641619 | ★ MELHOROU 0.197997
Iteração  71 | Treino = 105.570557 | Val = 106.428808 | ★ MELHOROU 0.212811
Iteração  72 | Treino = 105.344131 | Val = 106.203091 | ★ MELHOROU 0.225717
Iteração  73 | Treino = 105.103507 | Val = 105.958393 | ★ MELHOROU 0.244698
Iteração  74 | Treino = 104.845109 | Val = 105.680649 | ★ MELHOROU 0.277744
Iteração  75 | Treino = 104.557285 | Val = 105.349756 | ★ MELHOROU 0.330893
Iteração  76 | Treino = 104.221600 | Val = 104.948650 | ★ MELHOROU 0.401106
Iteração  77 | Treino = 103.816492 | Val = 104.472166 | ★ MELHOROU 0.476484
Iteração  78 | Treino = 103.326704 | Val = 103.926073 | ★ MELHOROU 0.546093
Iteração  79 | Treino = 102.760650 | Val = 103.355577 | ★ MELHOROU 0.570495
Iteração  80 | Treino = 102.164044 | Val = 102.841489 | ★ MELHOROU 0.514089
Iteração  81 | Treino = 101.613667 | Val = 102.452744 | ★ MELHOROU 0.388744
Iteração  82 | Treino = 101.204251 | Val = 102.227845 | ★ MELHOROU 0.224899
Iteração  83 | Treino = 100.969982 | Val = 102.071835 | ★ MELHOROU 0.156010
Iteração  84 | Treino = 100.801800 | Val = 101.827341 | ★ MELHOROU 0.244493
Iteração  85 | Treino = 100.549629 | Val = 101.383680 | ★ MELHOROU 0.443661
Iteração  86 | Treino = 100.105344 | Val = 100.706384 | ★ MELHOROU 0.677296
Iteração  87 | Treino = 99.434188 | Val = 99.886487 | ★ MELHOROU 0.819897
Iteração  88 | Treino = 98.621275 | Val = 99.139378 | ★ MELHOROU 0.747109
Iteração  89 | Treino = 97.881389 | Val = 98.578323 | ★ MELHOROU 0.561055
Iteração  90 | Treino = 97.340989 | Val = 98.088932 | ★ MELHOROU 0.489391
Iteração  91 | Treino = 96.893551 | Val = 97.522301 | ★ MELHOROU 0.566631
Iteração  92 | Treino = 96.375403 | Val = 96.813460 | ★ MELHOROU 0.708841
Iteração  93 | Treino = 95.707514 | Val = 96.001071 | ★ MELHOROU 0.812390
Iteração  94 | Treino = 94.922672 | Val = 95.193316 | ★ MELHOROU 0.807755
Iteração  95 | Treino = 94.119820 | Val = 94.485203 | ★ MELHOROU 0.708112
Iteração  96 | Treino = 93.392409 | Val = 93.889968 | ★ MELHOROU 0.595235
Iteração  97 | Treino = 92.774999 | Val = 93.377960 | ★ MELHOROU 0.512008
Iteração  98 | Treino = 92.263547 | Val = 92.925994 | ★ MELHOROU 0.451966
Iteração  99 | Treino = 91.826809 | Val = 92.460783 | ★ MELHOROU 0.465211
Iteração 100 | Treino = 91.356434 | Val = 91.856230 | ★ MELHOROU 0.604553
Iteração 101 | Treino = 90.710738 | Val = 91.090839 | ★ MELHOROU 0.765391
Iteração 102 | Treino = 89.875561 | Val = 90.358646 | ★ MELHOROU 0.732192
Iteração 103 | Treino = 89.071568 | Val = 89.827615 | ★ MELHOROU 0.531032
Iteração 104 | Treino = 88.497620 | Val = 89.434533 | ★ MELHOROU 0.393081
Iteração 105 | Treino = 88.091561 | Val = 89.011553 | ★ MELHOROU 0.422981
Iteração 106 | Treino = 87.667668 | Val = 88.445311 | ★ MELHOROU 0.566242
Iteração 107 | Treino = 87.098551 | Val = 87.741825 | ★ MELHOROU 0.703486
Iteração 108 | Treino = 86.385343 | Val = 87.049036 | ★ MELHOROU 0.692788
Iteração 109 | Treino = 85.685899 | Val = 86.546076 | ★ MELHOROU 0.502960
Iteração 110 | Treino = 85.192095 | Val = 86.159566 | ★ MELHOROU 0.386511
Iteração 111 | Treino = 84.818159 | Val = 85.662583 | ★ MELHOROU 0.496983
Iteração 112 | Treino = 84.322719 | Val = 85.046548 | ★ MELHOROU 0.616035
Iteração 113 | Treino = 83.697937 | Val = 84.482801 | ★ MELHOROU 0.563746
Iteração 114 | Treino = 83.124165 | Val = 84.054388 | ★ MELHOROU 0.428413
Iteração 115 | Treino = 82.695467 | Val = 83.650574 | ★ MELHOROU 0.403814
Iteração 116 | Treino = 82.297926 | Val = 83.153269 | ★ MELHOROU 0.497305
Iteração 117 | Treino = 81.805697 | Val = 82.588657 | ★ MELHOROU 0.564612
Iteração 118 | Treino = 81.249465 | Val = 82.083902 | ★ MELHOROU 0.504755
Iteração 119 | Treino = 80.764136 | Val = 81.683344 | ★ MELHOROU 0.400558
Iteração 120 | Treino = 80.386594 | Val = 81.272298 | ★ MELHOROU 0.411046
Iteração 121 | Treino = 79.989068 | Val = 80.793671 | ★ MELHOROU 0.478627
Iteração 122 | Treino = 79.511714 | Val = 80.354826 | ★ MELHOROU 0.438844
Iteração 123 | Treino = 79.069243 | Val = 80.002454 | ★ MELHOROU 0.352373
Iteração 124 | Treino = 78.718358 | Val = 79.643075 | ★ MELHOROU 0.359379
Iteração 125 | Treino = 78.365469 | Val = 79.221743 | ★ MELHOROU 0.421332
Iteração 126 | Treino = 77.951746 | Val = 78.811326 | ★ MELHOROU 0.410417
Iteração 127 | Treino = 77.551709 | Val = 78.468064 | ★ MELHOROU 0.343262
Iteração 128 | Treino = 77.218560 | Val = 78.130197 | ★ MELHOROU 0.337867
Iteração 129 | Treino = 76.883846 | Val = 77.757667 | ★ MELHOROU 0.372531
Iteração 130 | Treino = 76.506930 | Val = 77.415445 | ★ MELHOROU 0.342221
Iteração 131 | Treino = 76.158677 | Val = 77.123450 | ★ MELHOROU 0.291996
Iteração 132 | Treino = 75.864220 | Val = 76.809503 | ★ MELHOROU 0.313947
Iteração 133 | Treino = 75.550701 | Val = 76.472251 | ★ MELHOROU 0.337252
Iteração 134 | Treino = 75.217379 | Val = 76.172073 | ★ MELHOROU 0.300178
Iteração 135 | Treino = 74.925611 | Val = 75.886080 | ★ MELHOROU 0.285993
Iteração 136 | Treino = 74.648518 | Val = 75.575803 | ★ MELHOROU 0.310277
Iteração 137 | Treino = 74.343940 | Val = 75.281623 | ★ MELHOROU 0.294180
Iteração 138 | Treino = 74.052141 | Val = 75.018273 | ★ MELHOROU 0.263351
Iteração 139 | Treino = 73.791063 | Val = 74.738926 | ★ MELHOROU 0.279347
Iteração 140 | Treino = 73.517781 | Val = 74.450566 | ★ MELHOROU 0.288360
Iteração 141 | Treino = 73.240308 | Val = 74.191747 | ★ MELHOROU 0.258819
Iteração 142 | Treino = 72.991944 | Val = 73.938305 | ★ MELHOROU 0.253442
Iteração 143 | Treino = 72.741458 | Val = 73.682682 | ★ MELHOROU 0.255623
Iteração 144 | Treino = 72.480539 | Val = 73.450124 | ★ MELHOROU 0.232558
Iteração 145 | Treino = 72.240840 | Val = 73.215684 | ★ MELHOROU 0.234440
Iteração 146 | Treino = 72.004393 | Val = 72.966652 | ★ MELHOROU 0.249032
Iteração 147 | Treino = 71.759135 | Val = 72.730751 | ★ MELHOROU 0.235901
Iteração 148 | Treino = 71.528044 | Val = 72.503052 | ★ MELHOROU 0.227699
Iteração 149 | Treino = 71.302337 | Val = 72.268860 | ★ MELHOROU 0.234192
Iteração 150 | Treino = 71.068127 | Val = 72.044080 | ★ MELHOROU 0.224780
Iteração 151 | Treino = 70.844500 | Val = 71.820042 | ★ MELHOROU 0.224038
Iteração 152 | Treino = 70.625223 | Val = 71.585666 | ★ MELHOROU 0.234376
Iteração 153 | Treino = 70.399281 | Val = 71.360106 | ★ MELHOROU 0.225559
Iteração 154 | Treino = 70.182987 | Val = 71.138268 | ★ MELHOROU 0.221839
Iteração 155 | Treino = 69.966905 | Val = 70.917595 | ★ MELHOROU 0.220672
Iteração 156 | Treino = 69.746152 | Val = 70.706931 | ★ MELHOROU 0.210664
Iteração 157 | Treino = 69.532281 | Val = 70.490333 | ★ MELHOROU 0.216598
Iteração 158 | Treino = 69.315325 | Val = 70.268912 | ★ MELHOROU 0.221421
Iteração 159 | Treino = 69.097501 | Val = 70.053461 | ★ MELHOROU 0.215451
Iteração 160 | Treino = 68.884839 | Val = 69.835968 | ★ MELHOROU 0.217493
Iteração 161 | Treino = 68.666933 | Val = 69.619760 | ★ MELHOROU 0.216208
Iteração 162 | Treino = 68.450903 | Val = 69.398321 | ★ MELHOROU 0.221439
Iteração 163 | Treino = 68.234726 | Val = 69.169738 | ★ MELHOROU 0.228582
Iteração 164 | Treino = 68.014949 | Val = 68.945600 | ★ MELHOROU 0.224138
Iteração 165 | Treino = 67.798576 | Val = 68.720992 | ★ MELHOROU 0.224608
Iteração 166 | Treino = 67.579562 | Val = 68.498620 | ★ MELHOROU 0.222372
Iteração 167 | Treino = 67.361669 | Val = 68.277347 | ★ MELHOROU 0.221273
Iteração 168 | Treino = 67.144734 | Val = 68.054808 | ★ MELHOROU 0.222538
Iteração 169 | Treino = 66.927487 | Val = 67.836092 | ★ MELHOROU 0.218717
Iteração 170 | Treino = 66.715081 | Val = 67.619244 | ★ MELHOROU 0.216847
Iteração 171 | Treino = 66.504268 | Val = 67.409915 | ★ MELHOROU 0.209329
Iteração 172 | Treino = 66.301184 | Val = 67.203906 | ★ MELHOROU 0.206010
Iteração 173 | Treino = 66.104284 | Val = 67.006867 | ★ MELHOROU 0.197038
Iteração 174 | Treino = 65.918129 | Val = 66.822778 | ★ MELHOROU 0.184089
Iteração 175 | Treino = 65.743717 | Val = 66.654105 | ★ MELHOROU 0.168673
Iteração 176 | Treino = 65.584456 | Val = 66.500728 | ★ MELHOROU 0.153377
Iteração 177 | Treino = 65.441534 | Val = 66.365048 | ★ MELHOROU 0.135680
Iteração 178 | Treino = 65.315434 | Val = 66.246725 | ★ MELHOROU 0.118323
Iteração 179 | Treino = 65.205657 | Val = 66.142725 | ★ MELHOROU 0.104000
Iteração 180 | Treino = 65.110321 | Val = 66.048916 | ★ MELHOROU 0.093810
Iteração 181 | Treino = 65.023810 | Val = 65.960592 | ★ MELHOROU 0.088324
Iteração 182 | Treino = 64.941625 | Val = 65.868488 | ★ MELHOROU 0.092103
Iteração 183 | Treino = 64.856249 | Val = 65.771386 | ★ MELHOROU 0.097103
Iteração 184 | Treino = 64.764485 | Val = 65.666520 | ★ MELHOROU 0.104866
Iteração 185 | Treino = 64.662271 | Val = 65.553939 | ★ MELHOROU 0.112581
Iteração 186 | Treino = 64.551000 | Val = 65.436441 | ★ MELHOROU 0.117498
Iteração 187 | Treino = 64.433119 | Val = 65.317389 | ★ MELHOROU 0.119052
Iteração 188 | Treino = 64.312636 | Val = 65.200422 | ★ MELHOROU 0.116967
Iteração 189 | Treino = 64.194413 | Val = 65.088112 | ★ MELHOROU 0.112310
Iteração 190 | Treino = 64.080929 | Val = 64.983755 | ★ MELHOROU 0.104356
Iteração 191 | Treino = 63.975057 | Val = 64.888479 | ★ MELHOROU 0.095276
Iteração 192 | Treino = 63.876919 | Val = 64.800437 | ★ MELHOROU 0.088043
Iteração 193 | Treino = 63.785971 | Val = 64.718291 | ★ MELHOROU 0.082145
Iteração 194 | Treino = 63.701529 | Val = 64.640568 | ★ MELHOROU 0.077724
Iteração 195 | Treino = 63.621507 | Val = 64.564699 | ★ MELHOROU 0.075869
Iteração 196 | Treino = 63.544787 | Val = 64.490129 | ★ MELHOROU 0.074570
Iteração 197 | Treino = 63.469947 | Val = 64.415915 | ★ MELHOROU 0.074214
Iteração 198 | Treino = 63.395716 | Val = 64.341362 | ★ MELHOROU 0.074553
Iteração 199 | Treino = 63.321766 | Val = 64.265996 | ★ MELHOROU 0.075366

✅ Treinamento completo - 200 iterações realizadas

============================================================
RESULTADO FINAL (XAVIER + ADAM + EARLY STOPPING)
============================================================

Configuração: Adam(lr=0.7, wd=0.001), Early Stopping(patience=15)

MELHOR VALIDAÇÃO (PARÂMETROS FINAIS)
Melhor iteração de validação: 199
Loss de treino nessa iteração:  63.321766
Loss de validação: 64.265996

MELHOR TREINO (APENAS INFORMAÇÃO)
Melhor iteração de treino: 199
Loss de treino: 63.321766
Loss de validação nessa iteração: 64.265996

Parâmetros da MELHOR VALIDAÇÃO carregados no modelo

Parâmetros finais PyTorch (melhor validação) - ORDEM CORRETA:
[1.17921496 -5.24012473 -1.34184329 -5.32289458 28.81818666 -23.53624641 -3.74923194 -12.19418300 13.81089384]

Detalhado:
  w1, w2: 1.17921496, -5.24012473
  w3, w4: -1.34184329, -5.32289458
  w5, w6: 28.81818666, -23.53624641
  b1, b2: -3.74923194, -12.19418300
  b3:     13.81089384</code></pre>
</div>
</div>
<p>Tracking de resultados até o momento:</p>
<ul>
<li>Inicialização com zeros e Full Gradiente Descendente</li>
</ul>
<pre><code>Melhor loss de validação: 149.400522  

Parâmetros
w1, w2: -0.75778832, -2.40989992
w3, w4: -0.75778832, -2.40989992
w5, w6: 8.22808010, 8.22808010
b1, b2: 2.17300733, 2.17300733
b3:     11.38825398</code></pre>
<ul>
<li>Inicialização Xavier e Full Gradiente Descendente</li>
</ul>
<pre><code>Melhor loss de validação: 96.597687

w1, w2: 1.71651571, -6.81702601
w3, w4: -1.61371955, -2.89382036
w5, w6: 17.37388061, 9.09587648
b1, b2: -4.12289796, 5.78382848
b3:     7.62424542</code></pre>
<ul>
<li>Inicialização Xavier + SGD (0.01)</li>
</ul>
<pre><code>Melhor loss de validação: 86.270252</code></pre>
<ul>
<li>Inicialização Xavier + ADAM (0.04) + Early Stopping (199)</li>
</ul>
<pre><code>Melhor loss de validação: 64.265996</code></pre>
</section>
<section id="otimização-de-hiperparâmetros" class="level2">
<h2 class="anchored" data-anchor-id="otimização-de-hiperparâmetros">Otimização de hiperparâmetros</h2>
<div id="cell-46" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;f2f796d94bac41d4964f0375270096a7&quot;,&quot;7045de7ab8a54abfa8285dbe89cb3467&quot;,&quot;ba20a2745bd24c9e9f5b5a7b5bbed3b5&quot;,&quot;53efc12449474f03b5567e25c35f919a&quot;,&quot;b8be720392364da2aa0bf43bb9e76148&quot;,&quot;9ca44fa2da0c4f76a7a9bb4d218fd3c9&quot;,&quot;f5649942660d4ffebc77ee7fe087a3f5&quot;,&quot;2f50d677c1fb4e2089428474a4496ba6&quot;,&quot;24a41c93313a430da57493aa5cc9fb9b&quot;,&quot;fd65aa8df4c946b79f2251f18679cd87&quot;,&quot;0671e859162c49ca8242b9052cd5d000&quot;]}}" data-outputid="ef18cd58-d1c8-4991-d775-40a52be2747d">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>torch.cuda.manual_seed(seed)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>torch.cuda.manual_seed_all(seed)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(seed)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>random.seed(seed)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">False</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># SUGERIR HIPERPARÂMETROS</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    lr <span class="op">=</span> trial.suggest_float(<span class="st">'lr'</span>, <span class="fl">1e-5</span>, <span class="fl">1e-1</span>, log<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    weight_decay <span class="op">=</span> trial.suggest_float(<span class="st">'weight_decay'</span>, <span class="fl">1e-6</span>, <span class="fl">1e-1</span>, log<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    hidden_size <span class="op">=</span> trial.suggest_categorical(<span class="st">'hidden_size'</span>, [<span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">256</span>, <span class="dv">512</span>])</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    n_layers <span class="op">=</span> trial.suggest_int(<span class="st">'n_layers'</span>, <span class="dv">1</span>, <span class="dv">5</span>)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    dropout_rate <span class="op">=</span> trial.suggest_float(<span class="st">'dropout_rate'</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>)</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">class</span> DynamicNet(nn.Module):</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size<span class="op">=</span><span class="dv">2</span>, hidden_size<span class="op">=</span>hidden_size, n_layers<span class="op">=</span>n_layers, dropout_rate<span class="op">=</span>dropout_rate):</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>            <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>            layers <span class="op">=</span> []</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>            prev_size <span class="op">=</span> input_size</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_layers):</span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>                layers.extend([</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>                    nn.Linear(prev_size, hidden_size),</span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>                    nn.ReLU(),</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>                    nn.Dropout(dropout_rate)</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>                ])</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>                prev_size <span class="op">=</span> hidden_size</span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>            layers.append(nn.Linear(prev_size, <span class="dv">1</span>))</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.network(x)</span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TREINAR E AVALIAR</span></span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> DynamicNet().double().to(device)</span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a>    X_tensor <span class="op">=</span> torch.tensor(x_treino, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a>    y_tensor <span class="op">=</span> torch.tensor(y_treino, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a>    X_val_tensor <span class="op">=</span> torch.tensor(x_val, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a>    y_val_tensor <span class="op">=</span> torch.tensor(y_val, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>lr, weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb44-52"><a href="#cb44-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-53"><a href="#cb44-53" aria-hidden="true" tabindex="-1"></a>    best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb44-54"><a href="#cb44-54" aria-hidden="true" tabindex="-1"></a>    patience <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb44-55"><a href="#cb44-55" aria-hidden="true" tabindex="-1"></a>    no_improve <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb44-56"><a href="#cb44-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-57"><a href="#cb44-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb44-58"><a href="#cb44-58" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb44-59"><a href="#cb44-59" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb44-60"><a href="#cb44-60" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_tensor)</span>
<span id="cb44-61"><a href="#cb44-61" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_tensor)</span>
<span id="cb44-62"><a href="#cb44-62" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb44-63"><a href="#cb44-63" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb44-64"><a href="#cb44-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-65"><a href="#cb44-65" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb44-66"><a href="#cb44-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb44-67"><a href="#cb44-67" aria-hidden="true" tabindex="-1"></a>            y_val_pred <span class="op">=</span> model(X_val_tensor)</span>
<span id="cb44-68"><a href="#cb44-68" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">=</span> criterion(y_val_pred, y_val_tensor)</span>
<span id="cb44-69"><a href="#cb44-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-70"><a href="#cb44-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb44-71"><a href="#cb44-71" aria-hidden="true" tabindex="-1"></a>            best_val_loss <span class="op">=</span> val_loss</span>
<span id="cb44-72"><a href="#cb44-72" aria-hidden="true" tabindex="-1"></a>            no_improve <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb44-73"><a href="#cb44-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb44-74"><a href="#cb44-74" aria-hidden="true" tabindex="-1"></a>            no_improve <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb44-75"><a href="#cb44-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-76"><a href="#cb44-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> no_improve <span class="op">&gt;=</span> patience:</span>
<span id="cb44-77"><a href="#cb44-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb44-78"><a href="#cb44-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-79"><a href="#cb44-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_val_loss.item()</span>
<span id="cb44-80"><a href="#cb44-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-81"><a href="#cb44-81" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. EXECUTAR OTIMIZAÇÃO</span></span>
<span id="cb44-82"><a href="#cb44-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"INICIANDO OTIMIZAÇÃO BAYESIANA COM OPTUNA"</span>)</span>
<span id="cb44-83"><a href="#cb44-83" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(</span>
<span id="cb44-84"><a href="#cb44-84" aria-hidden="true" tabindex="-1"></a>    direction<span class="op">=</span><span class="st">'minimize'</span>,</span>
<span id="cb44-85"><a href="#cb44-85" aria-hidden="true" tabindex="-1"></a>    sampler<span class="op">=</span>optuna.samplers.TPESampler(),</span>
<span id="cb44-86"><a href="#cb44-86" aria-hidden="true" tabindex="-1"></a>    pruner<span class="op">=</span>optuna.pruners.HyperbandPruner()</span>
<span id="cb44-87"><a href="#cb44-87" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-88"><a href="#cb44-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-89"><a href="#cb44-89" aria-hidden="true" tabindex="-1"></a>study.optimize(objective, n_trials<span class="op">=</span><span class="dv">50</span>, show_progress_bar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-90"><a href="#cb44-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-91"><a href="#cb44-91" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. RESULTADOS</span></span>
<span id="cb44-92"><a href="#cb44-92" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb44-93"><a href="#cb44-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MELHORES HIPERPARÂMETROS ENCONTRADOS:"</span>)</span>
<span id="cb44-94"><a href="#cb44-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb44-95"><a href="#cb44-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-96"><a href="#cb44-96" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor trial: </span><span class="sc">{</span>study<span class="sc">.</span>best_trial<span class="sc">.</span>number<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-97"><a href="#cb44-97" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor loss de validação: </span><span class="sc">{</span>study<span class="sc">.</span>best_value<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb44-98"><a href="#cb44-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-99"><a href="#cb44-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Melhores parametros:"</span>)</span>
<span id="cb44-100"><a href="#cb44-100" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key, value <span class="kw">in</span> study.best_params.items():</span>
<span id="cb44-101"><a href="#cb44-101" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>key<span class="sc">:15}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-102"><a href="#cb44-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-103"><a href="#cb44-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-104"><a href="#cb44-104" aria-hidden="true" tabindex="-1"></a><span class="co">#TREINAR MODELO FINAL</span></span>
<span id="cb44-105"><a href="#cb44-105" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">TREINANDO MODELO FINAL COM OS MELHORES PARAMETROS..."</span>)</span>
<span id="cb44-106"><a href="#cb44-106" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> study.best_params</span>
<span id="cb44-107"><a href="#cb44-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-108"><a href="#cb44-108" aria-hidden="true" tabindex="-1"></a><span class="co">#Modelo final com melhores parametros</span></span>
<span id="cb44-109"><a href="#cb44-109" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FinalNet(nn.Module):</span>
<span id="cb44-110"><a href="#cb44-110" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size<span class="op">=</span><span class="dv">2</span>, hidden_size<span class="op">=</span>best_params[<span class="st">'hidden_size'</span>],</span>
<span id="cb44-111"><a href="#cb44-111" aria-hidden="true" tabindex="-1"></a>                 n_layers<span class="op">=</span>best_params[<span class="st">'n_layers'</span>], dropout_rate<span class="op">=</span>best_params[<span class="st">'dropout_rate'</span>]):</span>
<span id="cb44-112"><a href="#cb44-112" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb44-113"><a href="#cb44-113" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> []</span>
<span id="cb44-114"><a href="#cb44-114" aria-hidden="true" tabindex="-1"></a>        prev_size <span class="op">=</span> input_size</span>
<span id="cb44-115"><a href="#cb44-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-116"><a href="#cb44-116" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_layers):</span>
<span id="cb44-117"><a href="#cb44-117" aria-hidden="true" tabindex="-1"></a>            layers.extend([</span>
<span id="cb44-118"><a href="#cb44-118" aria-hidden="true" tabindex="-1"></a>                nn.Linear(prev_size, hidden_size),</span>
<span id="cb44-119"><a href="#cb44-119" aria-hidden="true" tabindex="-1"></a>                nn.ReLU(),</span>
<span id="cb44-120"><a href="#cb44-120" aria-hidden="true" tabindex="-1"></a>                nn.Dropout(dropout_rate)</span>
<span id="cb44-121"><a href="#cb44-121" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb44-122"><a href="#cb44-122" aria-hidden="true" tabindex="-1"></a>            prev_size <span class="op">=</span> hidden_size</span>
<span id="cb44-123"><a href="#cb44-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-124"><a href="#cb44-124" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.Linear(prev_size, <span class="dv">1</span>))</span>
<span id="cb44-125"><a href="#cb44-125" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb44-126"><a href="#cb44-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-127"><a href="#cb44-127" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb44-128"><a href="#cb44-128" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.network(x)</span>
<span id="cb44-129"><a href="#cb44-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-130"><a href="#cb44-130" aria-hidden="true" tabindex="-1"></a><span class="co"># Criar e treinar modelo final</span></span>
<span id="cb44-131"><a href="#cb44-131" aria-hidden="true" tabindex="-1"></a>model_final <span class="op">=</span> FinalNet().double().to(device)</span>
<span id="cb44-132"><a href="#cb44-132" aria-hidden="true" tabindex="-1"></a>optimizer_final <span class="op">=</span> torch.optim.Adam(</span>
<span id="cb44-133"><a href="#cb44-133" aria-hidden="true" tabindex="-1"></a>    model_final.parameters(),</span>
<span id="cb44-134"><a href="#cb44-134" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>best_params[<span class="st">'lr'</span>],</span>
<span id="cb44-135"><a href="#cb44-135" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span>best_params[<span class="st">'weight_decay'</span>]</span>
<span id="cb44-136"><a href="#cb44-136" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-137"><a href="#cb44-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-138"><a href="#cb44-138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Modelo final criado com sucesso!"</span>)</span>
<span id="cb44-139"><a href="#cb44-139" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Arquitetura: </span><span class="sc">{</span>best_params[<span class="st">'n_layers'</span>]<span class="sc">}</span><span class="ss"> camadas, </span><span class="sc">{</span>best_params[<span class="st">'hidden_size'</span>]<span class="sc">}</span><span class="ss"> neuronios"</span>)</span>
<span id="cb44-140"><a href="#cb44-140" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dropout: </span><span class="sc">{</span>best_params[<span class="st">'dropout_rate'</span>]<span class="sc">}</span><span class="ss">, LR: </span><span class="sc">{</span>best_params[<span class="st">'lr'</span>]<span class="sc">}</span><span class="ss">, WD: </span><span class="sc">{</span>best_params[<span class="st">'weight_decay'</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>🚀 INICIANDO OTIMIZAÇÃO BAYESIANA COM OPTUNA
Usando Processos Estocásticos para busca inteligente...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f2f796d94bac41d4964f0375270096a7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[I 2025-11-23 01:11:30,383] Trial 0 finished with value: 662.7231580437845 and parameters: {'lr': 0.00012599382015150677, 'weight_decay': 0.0017695579071883257, 'hidden_size': 64, 'n_layers': 2, 'dropout_rate': 0.2786433459779516}. Best is trial 0 with value: 662.7231580437845.
[I 2025-11-23 01:11:30,896] Trial 1 finished with value: 271.62874696941424 and parameters: {'lr': 0.03864149012499579, 'weight_decay': 0.06253363379209195, 'hidden_size': 64, 'n_layers': 4, 'dropout_rate': 0.15884881037758644}. Best is trial 1 with value: 271.62874696941424.
[I 2025-11-23 01:11:39,714] Trial 2 finished with value: 114.69323165192017 and parameters: {'lr': 0.0005861973600570069, 'weight_decay': 0.00037422073078600217, 'hidden_size': 128, 'n_layers': 3, 'dropout_rate': 0.15146867277292528}. Best is trial 2 with value: 114.69323165192017.
[I 2025-11-23 01:11:40,360] Trial 3 finished with value: 95.89862345622821 and parameters: {'lr': 0.021202810570388305, 'weight_decay': 1.2622420675928646e-05, 'hidden_size': 64, 'n_layers': 1, 'dropout_rate': 0.24969489962705974}. Best is trial 3 with value: 95.89862345622821.
[I 2025-11-23 01:11:41,541] Trial 4 finished with value: 687.4467667858665 and parameters: {'lr': 1.7887603661623283e-05, 'weight_decay': 9.724024333503987e-05, 'hidden_size': 32, 'n_layers': 2, 'dropout_rate': 0.3937386126084046}. Best is trial 3 with value: 95.89862345622821.
[I 2025-11-23 01:11:44,745] Trial 5 finished with value: 660.3229005794258 and parameters: {'lr': 0.0002213447203688942, 'weight_decay': 2.92773194482875e-05, 'hidden_size': 32, 'n_layers': 5, 'dropout_rate': 0.35349192229903736}. Best is trial 3 with value: 95.89862345622821.
[I 2025-11-23 01:11:45,419] Trial 6 finished with value: 116.02522938898048 and parameters: {'lr': 0.006814238445636355, 'weight_decay': 0.00013646963256732725, 'hidden_size': 64, 'n_layers': 1, 'dropout_rate': 0.4467181767891715}. Best is trial 3 with value: 95.89862345622821.
[I 2025-11-23 01:11:50,058] Trial 7 finished with value: 663.3789169576669 and parameters: {'lr': 1.2613586249598033e-05, 'weight_decay': 0.07693885948582334, 'hidden_size': 512, 'n_layers': 1, 'dropout_rate': 0.3367663063526962}. Best is trial 3 with value: 95.89862345622821.
[I 2025-11-23 01:11:52,932] Trial 8 finished with value: 285.51765076061014 and parameters: {'lr': 0.0003579764514005988, 'weight_decay': 3.246262031588693e-05, 'hidden_size': 64, 'n_layers': 3, 'dropout_rate': 0.4296947527996894}. Best is trial 3 with value: 95.89862345622821.
[I 2025-11-23 01:11:53,589] Trial 9 finished with value: 95.7192711447679 and parameters: {'lr': 0.027527150654447233, 'weight_decay': 0.0004513811490624018, 'hidden_size': 64, 'n_layers': 1, 'dropout_rate': 0.26943640543168257}. Best is trial 9 with value: 95.7192711447679.
[I 2025-11-23 01:12:10,267] Trial 10 finished with value: 68.02560522614084 and parameters: {'lr': 0.0039012360371798176, 'weight_decay': 1.500688001228173e-06, 'hidden_size': 256, 'n_layers': 2, 'dropout_rate': 0.2083754383621361}. Best is trial 10 with value: 68.02560522614084.
[I 2025-11-23 01:12:26,754] Trial 11 finished with value: 54.28551393327178 and parameters: {'lr': 0.005184955150354942, 'weight_decay': 1.0259259367942141e-06, 'hidden_size': 256, 'n_layers': 2, 'dropout_rate': 0.21582219896416183}. Best is trial 11 with value: 54.28551393327178.
[I 2025-11-23 01:12:43,122] Trial 12 finished with value: 73.5239017291592 and parameters: {'lr': 0.0031953318802539037, 'weight_decay': 1.6795877924082912e-06, 'hidden_size': 256, 'n_layers': 2, 'dropout_rate': 0.20705088911726838}. Best is trial 11 with value: 54.28551393327178.
[I 2025-11-23 01:12:59,481] Trial 13 finished with value: 90.35915118668628 and parameters: {'lr': 0.0023886824537715347, 'weight_decay': 1.7108185238956346e-06, 'hidden_size': 256, 'n_layers': 2, 'dropout_rate': 0.1069570661109362}. Best is trial 11 with value: 54.28551393327178.
[I 2025-11-23 01:13:43,762] Trial 14 finished with value: 14.102672525550782 and parameters: {'lr': 0.00763009194090056, 'weight_decay': 5.542630356377395e-06, 'hidden_size': 256, 'n_layers': 4, 'dropout_rate': 0.21280908279079366}. Best is trial 14 with value: 14.102672525550782.
[I 2025-11-23 01:13:49,522] Trial 15 finished with value: 199.40206521015872 and parameters: {'lr': 0.010490348160002884, 'weight_decay': 6.21928388450265e-06, 'hidden_size': 256, 'n_layers': 4, 'dropout_rate': 0.49913826039922593}. Best is trial 14 with value: 14.102672525550782.
[I 2025-11-23 01:14:33,915] Trial 16 finished with value: 44.82573076853326 and parameters: {'lr': 0.001037013043344349, 'weight_decay': 5.753634804769223e-06, 'hidden_size': 256, 'n_layers': 4, 'dropout_rate': 0.21500722862031305}. Best is trial 14 with value: 14.102672525550782.
[I 2025-11-23 01:14:50,373] Trial 17 finished with value: 628.6060215955904 and parameters: {'lr': 5.789536201399959e-05, 'weight_decay': 0.002845614901120097, 'hidden_size': 128, 'n_layers': 5, 'dropout_rate': 0.31065980845302066}. Best is trial 14 with value: 14.102672525550782.
[I 2025-11-23 01:17:47,839] Trial 18 finished with value: 9.923652949137228 and parameters: {'lr': 0.0012782314478058804, 'weight_decay': 5.071206793426592e-06, 'hidden_size': 512, 'n_layers': 4, 'dropout_rate': 0.15658205493421604}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:18:10,853] Trial 19 finished with value: 691.0228346468448 and parameters: {'lr': 0.0850834009258904, 'weight_decay': 6.994365965303051e-06, 'hidden_size': 512, 'n_layers': 4, 'dropout_rate': 0.14374299359260104}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:22:05,434] Trial 20 finished with value: 21.533057478797357 and parameters: {'lr': 0.0013631471648751366, 'weight_decay': 2.8492343332815124e-05, 'hidden_size': 512, 'n_layers': 5, 'dropout_rate': 0.12562205926169712}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:26:00,210] Trial 21 finished with value: 26.192082268234724 and parameters: {'lr': 0.0016526814730509533, 'weight_decay': 2.5528731064286744e-05, 'hidden_size': 512, 'n_layers': 5, 'dropout_rate': 0.12020125126247587}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:29:55,093] Trial 22 finished with value: 15.725249565877917 and parameters: {'lr': 0.0008340629944887506, 'weight_decay': 0.00011109685721998665, 'hidden_size': 512, 'n_layers': 5, 'dropout_rate': 0.16627957609413477}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:32:52,687] Trial 23 finished with value: 32.70355113306641 and parameters: {'lr': 0.0006434697841547095, 'weight_decay': 8.685129367229152e-05, 'hidden_size': 512, 'n_layers': 4, 'dropout_rate': 0.1847858632736283}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:33:20,817] Trial 24 finished with value: 560.5264009883372 and parameters: {'lr': 0.01177719239580189, 'weight_decay': 0.0009870319617601541, 'hidden_size': 512, 'n_layers': 5, 'dropout_rate': 0.18003844839376082}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:36:18,747] Trial 25 finished with value: 105.74873060538411 and parameters: {'lr': 0.0001078177831412424, 'weight_decay': 0.009956763800372656, 'hidden_size': 512, 'n_layers': 4, 'dropout_rate': 0.24157547048106437}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:38:18,885] Trial 26 finished with value: 67.75630250728375 and parameters: {'lr': 0.000484442314931826, 'weight_decay': 2.977907376294535e-06, 'hidden_size': 512, 'n_layers': 3, 'dropout_rate': 0.17542174268794491}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:38:20,761] Trial 27 finished with value: 120.35577894644915 and parameters: {'lr': 0.0019694637678791768, 'weight_decay': 1.293156921032239e-05, 'hidden_size': 32, 'n_layers': 3, 'dropout_rate': 0.23781907247467837}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:38:37,296] Trial 28 finished with value: 122.80998479462485 and parameters: {'lr': 0.0002542114462059905, 'weight_decay': 5.930843038877065e-05, 'hidden_size': 128, 'n_layers': 5, 'dropout_rate': 0.10579953635455205}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:41:35,110] Trial 29 finished with value: 105.79917487866472 and parameters: {'lr': 0.00011661015980611265, 'weight_decay': 0.00018316968946637872, 'hidden_size': 512, 'n_layers': 4, 'dropout_rate': 0.2952800764098742}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:45:30,025] Trial 30 finished with value: 15.4998928695423 and parameters: {'lr': 0.0008595292284139321, 'weight_decay': 3.126696128850405e-06, 'hidden_size': 512, 'n_layers': 5, 'dropout_rate': 0.2736892468379288}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:49:24,818] Trial 31 finished with value: 14.127788678704622 and parameters: {'lr': 0.000970598982790696, 'weight_decay': 2.9317189118110395e-06, 'hidden_size': 512, 'n_layers': 5, 'dropout_rate': 0.26707437952925567}. Best is trial 18 with value: 9.923652949137228.
[I 2025-11-23 01:49:46,053] Trial 32 finished with value: 610.199710788474 and parameters: {'lr': 0.009164767537848919, 'weight_decay': 3.4998061025673607e-06, 'hidden_size': 512, 'n_layers': 4, 'dropout_rate': 0.28006347422520217}. Best is trial 18 with value: 9.923652949137228.
[W 2025-11-23 01:49:57,819] Trial 33 failed with parameters: {'lr': 0.0011440525137980022, 'weight_decay': 1.277615246922208e-05, 'hidden_size': 512, 'n_layers': 5, 'dropout_rate': 0.32437467999586944} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/tmp/ipython-input-1703738945.py", line 82, in objective
    if no_improve &gt;= patience:
       ^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[W 2025-11-23 01:49:57,821] Trial 33 failed with value None.</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-1703738945.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">     96</span> 
<span class="ansi-green-fg ansi-bold">     97</span> <span class="ansi-red-fg"># Executar otimização</span>
<span class="ansi-green-fg">---&gt; 98</span><span class="ansi-red-fg"> </span>study<span class="ansi-blue-fg">.</span>optimize<span class="ansi-blue-fg">(</span>objective<span class="ansi-blue-fg">,</span> n_trials<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">50</span><span class="ansi-blue-fg">,</span> show_progress_bar<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">     99</span> 
<span class="ansi-green-fg ansi-bold">    100</span> <span class="ansi-red-fg"># 5. RESULTADOS</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/optuna/study/study.py</span> in <span class="ansi-cyan-fg">optimize</span><span class="ansi-blue-fg">(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)</span>
<span class="ansi-green-fg ansi-bold">    488</span>                 If nested invocation of this method occurs<span class="ansi-blue-fg">.</span>
<span class="ansi-green-fg ansi-bold">    489</span>         """
<span class="ansi-green-fg">--&gt; 490</span><span class="ansi-red-fg">         _optimize(
</span><span class="ansi-green-fg ansi-bold">    491</span>             study<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg ansi-bold">    492</span>             func<span class="ansi-blue-fg">=</span>func<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py</span> in <span class="ansi-cyan-fg">_optimize</span><span class="ansi-blue-fg">(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)</span>
<span class="ansi-green-fg ansi-bold">     65</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">     66</span>         <span class="ansi-green-fg">if</span> n_jobs <span class="ansi-blue-fg">==</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 67</span><span class="ansi-red-fg">             _optimize_sequential(
</span><span class="ansi-green-fg ansi-bold">     68</span>                 study<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg ansi-bold">     69</span>                 func<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py</span> in <span class="ansi-cyan-fg">_optimize_sequential</span><span class="ansi-blue-fg">(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)</span>
<span class="ansi-green-fg ansi-bold">    162</span> 
<span class="ansi-green-fg ansi-bold">    163</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 164</span><span class="ansi-red-fg">             </span>frozen_trial_id <span class="ansi-blue-fg">=</span> _run_trial<span class="ansi-blue-fg">(</span>study<span class="ansi-blue-fg">,</span> func<span class="ansi-blue-fg">,</span> catch<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    165</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    166</span>             <span class="ansi-red-fg"># The following line mitigates memory problems that can be occurred in some</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py</span> in <span class="ansi-cyan-fg">_run_trial</span><span class="ansi-blue-fg">(study, func, catch)</span>
<span class="ansi-green-fg ansi-bold">    260</span>         <span class="ansi-green-fg">and</span> <span class="ansi-green-fg">not</span> isinstance<span class="ansi-blue-fg">(</span>func_err<span class="ansi-blue-fg">,</span> catch<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    261</span>     ):
<span class="ansi-green-fg">--&gt; 262</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">raise</span> func_err
<span class="ansi-green-fg ansi-bold">    263</span>     <span class="ansi-green-fg">return</span> trial<span class="ansi-blue-fg">.</span>_trial_id
<span class="ansi-green-fg ansi-bold">    264</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py</span> in <span class="ansi-cyan-fg">_run_trial</span><span class="ansi-blue-fg">(study, func, catch)</span>
<span class="ansi-green-fg ansi-bold">    203</span>     <span class="ansi-green-fg">with</span> get_heartbeat_thread<span class="ansi-blue-fg">(</span>trial<span class="ansi-blue-fg">.</span>_trial_id<span class="ansi-blue-fg">,</span> study<span class="ansi-blue-fg">.</span>_storage<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    204</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 205</span><span class="ansi-red-fg">             </span>value_or_values <span class="ansi-blue-fg">=</span> func<span class="ansi-blue-fg">(</span>trial<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    206</span>         <span class="ansi-green-fg">except</span> exceptions<span class="ansi-blue-fg">.</span>TrialPruned <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    207</span>             <span class="ansi-red-fg"># TODO(mamu): Handle multi-objective cases.</span>

<span class="ansi-green-fg">/tmp/ipython-input-1703738945.py</span> in <span class="ansi-cyan-fg">objective</span><span class="ansi-blue-fg">(trial)</span>
<span class="ansi-green-fg ansi-bold">     80</span>             no_improve <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-fg ansi-bold">     81</span> 
<span class="ansi-green-fg">---&gt; 82</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">if</span> no_improve <span class="ansi-blue-fg">&gt;=</span> patience<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">     83</span>             <span class="ansi-green-fg">break</span>
<span class="ansi-green-fg ansi-bold">     84</span> 

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>
</div>
</section>
<section id="refinamento-focado" class="level2">
<h2 class="anchored" data-anchor-id="refinamento-focado">Refinamento focado</h2>
<p>Considerando que temos um conjunto de hiperparâmetros que diminuiu MUITO a perda no conjunto de validação, vamos tentar refinar um pouco mais a busca em torno desses valores:</p>
<pre><code>Melhores parametros:
  lr             : 0.001278      # Learning rate médio-baixo
  weight_decay   : 5.07e-06      # Regularização L2 muito suave
  hidden_size    : 512           
  n_layers       : 4             
  dropout_rate   : 0.156         </code></pre>
<div id="cell-50" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8b4e40ce-e9e3-4f46-f36f-a2eafdd14fde" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TESTE FOCADO - 4 DROPOUT RATES ESTRATÉGICOS</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>base_params <span class="op">=</span> {</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lr'</span>: <span class="fl">0.001278</span>,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'weight_decay'</span>: <span class="fl">5.07e-06</span>,</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'hidden_size'</span>: <span class="dv">512</span>,</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_layers'</span>: <span class="dv">4</span>,</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 4 valores estratégicos ao redor do ótimo 0.156</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>dropout_rates_to_test <span class="op">=</span> [</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.14</span>,    <span class="co"># Um pouco menos - pode underfit</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.156</span>,   <span class="co"># Seu atual melhor (para baseline)</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.17</span>,    <span class="co"># Um pouco mais - pode melhorar regularização</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.19</span>     <span class="co"># Mais regularização - testar limite</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TESTE FOCADO - 4 DROPOUT RATES ESTRATÉGICOS:"</span>)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SameNet(nn.Module):</span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dropout_rate):</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> []</span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>        prev_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a>            layers.extend([</span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a>                nn.Linear(prev_size, <span class="dv">512</span>),</span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a>                nn.ReLU(),</span>
<span id="cb48-30"><a href="#cb48-30" aria-hidden="true" tabindex="-1"></a>                nn.Dropout(dropout_rate)</span>
<span id="cb48-31"><a href="#cb48-31" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb48-32"><a href="#cb48-32" aria-hidden="true" tabindex="-1"></a>            prev_size <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb48-33"><a href="#cb48-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-34"><a href="#cb48-34" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.Linear(<span class="dv">512</span>, <span class="dv">1</span>))</span>
<span id="cb48-35"><a href="#cb48-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb48-36"><a href="#cb48-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-37"><a href="#cb48-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb48-38"><a href="#cb48-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.network(x)</span>
<span id="cb48-39"><a href="#cb48-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-40"><a href="#cb48-40" aria-hidden="true" tabindex="-1"></a>best_dropout_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb48-41"><a href="#cb48-41" aria-hidden="true" tabindex="-1"></a>best_dropout_rate <span class="op">=</span> <span class="va">None</span></span>
<span id="cb48-42"><a href="#cb48-42" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb48-43"><a href="#cb48-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-44"><a href="#cb48-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-45"><a href="#cb48-45" aria-hidden="true" tabindex="-1"></a>X_tensor <span class="op">=</span> torch.tensor(x_treino, dtype<span class="op">=</span>torch.float64).to(device)  <span class="co"># double</span></span>
<span id="cb48-46"><a href="#cb48-46" aria-hidden="true" tabindex="-1"></a>y_tensor <span class="op">=</span> torch.tensor(y_treino, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb48-47"><a href="#cb48-47" aria-hidden="true" tabindex="-1"></a>X_val_tensor <span class="op">=</span> torch.tensor(x_val, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb48-48"><a href="#cb48-48" aria-hidden="true" tabindex="-1"></a>y_val_tensor <span class="op">=</span> torch.tensor(y_val, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb48-49"><a href="#cb48-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-50"><a href="#cb48-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> dropout_rate <span class="kw">in</span> dropout_rates_to_test:</span>
<span id="cb48-51"><a href="#cb48-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Testando dropout_rate = </span><span class="sc">{</span>dropout_rate<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb48-52"><a href="#cb48-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-53"><a href="#cb48-53" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SameNet(dropout_rate).double().to(device)</span>
<span id="cb48-54"><a href="#cb48-54" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>base_params[<span class="st">'lr'</span>],</span>
<span id="cb48-55"><a href="#cb48-55" aria-hidden="true" tabindex="-1"></a>                               weight_decay<span class="op">=</span>base_params[<span class="st">'weight_decay'</span>])</span>
<span id="cb48-56"><a href="#cb48-56" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb48-57"><a href="#cb48-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-58"><a href="#cb48-58" aria-hidden="true" tabindex="-1"></a>    best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb48-59"><a href="#cb48-59" aria-hidden="true" tabindex="-1"></a>    patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb48-60"><a href="#cb48-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-61"><a href="#cb48-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb48-62"><a href="#cb48-62" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb48-63"><a href="#cb48-63" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb48-64"><a href="#cb48-64" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_tensor)</span>
<span id="cb48-65"><a href="#cb48-65" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_tensor)</span>
<span id="cb48-66"><a href="#cb48-66" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb48-67"><a href="#cb48-67" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb48-68"><a href="#cb48-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-69"><a href="#cb48-69" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb48-70"><a href="#cb48-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb48-71"><a href="#cb48-71" aria-hidden="true" tabindex="-1"></a>            y_val_pred <span class="op">=</span> model(X_val_tensor)</span>
<span id="cb48-72"><a href="#cb48-72" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">=</span> criterion(y_val_pred, y_val_tensor)</span>
<span id="cb48-73"><a href="#cb48-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-74"><a href="#cb48-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb48-75"><a href="#cb48-75" aria-hidden="true" tabindex="-1"></a>            best_val_loss <span class="op">=</span> val_loss</span>
<span id="cb48-76"><a href="#cb48-76" aria-hidden="true" tabindex="-1"></a>            patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb48-77"><a href="#cb48-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb48-78"><a href="#cb48-78" aria-hidden="true" tabindex="-1"></a>            patience_counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb48-79"><a href="#cb48-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-80"><a href="#cb48-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> patience_counter <span class="op">&gt;=</span> <span class="dv">10</span>:</span>
<span id="cb48-81"><a href="#cb48-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb48-82"><a href="#cb48-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-83"><a href="#cb48-83" aria-hidden="true" tabindex="-1"></a>    results.append((dropout_rate, best_val_loss.item()))</span>
<span id="cb48-84"><a href="#cb48-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Loss: </span><span class="sc">{</span>best_val_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb48-85"><a href="#cb48-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-86"><a href="#cb48-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> best_val_loss.item() <span class="op">&lt;</span> best_dropout_loss:</span>
<span id="cb48-87"><a href="#cb48-87" aria-hidden="true" tabindex="-1"></a>        best_dropout_loss <span class="op">=</span> best_val_loss.item()</span>
<span id="cb48-88"><a href="#cb48-88" aria-hidden="true" tabindex="-1"></a>        best_dropout_rate <span class="op">=</span> dropout_rate</span>
<span id="cb48-89"><a href="#cb48-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-90"><a href="#cb48-90" aria-hidden="true" tabindex="-1"></a><span class="co"># RESULTADOS</span></span>
<span id="cb48-91"><a href="#cb48-91" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb48-92"><a href="#cb48-92" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESULTADOS DOS 4 TESTES:"</span>)</span>
<span id="cb48-93"><a href="#cb48-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb48-94"><a href="#cb48-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-95"><a href="#cb48-95" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor dropout: </span><span class="sc">{</span>best_dropout_rate<span class="sc">}</span><span class="ss"> -&gt; Loss: </span><span class="sc">{</span>best_dropout_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb48-96"><a href="#cb48-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-97"><a href="#cb48-97" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Comparação detalhada:"</span>)</span>
<span id="cb48-98"><a href="#cb48-98" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> dropout, loss <span class="kw">in</span> results:</span>
<span id="cb48-99"><a href="#cb48-99" aria-hidden="true" tabindex="-1"></a>    improvement <span class="op">=</span> ((<span class="fl">9.923652</span> <span class="op">-</span> loss) <span class="op">/</span> <span class="fl">9.923652</span>) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb48-100"><a href="#cb48-100" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  dropout=</span><span class="sc">{</span>dropout<span class="sc">}</span><span class="ss">: loss=</span><span class="sc">{</span>loss<span class="sc">:.6f}</span><span class="ss"> (melhoria: </span><span class="sc">{</span>improvement<span class="sc">:+.2f}</span><span class="ss">%)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>TESTE FOCADO - 4 DROPOUT RATES ESTRATÉGICOS:
==================================================
Testando dropout_rate = 0.14
  Loss: 14.631329
Testando dropout_rate = 0.156
  Loss: 17.454025
Testando dropout_rate = 0.17
  Loss: 15.058065
Testando dropout_rate = 0.19
  Loss: 19.204266

==================================================
RESULTADOS DOS 4 TESTES:
==================================================
Melhor dropout: 0.14 -&gt; Loss: 14.631329

Comparação detalhada:
  dropout=0.14: loss=14.631329 (melhoria: -47.44%)
  dropout=0.156: loss=17.454025 (melhoria: -75.88%)
  dropout=0.17: loss=15.058065 (melhoria: -51.74%)
  dropout=0.19: loss=19.204266 (melhoria: -93.52%)</code></pre>
</div>
</div>
<p>Mesmo testando outras taxas para <strong>Dropout</strong> não conseguimos melhorar o resultado anterior.</p>
</section>
<section id="precisão-da-rede-no-conjunto-de-teste" class="level2">
<h2 class="anchored" data-anchor-id="precisão-da-rede-no-conjunto-de-teste">Precisão da rede no conjunto de teste</h2>
<p>Vamos pegar os melhores parâmetros hiperparâmetros das etapa passada e treinar o conjunto de treino + validação:</p>
<pre><code>Melhores parametros:
  lr             : 0.001278      
  weight_decay   : 5.07e-06      
  hidden_size    : 512           
  n_layers       : 4             
  dropout_rate   : 0.156         </code></pre>
<div id="cell-55" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}" data-outputid="3bac0c3a-07b5-44b5-fd07-eb50cc44ad7f" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TREINO DO MODELO FINAL COM MELHORES PARÂMETROS + TESTE</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>torch.cuda.manual_seed(seed)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>torch.cuda.manual_seed_all(seed)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(seed)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>random.seed(seed)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">False</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a><span class="co"># MELHORES PARÂMETROS</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> {</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lr'</span>: <span class="fl">0.0012782314478058804</span>,</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'weight_decay'</span>: <span class="fl">5.071206793426592e-06</span>,</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'hidden_size'</span>: <span class="dv">512</span>,</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_layers'</span>: <span class="dv">4</span>,</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dropout_rate'</span>: <span class="fl">0.15658205493421604</span></span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a><span class="co"># MODELO FINAL COM MELHORES PARÂMETROS</span></span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FinalNet(nn.Module):</span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> []</span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a>        prev_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(best_params[<span class="st">'n_layers'</span>]):</span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a>            layers.extend([</span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a>                nn.Linear(prev_size, best_params[<span class="st">'hidden_size'</span>]),</span>
<span id="cb51-33"><a href="#cb51-33" aria-hidden="true" tabindex="-1"></a>                nn.ReLU(),</span>
<span id="cb51-34"><a href="#cb51-34" aria-hidden="true" tabindex="-1"></a>                nn.Dropout(best_params[<span class="st">'dropout_rate'</span>])</span>
<span id="cb51-35"><a href="#cb51-35" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb51-36"><a href="#cb51-36" aria-hidden="true" tabindex="-1"></a>            prev_size <span class="op">=</span> best_params[<span class="st">'hidden_size'</span>]</span>
<span id="cb51-37"><a href="#cb51-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-38"><a href="#cb51-38" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.Linear(prev_size, <span class="dv">1</span>))</span>
<span id="cb51-39"><a href="#cb51-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb51-40"><a href="#cb51-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-41"><a href="#cb51-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb51-42"><a href="#cb51-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.network(x)</span>
<span id="cb51-43"><a href="#cb51-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-44"><a href="#cb51-44" aria-hidden="true" tabindex="-1"></a><span class="co"># INICIALIZAÇÃO XAVIER</span></span>
<span id="cb51-45"><a href="#cb51-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> inicializar_xavier(model):</span>
<span id="cb51-46"><a href="#cb51-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> module <span class="kw">in</span> model.modules():</span>
<span id="cb51-47"><a href="#cb51-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(module, nn.Linear):</span>
<span id="cb51-48"><a href="#cb51-48" aria-hidden="true" tabindex="-1"></a>            nn.init.xavier_uniform_(module.weight)</span>
<span id="cb51-49"><a href="#cb51-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> module.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb51-50"><a href="#cb51-50" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(module.bias, <span class="fl">0.0</span>)</span>
<span id="cb51-51"><a href="#cb51-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-52"><a href="#cb51-52" aria-hidden="true" tabindex="-1"></a><span class="co"># PREPARAR DADOS (TREINO + VALIDAÇÃO JUNTOS)</span></span>
<span id="cb51-53"><a href="#cb51-53" aria-hidden="true" tabindex="-1"></a>x_treino_final <span class="op">=</span> np.vstack([x_treino, x_val])</span>
<span id="cb51-54"><a href="#cb51-54" aria-hidden="true" tabindex="-1"></a>y_treino_final <span class="op">=</span> np.hstack([y_treino, y_val])</span>
<span id="cb51-55"><a href="#cb51-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-56"><a href="#cb51-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Treino final: </span><span class="sc">{</span>x_treino_final<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> amostras"</span>)</span>
<span id="cb51-57"><a href="#cb51-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Teste: </span><span class="sc">{</span>x_teste<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> amostras"</span>)</span>
<span id="cb51-58"><a href="#cb51-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-59"><a href="#cb51-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Converter para tensores (nao tínhamos feito isso com o teste)</span></span>
<span id="cb51-60"><a href="#cb51-60" aria-hidden="true" tabindex="-1"></a>X_test_tensor <span class="op">=</span> torch.tensor(x_teste, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb51-61"><a href="#cb51-61" aria-hidden="true" tabindex="-1"></a>y_test_tensor <span class="op">=</span> torch.tensor(y_teste, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb51-62"><a href="#cb51-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-63"><a href="#cb51-63" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> torch.tensor(x_treino_final, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb51-64"><a href="#cb51-64" aria-hidden="true" tabindex="-1"></a>y_train_tensor <span class="op">=</span> torch.tensor(y_treino_final, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb51-65"><a href="#cb51-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-66"><a href="#cb51-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Criar DataLoaders</span></span>
<span id="cb51-67"><a href="#cb51-67" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)</span>
<span id="cb51-68"><a href="#cb51-68" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)</span>
<span id="cb51-69"><a href="#cb51-69" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> torch.utils.data.DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb51-70"><a href="#cb51-70" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb51-71"><a href="#cb51-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-72"><a href="#cb51-72" aria-hidden="true" tabindex="-1"></a><span class="co"># INICIALIZAR MODELO</span></span>
<span id="cb51-73"><a href="#cb51-73" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> FinalNet().double().to(device)</span>
<span id="cb51-74"><a href="#cb51-74" aria-hidden="true" tabindex="-1"></a>inicializar_xavier(model)</span>
<span id="cb51-75"><a href="#cb51-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIALIZAÇÃO XAVIER APLICADA"</span>)</span>
<span id="cb51-76"><a href="#cb51-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-77"><a href="#cb51-77" aria-hidden="true" tabindex="-1"></a><span class="co"># OTIMIZADOR E CRITÉRIO</span></span>
<span id="cb51-78"><a href="#cb51-78" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(</span>
<span id="cb51-79"><a href="#cb51-79" aria-hidden="true" tabindex="-1"></a>    model.parameters(),</span>
<span id="cb51-80"><a href="#cb51-80" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>best_params[<span class="st">'lr'</span>],</span>
<span id="cb51-81"><a href="#cb51-81" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span>best_params[<span class="st">'weight_decay'</span>]  <span class="co"># L2 Regularization</span></span>
<span id="cb51-82"><a href="#cb51-82" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb51-83"><a href="#cb51-83" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb51-84"><a href="#cb51-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-85"><a href="#cb51-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">MELHORES PARÂMETROS:"</span>)</span>
<span id="cb51-86"><a href="#cb51-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Learning Rate: </span><span class="sc">{</span>best_params[<span class="st">'lr'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-87"><a href="#cb51-87" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Weight Decay: </span><span class="sc">{</span>best_params[<span class="st">'weight_decay'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-88"><a href="#cb51-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Hidden Size: </span><span class="sc">{</span>best_params[<span class="st">'hidden_size'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-89"><a href="#cb51-89" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  N Layers: </span><span class="sc">{</span>best_params[<span class="st">'n_layers'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-90"><a href="#cb51-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Dropout Rate: </span><span class="sc">{</span>best_params[<span class="st">'dropout_rate'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-91"><a href="#cb51-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-92"><a href="#cb51-92" aria-hidden="true" tabindex="-1"></a><span class="co"># VERIFICAÇÃO DO LOSS INICIAL</span></span>
<span id="cb51-93"><a href="#cb51-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">VERIFICAÇÃO DO LOSS INICIAL"</span>)</span>
<span id="cb51-94"><a href="#cb51-94" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb51-95"><a href="#cb51-95" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb51-96"><a href="#cb51-96" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loss no treino</span></span>
<span id="cb51-97"><a href="#cb51-97" aria-hidden="true" tabindex="-1"></a>    y_pred_initial <span class="op">=</span> model(X_train_tensor)</span>
<span id="cb51-98"><a href="#cb51-98" aria-hidden="true" tabindex="-1"></a>    initial_train_loss <span class="op">=</span> criterion(y_pred_initial, y_train_tensor)</span>
<span id="cb51-99"><a href="#cb51-99" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Loss inicial (treino): </span><span class="sc">{</span>initial_train_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-100"><a href="#cb51-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-101"><a href="#cb51-101" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loss no teste</span></span>
<span id="cb51-102"><a href="#cb51-102" aria-hidden="true" tabindex="-1"></a>    y_test_pred_initial <span class="op">=</span> model(X_test_tensor)</span>
<span id="cb51-103"><a href="#cb51-103" aria-hidden="true" tabindex="-1"></a>    initial_test_loss <span class="op">=</span> criterion(y_test_pred_initial, y_test_tensor)</span>
<span id="cb51-104"><a href="#cb51-104" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Loss inicial (teste): </span><span class="sc">{</span>initial_test_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-105"><a href="#cb51-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-106"><a href="#cb51-106" aria-hidden="true" tabindex="-1"></a><span class="co"># TREINAMENTO</span></span>
<span id="cb51-107"><a href="#cb51-107" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">INICIANDO TREINO FINAL"</span>)</span>
<span id="cb51-108"><a href="#cb51-108" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb51-109"><a href="#cb51-109" aria-hidden="true" tabindex="-1"></a>patience <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb51-110"><a href="#cb51-110" aria-hidden="true" tabindex="-1"></a>best_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb51-111"><a href="#cb51-111" aria-hidden="true" tabindex="-1"></a>patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb51-112"><a href="#cb51-112" aria-hidden="true" tabindex="-1"></a>train_losses <span class="op">=</span> []</span>
<span id="cb51-113"><a href="#cb51-113" aria-hidden="true" tabindex="-1"></a>val_losses <span class="op">=</span> []</span>
<span id="cb51-114"><a href="#cb51-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-115"><a href="#cb51-115" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb51-116"><a href="#cb51-116" aria-hidden="true" tabindex="-1"></a>    <span class="co"># FASE DE TREINO</span></span>
<span id="cb51-117"><a href="#cb51-117" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb51-118"><a href="#cb51-118" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb51-119"><a href="#cb51-119" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_loader:</span>
<span id="cb51-120"><a href="#cb51-120" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb51-121"><a href="#cb51-121" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb51-122"><a href="#cb51-122" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb51-123"><a href="#cb51-123" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb51-124"><a href="#cb51-124" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb51-125"><a href="#cb51-125" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">+=</span> loss.item() <span class="op">*</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb51-126"><a href="#cb51-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-127"><a href="#cb51-127" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> train_loss <span class="op">/</span> <span class="bu">len</span>(train_loader.dataset)</span>
<span id="cb51-128"><a href="#cb51-128" aria-hidden="true" tabindex="-1"></a>    train_losses.append(train_loss)</span>
<span id="cb51-129"><a href="#cb51-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-130"><a href="#cb51-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># FASE DE VALIDAÇÃO (usando conjunto de teste como "validação" para early stopping)</span></span>
<span id="cb51-131"><a href="#cb51-131" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb51-132"><a href="#cb51-132" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb51-133"><a href="#cb51-133" aria-hidden="true" tabindex="-1"></a>        test_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb51-134"><a href="#cb51-134" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> test_loader:</span>
<span id="cb51-135"><a href="#cb51-135" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)</span>
<span id="cb51-136"><a href="#cb51-136" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(y_pred, y_batch)</span>
<span id="cb51-137"><a href="#cb51-137" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> loss.item() <span class="op">*</span> X_batch.size(<span class="dv">0</span>)</span>
<span id="cb51-138"><a href="#cb51-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-139"><a href="#cb51-139" aria-hidden="true" tabindex="-1"></a>        test_loss <span class="op">=</span> test_loss <span class="op">/</span> <span class="bu">len</span>(test_loader.dataset)</span>
<span id="cb51-140"><a href="#cb51-140" aria-hidden="true" tabindex="-1"></a>        val_losses.append(test_loss)</span>
<span id="cb51-141"><a href="#cb51-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-142"><a href="#cb51-142" aria-hidden="true" tabindex="-1"></a>    <span class="co"># EARLY STOPPING</span></span>
<span id="cb51-143"><a href="#cb51-143" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> test_loss <span class="op">&lt;</span> best_loss:</span>
<span id="cb51-144"><a href="#cb51-144" aria-hidden="true" tabindex="-1"></a>        best_loss <span class="op">=</span> test_loss</span>
<span id="cb51-145"><a href="#cb51-145" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb51-146"><a href="#cb51-146" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Salvar melhor modelo</span></span>
<span id="cb51-147"><a href="#cb51-147" aria-hidden="true" tabindex="-1"></a>        torch.save(model.state_dict(), <span class="st">'melhor_modelo.pth'</span>)</span>
<span id="cb51-148"><a href="#cb51-148" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb51-149"><a href="#cb51-149" aria-hidden="true" tabindex="-1"></a>        patience_counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb51-150"><a href="#cb51-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-151"><a href="#cb51-151" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> patience_counter <span class="op">&gt;=</span> patience:</span>
<span id="cb51-152"><a href="#cb51-152" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Early stopping na época </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-153"><a href="#cb51-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb51-154"><a href="#cb51-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-155"><a href="#cb51-155" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb51-156"><a href="#cb51-156" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Época </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">:3d}</span><span class="ss"> | Treino: </span><span class="sc">{</span>train_loss<span class="sc">:.6f}</span><span class="ss"> | Teste: </span><span class="sc">{</span>test_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-157"><a href="#cb51-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-158"><a href="#cb51-158" aria-hidden="true" tabindex="-1"></a><span class="co"># CARREGAR MELHOR MODELO</span></span>
<span id="cb51-159"><a href="#cb51-159" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(torch.load(<span class="st">'melhor_modelo.pth'</span>))</span>
<span id="cb51-160"><a href="#cb51-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-161"><a href="#cb51-161" aria-hidden="true" tabindex="-1"></a><span class="co"># AVALIAÇÃO FINAL</span></span>
<span id="cb51-162"><a href="#cb51-162" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb51-163"><a href="#cb51-163" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"AVALIAÇÃO FINAL NO CONJUNTO DE TESTE"</span>)</span>
<span id="cb51-164"><a href="#cb51-164" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb51-165"><a href="#cb51-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-166"><a href="#cb51-166" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb51-167"><a href="#cb51-167" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb51-168"><a href="#cb51-168" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Previsões finais</span></span>
<span id="cb51-169"><a href="#cb51-169" aria-hidden="true" tabindex="-1"></a>    y_test_pred <span class="op">=</span> model(X_test_tensor)</span>
<span id="cb51-170"><a href="#cb51-170" aria-hidden="true" tabindex="-1"></a>    final_test_loss <span class="op">=</span> criterion(y_test_pred, y_test_tensor)</span>
<span id="cb51-171"><a href="#cb51-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-172"><a href="#cb51-172" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcular R² Score (acurácia para regressão)</span></span>
<span id="cb51-173"><a href="#cb51-173" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score, mean_squared_error</span>
<span id="cb51-174"><a href="#cb51-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-175"><a href="#cb51-175" aria-hidden="true" tabindex="-1"></a>    y_test_np <span class="op">=</span> y_test_tensor.cpu().numpy()</span>
<span id="cb51-176"><a href="#cb51-176" aria-hidden="true" tabindex="-1"></a>    y_pred_np <span class="op">=</span> y_test_pred.cpu().numpy()</span>
<span id="cb51-177"><a href="#cb51-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-178"><a href="#cb51-178" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_test_np, y_pred_np)</span>
<span id="cb51-179"><a href="#cb51-179" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> mean_squared_error(y_test_np, y_pred_np)</span>
<span id="cb51-180"><a href="#cb51-180" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb51-181"><a href="#cb51-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-182"><a href="#cb51-182" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Loss Final (MSE): </span><span class="sc">{</span>final_test_loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-183"><a href="#cb51-183" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-184"><a href="#cb51-184" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"R² Score: </span><span class="sc">{</span>r2<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-185"><a href="#cb51-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-186"><a href="#cb51-186" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Comparação com baseline</span></span>
<span id="cb51-187"><a href="#cb51-187" aria-hidden="true" tabindex="-1"></a>    baseline_loss <span class="op">=</span> np.mean((y_test_np <span class="op">-</span> np.mean(y_test_np))<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb51-188"><a href="#cb51-188" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Baseline (variação total): </span><span class="sc">{</span>baseline_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-189"><a href="#cb51-189" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Melhoria sobre baseline: </span><span class="sc">{</span>((baseline_loss <span class="op">-</span> mse) <span class="op">/</span> baseline_loss <span class="op">*</span> <span class="dv">100</span>)<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb51-190"><a href="#cb51-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-191"><a href="#cb51-191" aria-hidden="true" tabindex="-1"></a><span class="co"># RESULTADOS DO TREINO</span></span>
<span id="cb51-192"><a href="#cb51-192" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb51-193"><a href="#cb51-193" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESUMO DO TREINAMENTO"</span>)</span>
<span id="cb51-194"><a href="#cb51-194" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb51-195"><a href="#cb51-195" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Épocas treinadas: </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-196"><a href="#cb51-196" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Melhor loss no teste: </span><span class="sc">{</span>best_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-197"><a href="#cb51-197" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss final no treino: </span><span class="sc">{</span>train_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb51-198"><a href="#cb51-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-199"><a href="#cb51-199" aria-hidden="true" tabindex="-1"></a><span class="co"># PLOT</span></span>
<span id="cb51-200"><a href="#cb51-200" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb51-201"><a href="#cb51-201" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb51-202"><a href="#cb51-202" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb51-203"><a href="#cb51-203" aria-hidden="true" tabindex="-1"></a>    plt.plot(train_losses, label<span class="op">=</span><span class="st">'Treino'</span>)</span>
<span id="cb51-204"><a href="#cb51-204" aria-hidden="true" tabindex="-1"></a>    plt.plot(val_losses, label<span class="op">=</span><span class="st">'Teste'</span>)</span>
<span id="cb51-205"><a href="#cb51-205" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Época'</span>)</span>
<span id="cb51-206"><a href="#cb51-206" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb51-207"><a href="#cb51-207" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Curva de Aprendizado'</span>)</span>
<span id="cb51-208"><a href="#cb51-208" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb51-209"><a href="#cb51-209" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb51-210"><a href="#cb51-210" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb51-211"><a href="#cb51-211" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb51-212"><a href="#cb51-212" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Instale matplotlib para ver o gráfico: pip install matplotlib"</span>)</span>
<span id="cb51-213"><a href="#cb51-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-214"><a href="#cb51-214" aria-hidden="true" tabindex="-1"></a><span class="co"># Salvar o modelo completo (arquivo maior)</span></span>
<span id="cb51-215"><a href="#cb51-215" aria-hidden="true" tabindex="-1"></a>torch.save(model, <span class="st">'melhor_modelo_completo.pth'</span>)</span>
<span id="cb51-216"><a href="#cb51-216" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✅ Modelo completo salvo como 'melhor_modelo_completo.pth'"</span>)</span>
<span id="cb51-217"><a href="#cb51-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-218"><a href="#cb51-218" aria-hidden="true" tabindex="-1"></a><span class="co"># Para carregar depois:</span></span>
<span id="cb51-219"><a href="#cb51-219" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb51-220"><a href="#cb51-220" aria-hidden="true" tabindex="-1"></a><span class="co">modelo_carregado = torch.load('melhor_modelo_completo.pth')</span></span>
<span id="cb51-221"><a href="#cb51-221" aria-hidden="true" tabindex="-1"></a><span class="co">modelo_carregado.eval()</span></span>
<span id="cb51-222"><a href="#cb51-222" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Treino final: 90000 amostras
Teste: 10000 amostras

INICIALIZAÇÃO XAVIER APLICADA

MELHORES PARÂMETROS:
  Learning Rate: 0.0012782314478058804
  Weight Decay: 5.071206793426592e-06
  Hidden Size: 512
  N Layers: 4
  Dropout Rate: 0.15658205493421604

VERIFICAÇÃO DO LOSS INICIAL
Loss inicial (treino): 678.341852
Loss inicial (teste): 673.186958

INICIANDO TREINO FINAL
Época  10 | Treino: 3.967327 | Teste: 2.338702
Época  20 | Treino: 3.476542 | Teste: 2.537265
Early stopping na época 27

======================================================================
AVALIAÇÃO FINAL NO CONJUNTO DE TESTE
======================================================================
Loss Final (MSE): 1.543326
RMSE: 1.242307
R² Score: 0.992256
Baseline (variação total): 199.283321
Melhoria sobre baseline: 99.23%

======================================================================
RESUMO DO TREINAMENTO
======================================================================
Épocas treinadas: 27
Melhor loss no teste: 1.543326
Loss final no treino: 3.204205</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="Lista_4_RebecaChuffi_files/figure-html/Cod4-cell-27-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="Lista_4_RebecaChuffi_files/figure-html/Cod4-cell-27-output-2.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✅ Modelo completo salvo como 'melhor_modelo_completo.pth'</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>"\nmodelo_carregado = torch.load('melhor_modelo_completo.pth')\nmodelo_carregado.eval()\n"</code></pre>
</div>
</div>
<p>Usamos Early stopping (para evitar overfitting), além de Dropout (0.156) e L2 Regularization. Analisando as métricas, temos:</p>
<ul>
<li><p>MSE: <span class="math inline">\(1.248925\)</span> erro bom (muito menor do que achamos em outras etapas, o que significa que encontramos bons parâmetros E hiperparâmetros para o modelo).</p></li>
<li><p><span class="math inline">\(R^2 = 99.2%\)</span>: ótima performance em dados não vistos (boa generalização), ou seja, não está overfittando (early stopping funcionou de maneira correta aqui). <span class="math inline">\(R^2\)</span> compara os resultados com um modelo que sempre prevê a média.</p></li>
<li><p>RMSE= <span class="math inline">\(1.248925\)</span>: voltando à mesma unidade dos dados originais com erro médio de 1.25 unidades.</p></li>
<li><p>O único ponto de atenção é o tamanho da rede. Procurei redes com performances semelhantes com menos camadas, mas não encontrei algo que pudesse substituir os parâmetros encontrados acima.</p></li>
</ul>
<div id="cell-57" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:17}}" data-outputid="b11f3d69-2276-4782-df58-a63516319cd9" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>files.download(<span class="st">'melhor_modelo_completo.pth'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<script type="application/javascript">

    async function download(id, filename, size) {
      if (!google.colab.kernel.accessAllowed) {
        return;
      }
      const div = document.createElement('div');
      const label = document.createElement('label');
      label.textContent = `Downloading "${filename}": `;
      div.appendChild(label);
      const progress = document.createElement('progress');
      progress.max = size;
      div.appendChild(progress);
      document.body.appendChild(div);

      const buffers = [];
      let downloaded = 0;

      const channel = await google.colab.kernel.comms.open(id);
      // Send a message to notify the kernel that we're ready.
      channel.send({})

      for await (const message of channel.messages) {
        // Send a message to notify the kernel that we're ready.
        channel.send({})
        if (message.buffers) {
          for (const buffer of message.buffers) {
            buffers.push(buffer);
            downloaded += buffer.byteLength;
            progress.value = downloaded;
          }
        }
      }
      const blob = new Blob(buffers, {type: 'application/binary'});
      const a = document.createElement('a');
      a.href = window.URL.createObjectURL(blob);
      a.download = filename;
      div.appendChild(a);
      a.click();
      div.remove();
    }
  
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/javascript">
download("download_771ce660-6036-4e80-b22c-659160185453", "melhor_modelo_completo.pth", 6327989)
</script>
</div>
</div>
</section>
</section>
<section id="item-c." class="level1">
<h1>ITEM C.</h1>
<p>Refaça o <strong>item b) da Lista 3</strong> para essa nova rede. Comente os resultados.</p>
<blockquote class="blockquote">
<p>Faça um gráfico do valor observado (<span class="math inline">\(y_i\)</span>) em função do valor esperado (<span class="math inline">\(\hat{y}_i=E(Y_i|x_{1i}, x_{2i})\)</span>) para cada observação do conjunto de teste. Interprete o resultado.</p>
</blockquote>
<p>Recuperando o código usado:</p>
<div id="cell-59" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:742}}" data-outputid="e306b99c-d19e-407e-ba76-b7e342371ff2" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fazer previsões no conjunto de teste</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    y_test_pred <span class="op">=</span> model(X_test_tensor)</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Converter para numpy</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    y_pred_np <span class="op">=</span> y_test_pred.cpu().numpy().flatten()</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    y_real_np <span class="op">=</span> y_test_tensor.cpu().numpy().flatten()</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Criar DataFrame com resultados</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>resultados_teste <span class="op">=</span> pd.DataFrame({</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_real'</span>: y_real_np,</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_previsto'</span>: y_pred_np</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Folha de estilo</span></span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">"ggplot"</span>)</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">"axes"</span>, facecolor<span class="op">=</span><span class="st">"#fafafa"</span>, grid<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">"grid"</span>, color<span class="op">=</span><span class="st">"#f0f0f0"</span>)</span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>plt.scatter(resultados_teste[<span class="st">'y_previsto'</span>], resultados_teste[<span class="st">'y_real'</span>],</span>
<span id="cb56-24"><a href="#cb56-24" aria-hidden="true" tabindex="-1"></a>           alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb56-25"><a href="#cb56-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-26"><a href="#cb56-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Linha vermelha de perfeita previsão</span></span>
<span id="cb56-27"><a href="#cb56-27" aria-hidden="true" tabindex="-1"></a>min_val <span class="op">=</span> <span class="bu">min</span>(resultados_teste[<span class="st">'y_real'</span>].<span class="bu">min</span>(), resultados_teste[<span class="st">'y_previsto'</span>].<span class="bu">min</span>())</span>
<span id="cb56-28"><a href="#cb56-28" aria-hidden="true" tabindex="-1"></a>max_val <span class="op">=</span> <span class="bu">max</span>(resultados_teste[<span class="st">'y_real'</span>].<span class="bu">max</span>(), resultados_teste[<span class="st">'y_previsto'</span>].<span class="bu">max</span>())</span>
<span id="cb56-29"><a href="#cb56-29" aria-hidden="true" tabindex="-1"></a>plt.plot([min_val, max_val], [min_val, max_val], <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb56-30"><a href="#cb56-30" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Linha de perfeita previsão'</span>)</span>
<span id="cb56-31"><a href="#cb56-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-32"><a href="#cb56-32" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Valor Predito (ŷ)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb56-33"><a href="#cb56-33" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Valor Observado (y)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb56-34"><a href="#cb56-34" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Valores observados vs preditos</span><span class="ch">\n</span><span class="st">Rede Neural (4 camadas, 512 neurônios)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb56-35"><a href="#cb56-35" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb56-36"><a href="#cb56-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-37"><a href="#cb56-37" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb56-38"><a href="#cb56-38" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb56-39"><a href="#cb56-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb56-40"><a href="#cb56-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-41"><a href="#cb56-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Estatísticas adicionais para interpretação</span></span>
<span id="cb56-42"><a href="#cb56-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb56-43"><a href="#cb56-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ANÁLISE DO GRÁFICO:"</span>)</span>
<span id="cb56-44"><a href="#cb56-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb56-45"><a href="#cb56-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-46"><a href="#cb56-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular métricas de qualidade do ajuste</span></span>
<span id="cb56-47"><a href="#cb56-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr</span>
<span id="cb56-48"><a href="#cb56-48" aria-hidden="true" tabindex="-1"></a>correlacao, _ <span class="op">=</span> pearsonr(y_pred_np, y_real_np)</span>
<span id="cb56-49"><a href="#cb56-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-50"><a href="#cb56-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Correlação entre previsto e real: </span><span class="sc">{</span>correlacao<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb56-51"><a href="#cb56-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R² Score: </span><span class="sc">{</span>r2_score(y_real_np, y_pred_np)<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb56-52"><a href="#cb56-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-53"><a href="#cb56-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Porcentagem dentro de margens</span></span>
<span id="cb56-54"><a href="#cb56-54" aria-hidden="true" tabindex="-1"></a>margem_1 <span class="op">=</span> <span class="fl">0.01</span> <span class="op">*</span> np.std(y_real_np)</span>
<span id="cb56-55"><a href="#cb56-55" aria-hidden="true" tabindex="-1"></a>margem_5 <span class="op">=</span> <span class="fl">0.05</span> <span class="op">*</span> np.std(y_real_np)</span>
<span id="cb56-56"><a href="#cb56-56" aria-hidden="true" tabindex="-1"></a>dentro_1pct <span class="op">=</span> np.mean(distancias <span class="op">&lt;=</span> margem_1) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb56-57"><a href="#cb56-57" aria-hidden="true" tabindex="-1"></a>dentro_5pct <span class="op">=</span> np.mean(distancias <span class="op">&lt;=</span> margem_5) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb56-58"><a href="#cb56-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-59"><a href="#cb56-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Previsões dentro de 1% do desvio padrão: </span><span class="sc">{</span>dentro_1pct<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb56-60"><a href="#cb56-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Previsões dentro de 5% do desvio padrão: </span><span class="sc">{</span>dentro_5pct<span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="Lista_4_RebecaChuffi_files/figure-html/Cod4-cell-29-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="Lista_4_RebecaChuffi_files/figure-html/Cod4-cell-29-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
============================================================
ANÁLISE DO GRÁFICO:
============================================================
Correlação entre previsto e real: 0.996136
R² Score: 0.992173

Previsões dentro de 1% do desvio padrão: 9.88%
Previsões dentro de 5% do desvio padrão: 44.72%</code></pre>
</div>
</div>
<p>Note que temos um comportamento BEM diferente do observado na lista 3:</p>
<ul>
<li>Os pontos com valores preditos entre <span class="math inline">\(0\)</span> e <span class="math inline">\(40\)</span> são os que aparecem mais (maior densidade de pontos nessa região).</li>
<li>Os pontos parecem acompanhar a linha perfeita de previsão, com uma variância bem menor que o caso anterior.</li>
<li>Anteriormente tínhamos que o <span class="math inline">\(y\)</span> previsto ia apenas até aproximadamente <span class="math inline">\(30\)</span>, enquanto o valor real tinha vários valores próximos a <span class="math inline">\(60\)</span>, o que foi corrigido nessa outra versão do modelo.</li>
<li>A imagem também mostra evidências de baixo bias, pois os erros parecem estar distribuídos de maneira simétrica ao redor da linha vermelha (não tem uma tendência sistemática à um erro específico).</li>
</ul>
</section>
<section id="item-d." class="level1">
<h1>ITEM D.</h1>
<p>Use a função de previsão do <em>PyTorch</em> para calcular o valor predito da variável resposta, <span class="math inline">\(\hat{y} = f(x_1 = 1, x_2 = 1; \theta)\)</span>, para <span class="math inline">\(\theta\)</span> definido de acordo com a rede ajustada. (Veja o item a) da Lista 2).</p>
<p>Segue a previsão para os valores <span class="math inline">\(x_1 = 1, x_2 = 1\)</span> usando o a rede ajustada (model) e considerando que os dados não foram normalizados. Numa primeira tentativa notamos que <span class="math inline">\(x_1 = 1, x_2 = 1\)</span> não são dados que estão no conjunto original e por isso vamos fazer uma aproximação numa vizinhança desse ponto (para capturar pontos que estão no dataset gerado inicialmente):</p>
<div id="cell-63" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7bce49ea-c407-4b5c-acef-4cf0a842780c" data-execution_count="28">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pevisão para x1 = 1, x2 = 1</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    x_novo <span class="op">=</span> torch.tensor([[<span class="fl">1.0</span>, <span class="fl">1.0</span>]], dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fazer previsão</span></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    y_predito <span class="op">=</span> model(x_novo)</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> (dados[<span class="st">'x1.obs'</span>] <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (dados[<span class="st">'x2.obs'</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    valores_reais <span class="op">=</span> dados[mask]</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"PREVISÃO PARA x1 = 1, x2 = 1"</span>)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Entrada: x1 = </span><span class="sc">{</span>x_novo[<span class="dv">0</span>,<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">, x2 = </span><span class="sc">{</span>x_novo[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Valor predito (ŷ): </span><span class="sc">{</span>y_predito<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(valores_reais[[<span class="st">'x1.obs'</span>, <span class="st">'x2.obs'</span>, <span class="st">'y'</span>]])</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>    tolerancia <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>    mask_proximo <span class="op">=</span> (np.<span class="bu">abs</span>(dados[<span class="st">'x1.obs'</span>] <span class="op">-</span> <span class="dv">1</span>) <span class="op">&lt;=</span> tolerancia) <span class="op">&amp;</span> <span class="op">\</span></span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>               (np.<span class="bu">abs</span>(dados[<span class="st">'x2.obs'</span>] <span class="op">-</span> <span class="dv">1</span>) <span class="op">&lt;=</span> tolerancia)</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>    valores_proximos <span class="op">=</span> dados[mask_proximo]</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Valores próximos de (1,1):"</span>)</span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(valores_proximos[[<span class="st">'x1.obs'</span>, <span class="st">'x2.obs'</span>, <span class="st">'y'</span>]].head(<span class="dv">10</span>))</span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>PREVISÃO PARA x1 = 1, x2 = 1
--------------------------------------------------
Entrada: x1 = 1.0, x2 = 1.0
Valor predito (ŷ): 14.529345
Empty DataFrame
Columns: [x1.obs, x2.obs, y]
Index: []
--------------------------------------------------
Valores próximos de (1,1):
        x1.obs    x2.obs          y
245   1.023646  0.962878  12.517536
2813  1.040812  1.050675  15.050058
2852  1.074940  0.923175  14.982424
2935  0.992593  1.020800  16.634313
2996  1.037309  0.980435  14.021036
3897  0.955089  0.942634  13.300892
5092  1.090552  1.029826  13.253533
5195  1.071307  1.006464  13.034508
5446  1.056140  1.087104  14.231893
5942  0.996052  1.095911  16.224011</code></pre>
</div>
</div>
<p>O modelo previu <span class="math inline">\(\hat{y} = f(x_1 = 1, x_2 = 1; \theta) = 14.529\)</span>. Analisando os pontos nas vizinhanças de <span class="math inline">\((1,1)\)</span> notamos que estão próximos da faixa observada.</p>
</section>
<section id="item-e." class="level1">
<h1>ITEM E.</h1>
<p>Neste exemplo meramente didático, conhecemos a superfície que estamos estimando. Apresente, lado a lado, a Figura 1 da Lista 2 e a superfície estimada pela sua rede neural. Para tanto, basta trocar a variável mu pelos valores preditos pela rede. Comente os resultados.</p>
<div id="cell-66" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:288}}" data-outputid="bb5f7395-ef1a-401d-b276-51c7c75f6a14" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>X1, X2 <span class="op">=</span> np.meshgrid(x1, x2)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Extrair pontos e valores mu da tabela</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>pontos_reais <span class="op">=</span> dados[[<span class="st">'x1.obs'</span>, <span class="st">'x2.obs'</span>]].values</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>valores_mu_reais <span class="op">=</span> dados[<span class="st">'mu'</span>].values</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Interpolação</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>mu_real_interp <span class="op">=</span> griddata(pontos_reais, valores_mu_reais, (X1, X2), method<span class="op">=</span><span class="st">'linear'</span>)  <span class="co"># linear é mais rápido</span></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a>    grid_points <span class="op">=</span> np.column_stack([X1.ravel(), X2.ravel()])</span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>    grid_tensor <span class="op">=</span> torch.tensor(grid_points, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>    y_grid_pred <span class="op">=</span> model(grid_tensor)</span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a>    mu_predito <span class="op">=</span> y_grid_pred.cpu().numpy().reshape(X1.shape)</span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Figura</span></span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Superfície real</span></span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb60-26"><a href="#cb60-26" aria-hidden="true" tabindex="-1"></a>contour1 <span class="op">=</span> plt.contourf(X1, X2, mu_real_interp, levels<span class="op">=</span><span class="dv">30</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb60-27"><a href="#cb60-27" aria-hidden="true" tabindex="-1"></a>plt.contour(X1, X2, mu_real_interp, levels<span class="op">=</span><span class="dv">8</span>, colors<span class="op">=</span><span class="st">'#404040'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb60-28"><a href="#cb60-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'$X_1$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb60-29"><a href="#cb60-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'$X_2$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb60-30"><a href="#cb60-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Superfície Real: $E(Y|X_1, X_2)$'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb60-31"><a href="#cb60-31" aria-hidden="true" tabindex="-1"></a>plt.colorbar(contour1, label<span class="op">=</span><span class="st">'$E(Y|X_1, X_2)$'</span>)</span>
<span id="cb60-32"><a href="#cb60-32" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">False</span>)</span>
<span id="cb60-33"><a href="#cb60-33" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb60-34"><a href="#cb60-34" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb60-35"><a href="#cb60-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-36"><a href="#cb60-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Superfície Estimada</span></span>
<span id="cb60-37"><a href="#cb60-37" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb60-38"><a href="#cb60-38" aria-hidden="true" tabindex="-1"></a>contour2 <span class="op">=</span> plt.contourf(X1, X2, mu_predito, levels<span class="op">=</span><span class="dv">30</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb60-39"><a href="#cb60-39" aria-hidden="true" tabindex="-1"></a>plt.contour(X1, X2, mu_predito, levels<span class="op">=</span><span class="dv">8</span>, colors<span class="op">=</span><span class="st">'#404040'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb60-40"><a href="#cb60-40" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'$X_1$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb60-41"><a href="#cb60-41" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'$X_2$'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb60-42"><a href="#cb60-42" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Superfície Estimada: Rede Neural'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb60-43"><a href="#cb60-43" aria-hidden="true" tabindex="-1"></a>plt.colorbar(contour2, label<span class="op">=</span><span class="st">'Valor Predito ($</span><span class="ch">\\</span><span class="st">hat</span><span class="sc">{y}</span><span class="st">$)'</span>)</span>
<span id="cb60-44"><a href="#cb60-44" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">False</span>)</span>
<span id="cb60-45"><a href="#cb60-45" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb60-46"><a href="#cb60-46" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb60-47"><a href="#cb60-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-48"><a href="#cb60-48" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb60-49"><a href="#cb60-49" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="Lista_4_RebecaChuffi_files/figure-html/Cod4-cell-31-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="Lista_4_RebecaChuffi_files/figure-html/Cod4-cell-31-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>As superfíceis estão bem próximas em termos de coloração (níveis) e formato (considerando a mesma escala). Além disso, a rede aprendeu uma função não-linear complexa sem overfittar. A rede capturou bem as mudanças graduais que acontecem ao longo da superfície apresentando um comportamente semelhante e satisfatório.</p>
</section>
<section id="item-f." class="level1">
<h1>ITEM F.</h1>
<p>Refaça o item g) da Lista 3 para essa nova rede. Comente os resultados.</p>
<blockquote class="blockquote">
<p>Para o modelo linear 2, faça um gráfico de dispersão entre e onde cada ponto corresponde a uma observação do conjunto de teste. Identifique os pontos que estavam contidos nos respectivos intervalos de confianças utilizando a cor verde. Para os demais pontos, use vermelho. Comente o resultado.</p>
</blockquote>
<div id="cell-69" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:800}}" data-outputid="cfd83ced-76ee-4a2b-fda0-e553d3db2f51" data-execution_count="28">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"GRÁFICO DE DISPERSÃO - REDE NEURAL"</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fazer previsões no conjunto de teste</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>    y_pred_teste <span class="op">=</span> model(X_test_tensor).cpu().numpy().flatten()</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular resíduos e intervalo de predição</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>residuos <span class="op">=</span> y_teste <span class="op">-</span> y_pred_teste</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>std_residuos <span class="op">=</span> np.std(residuos)</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Intervalo de predição 95% (assumindo distribuição normal dos resíduos)</span></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>intervalo <span class="op">=</span> <span class="fl">1.96</span> <span class="op">*</span> std_residuos</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>lower_rn <span class="op">=</span> y_pred_teste <span class="op">-</span> intervalo</span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>upper_rn <span class="op">=</span> y_pred_teste <span class="op">+</span> intervalo</span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Identificar quais pontos foram capturados pelos intervalos</span></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>pontos_capturados <span class="op">=</span> (y_teste <span class="op">&gt;=</span> lower_rn) <span class="op">&amp;</span> (y_teste <span class="op">&lt;=</span> upper_rn)</span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a>pontos_nao_capturados <span class="op">=</span> <span class="op">~</span>pontos_capturados</span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a>cobertura <span class="op">=</span> np.mean(pontos_capturados) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Desvio padrão dos resíduos: </span><span class="sc">{</span>std_residuos<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Intervalo de predição 95%: ±</span><span class="sc">{</span>intervalo<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Pontos capturados: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(pontos_capturados)<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(y_teste)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>cobertura<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Pontos não capturados: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(pontos_nao_capturados)<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(y_teste)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="dv">100</span><span class="op">-</span>cobertura<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Criar o gráfico de dispersão</span></span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotar pontos capturados (verde)</span></span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_teste[pontos_capturados, <span class="dv">0</span>], x_teste[pontos_capturados, <span class="dv">1</span>],</span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a>           c<span class="op">=</span><span class="st">'#90EE90'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">20</span>, label<span class="op">=</span><span class="ss">f'Capturados (</span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(pontos_capturados)<span class="sc">}</span><span class="ss"> pontos)'</span>)</span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotar pontos não capturados (vermelho)</span></span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_teste[pontos_nao_capturados, <span class="dv">0</span>], x_teste[pontos_nao_capturados, <span class="dv">1</span>],</span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a>           c<span class="op">=</span><span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, s<span class="op">=</span><span class="dv">30</span>, label<span class="op">=</span><span class="ss">f'Não Capturados (</span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(pontos_nao_capturados)<span class="sc">}</span><span class="ss"> pontos)'</span>)</span>
<span id="cb61-38"><a href="#cb61-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-39"><a href="#cb61-39" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x₁'</span>)</span>
<span id="cb61-40"><a href="#cb61-40" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'x₂'</span>)</span>
<span id="cb61-41"><a href="#cb61-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Rede Neural - Pontos Capturados pelos Intervalos de Predição 95%</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb61-42"><a href="#cb61-42" aria-hidden="true" tabindex="-1"></a>          <span class="ss">f'Cobertura: </span><span class="sc">{</span>cobertura<span class="sc">:.2f}</span><span class="ss">%'</span>)</span>
<span id="cb61-43"><a href="#cb61-43" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb61-44"><a href="#cb61-44" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb61-45"><a href="#cb61-45" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb61-46"><a href="#cb61-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb61-47"><a href="#cb61-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-48"><a href="#cb61-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Análise adicional por regiões</span></span>
<span id="cb61-49"><a href="#cb61-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ANÁLISE POR REGIÕES"</span>)</span>
<span id="cb61-50"><a href="#cb61-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-51"><a href="#cb61-51" aria-hidden="true" tabindex="-1"></a>x1_median <span class="op">=</span> np.median(x_teste[:, <span class="dv">0</span>])</span>
<span id="cb61-52"><a href="#cb61-52" aria-hidden="true" tabindex="-1"></a>x2_median <span class="op">=</span> np.median(x_teste[:, <span class="dv">1</span>])</span>
<span id="cb61-53"><a href="#cb61-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-54"><a href="#cb61-54" aria-hidden="true" tabindex="-1"></a>regioes <span class="op">=</span> {</span>
<span id="cb61-55"><a href="#cb61-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q1 (x₁ baixo, x₂ baixo)'</span>: (x_teste[:, <span class="dv">0</span>] <span class="op">&lt;</span> x1_median) <span class="op">&amp;</span> (x_teste[:, <span class="dv">1</span>] <span class="op">&lt;</span> x2_median),</span>
<span id="cb61-56"><a href="#cb61-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q2 (x₁ alto, x₂ baixo)'</span>: (x_teste[:, <span class="dv">0</span>] <span class="op">&gt;=</span> x1_median) <span class="op">&amp;</span> (x_teste[:, <span class="dv">1</span>] <span class="op">&lt;</span> x2_median),</span>
<span id="cb61-57"><a href="#cb61-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q3 (x₁ baixo, x₂ alto)'</span>: (x_teste[:, <span class="dv">0</span>] <span class="op">&lt;</span> x1_median) <span class="op">&amp;</span> (x_teste[:, <span class="dv">1</span>] <span class="op">&gt;=</span> x2_median),</span>
<span id="cb61-58"><a href="#cb61-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q4 (x₁ alto, x₂ alto)'</span>: (x_teste[:, <span class="dv">0</span>] <span class="op">&gt;=</span> x1_median) <span class="op">&amp;</span> (x_teste[:, <span class="dv">1</span>] <span class="op">&gt;=</span> x2_median)</span>
<span id="cb61-59"><a href="#cb61-59" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb61-60"><a href="#cb61-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-61"><a href="#cb61-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cobertura por região:"</span>)</span>
<span id="cb61-62"><a href="#cb61-62" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> regiao, mascara <span class="kw">in</span> regioes.items():</span>
<span id="cb61-63"><a href="#cb61-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.<span class="bu">sum</span>(mascara) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb61-64"><a href="#cb61-64" aria-hidden="true" tabindex="-1"></a>        cobertura_regiao <span class="op">=</span> np.mean(pontos_capturados[mascara]) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb61-65"><a href="#cb61-65" aria-hidden="true" tabindex="-1"></a>        n_pontos <span class="op">=</span> np.<span class="bu">sum</span>(mascara)</span>
<span id="cb61-66"><a href="#cb61-66" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>regiao<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>cobertura_regiao<span class="sc">:.2f}</span><span class="ss">% (</span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(pontos_capturados[mascara])<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_pontos<span class="sc">}</span><span class="ss"> pontos)"</span>)</span>
<span id="cb61-67"><a href="#cb61-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-68"><a href="#cb61-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparação</span></span>
<span id="cb61-69"><a href="#cb61-69" aria-hidden="true" tabindex="-1"></a>esperado <span class="op">=</span> <span class="fl">95.0</span></span>
<span id="cb61-70"><a href="#cb61-70" aria-hidden="true" tabindex="-1"></a>diferenca_cobertura <span class="op">=</span> cobertura <span class="op">-</span> esperado</span>
<span id="cb61-71"><a href="#cb61-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">COMPARAÇÃO COM O ESPERADO (95%):"</span>)</span>
<span id="cb61-72"><a href="#cb61-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Cobertura observada: </span><span class="sc">{</span>cobertura<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb61-73"><a href="#cb61-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Diferença: </span><span class="sc">{</span>diferenca_cobertura<span class="sc">:+.2f}</span><span class="ss">%"</span>)</span>
<span id="cb61-74"><a href="#cb61-74" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>GRÁFICO DE DISPERSÃO - REDE NEURAL
Desvio padrão dos resíduos: 1.240018
Intervalo de predição 95%: ±2.430436
Pontos capturados: 9496/10000 (94.96%)
Pontos não capturados: 504/10000 (5.04%)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="Lista_4_RebecaChuffi_files/figure-html/Cod4-cell-32-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="Lista_4_RebecaChuffi_files/figure-html/Cod4-cell-32-output-2.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
ANÁLISE POR REGIÕES
Cobertura por região:
  Q1 (x₁ baixo, x₂ baixo): 95.73% (2424/2532 pontos)
  Q2 (x₁ alto, x₂ baixo): 95.26% (2351/2468 pontos)
  Q3 (x₁ baixo, x₂ alto): 95.83% (2365/2468 pontos)
  Q4 (x₁ alto, x₂ alto): 93.05% (2356/2532 pontos)

COMPARAÇÃO COM O ESPERADO (95%):
  Cobertura observada: 94.96%
  Diferença: -0.04%</code></pre>
</div>
</div>
<p>Note que, em comparação com a figura da Lista 3, os resíduos (pontos em vermelho) estão distribuídos de maneira bem mais aleatória, ou seja, temos bem menos possíveis erros sistemáticos. De maneira geral, os erros estão distribuídos por toda a superfície. Temos alguns pontos de maior acúmulo (por exemplo, canto superior direito), mas mesmos assim a rede neural (correramente calibrada) apresenta uma performance muito melhor que a regressão 2.</p>
</section>
<section id="item-g." class="level1">
<h1>ITEM G.</h1>
<p>Ajuste uma rede neural só com a variável <span class="math inline">\(x_1\)</span> e outra só com a variável <span class="math inline">\(x_2\)</span>. Qual das duas variáveis é mais importante para o poder preditivo? Agora, com o modelo completo ajustado no item b), faça um Teste de Importância por Permutação. Comente os resultados.</p>
<section id="rede-ajustada-apenas-com-x1" class="level2">
<h2 class="anchored" data-anchor-id="rede-ajustada-apenas-com-x1">Rede ajustada apenas com x1</h2>
<div id="cell-73" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e51222d4-29a8-4bcb-e37d-c0fa55d7ca38" data-execution_count="29">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co">####Rede ajustada apenas com x1</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"REDE NEURAL APENAS COM x1"</span>)</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NetX1(nn.Module):</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> []</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>        prev_size <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Apenas x1</span></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(best_params[<span class="st">'n_layers'</span>]):</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>            layers.extend([</span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>                nn.Linear(prev_size, best_params[<span class="st">'hidden_size'</span>]),</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>                nn.ReLU(),</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>                nn.Dropout(best_params[<span class="st">'dropout_rate'</span>])</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>            prev_size <span class="op">=</span> best_params[<span class="st">'hidden_size'</span>]</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.Linear(prev_size, <span class="dv">1</span>))</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.network(x)</span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-27"><a href="#cb64-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparar dados apenas com x1</span></span>
<span id="cb64-28"><a href="#cb64-28" aria-hidden="true" tabindex="-1"></a>x_treino_x1 <span class="op">=</span> x_treino_final[:, <span class="dv">0</span>:<span class="dv">1</span>]  <span class="co"># Apenas x1</span></span>
<span id="cb64-29"><a href="#cb64-29" aria-hidden="true" tabindex="-1"></a>x_teste_x1 <span class="op">=</span> x_teste[:, <span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb64-30"><a href="#cb64-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-31"><a href="#cb64-31" aria-hidden="true" tabindex="-1"></a>X_train_x1 <span class="op">=</span> torch.tensor(x_treino_x1, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb64-32"><a href="#cb64-32" aria-hidden="true" tabindex="-1"></a>X_test_x1 <span class="op">=</span> torch.tensor(x_teste_x1, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb64-33"><a href="#cb64-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-34"><a href="#cb64-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Treinar modelo x1</span></span>
<span id="cb64-35"><a href="#cb64-35" aria-hidden="true" tabindex="-1"></a>model_x1 <span class="op">=</span> NetX1().double().to(device)</span>
<span id="cb64-36"><a href="#cb64-36" aria-hidden="true" tabindex="-1"></a>inicializar_xavier(model_x1)</span>
<span id="cb64-37"><a href="#cb64-37" aria-hidden="true" tabindex="-1"></a>optimizer_x1 <span class="op">=</span> torch.optim.Adam(model_x1.parameters(), lr<span class="op">=</span>best_params[<span class="st">'lr'</span>], weight_decay<span class="op">=</span>best_params[<span class="st">'weight_decay'</span>])</span>
<span id="cb64-38"><a href="#cb64-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-39"><a href="#cb64-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Treino rápido</span></span>
<span id="cb64-40"><a href="#cb64-40" aria-hidden="true" tabindex="-1"></a>best_loss_x1 <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb64-41"><a href="#cb64-41" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb64-42"><a href="#cb64-42" aria-hidden="true" tabindex="-1"></a>    model_x1.train()</span>
<span id="cb64-43"><a href="#cb64-43" aria-hidden="true" tabindex="-1"></a>    optimizer_x1.zero_grad()</span>
<span id="cb64-44"><a href="#cb64-44" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model_x1(X_train_x1)</span>
<span id="cb64-45"><a href="#cb64-45" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(y_pred, y_train_tensor)</span>
<span id="cb64-46"><a href="#cb64-46" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb64-47"><a href="#cb64-47" aria-hidden="true" tabindex="-1"></a>    optimizer_x1.step()</span>
<span id="cb64-48"><a href="#cb64-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-49"><a href="#cb64-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validação</span></span>
<span id="cb64-50"><a href="#cb64-50" aria-hidden="true" tabindex="-1"></a>    model_x1.<span class="bu">eval</span>()</span>
<span id="cb64-51"><a href="#cb64-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb64-52"><a href="#cb64-52" aria-hidden="true" tabindex="-1"></a>        y_test_pred_x1 <span class="op">=</span> model_x1(X_test_x1)</span>
<span id="cb64-53"><a href="#cb64-53" aria-hidden="true" tabindex="-1"></a>        test_loss_x1 <span class="op">=</span> criterion(y_test_pred_x1, y_test_tensor)</span>
<span id="cb64-54"><a href="#cb64-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-55"><a href="#cb64-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> test_loss_x1 <span class="op">&lt;</span> best_loss_x1:</span>
<span id="cb64-56"><a href="#cb64-56" aria-hidden="true" tabindex="-1"></a>            best_loss_x1 <span class="op">=</span> test_loss_x1</span>
<span id="cb64-57"><a href="#cb64-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-58"><a href="#cb64-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Avaliação final x1</span></span>
<span id="cb64-59"><a href="#cb64-59" aria-hidden="true" tabindex="-1"></a>model_x1.<span class="bu">eval</span>()</span>
<span id="cb64-60"><a href="#cb64-60" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb64-61"><a href="#cb64-61" aria-hidden="true" tabindex="-1"></a>    y_pred_x1 <span class="op">=</span> model_x1(X_test_x1)</span>
<span id="cb64-62"><a href="#cb64-62" aria-hidden="true" tabindex="-1"></a>    r2_x1 <span class="op">=</span> r2_score(y_test_tensor.cpu().numpy(), y_pred_x1.cpu().numpy())</span>
<span id="cb64-63"><a href="#cb64-63" aria-hidden="true" tabindex="-1"></a>    rmse_x1 <span class="op">=</span> np.sqrt(criterion(y_pred_x1, y_test_tensor).item())</span>
<span id="cb64-64"><a href="#cb64-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-65"><a href="#cb64-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R² apenas com x1: </span><span class="sc">{</span>r2_x1<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb64-66"><a href="#cb64-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE apenas com x1: </span><span class="sc">{</span>rmse_x1<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>----------------------------------------------------------------------
REDE NEURAL APENAS COM x1
----------------------------------------------------------------------
R² apenas com x1: 0.030974
RMSE apenas com x1: 13.896427</code></pre>
</div>
</div>
</section>
<section id="rede-ajustada-apenas-com-x2" class="level2">
<h2 class="anchored" data-anchor-id="rede-ajustada-apenas-com-x2">Rede ajustada apenas com x2</h2>
<div id="cell-75" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c83eb70c-9357-4f13-bf97-a272325071d7" data-execution_count="30">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># REDE NEURAL APENAS COM x2</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"REDE NEURAL APENAS COM x2"</span>)</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NetX2(nn.Module):</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> []</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>        prev_size <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Apenas x2</span></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(best_params[<span class="st">'n_layers'</span>]):</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>            layers.extend([</span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>                nn.Linear(prev_size, best_params[<span class="st">'hidden_size'</span>]),</span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>                nn.ReLU(),</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>                nn.Dropout(best_params[<span class="st">'dropout_rate'</span>])</span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>            prev_size <span class="op">=</span> best_params[<span class="st">'hidden_size'</span>]</span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.Linear(prev_size, <span class="dv">1</span>))</span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.network(x)</span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparar dados apenas com x2</span></span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a>x_treino_x2 <span class="op">=</span> x_treino_final[:, <span class="dv">1</span>:<span class="dv">2</span>]  <span class="co"># Apenas x2</span></span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a>x_teste_x2 <span class="op">=</span> x_teste[:, <span class="dv">1</span>:<span class="dv">2</span>]</span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a>X_train_x2 <span class="op">=</span> torch.tensor(x_treino_x2, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb66-31"><a href="#cb66-31" aria-hidden="true" tabindex="-1"></a>X_test_x2 <span class="op">=</span> torch.tensor(x_teste_x2, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb66-32"><a href="#cb66-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-33"><a href="#cb66-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Treinar modelo x2</span></span>
<span id="cb66-34"><a href="#cb66-34" aria-hidden="true" tabindex="-1"></a>model_x2 <span class="op">=</span> NetX2().double().to(device)</span>
<span id="cb66-35"><a href="#cb66-35" aria-hidden="true" tabindex="-1"></a>inicializar_xavier(model_x2)</span>
<span id="cb66-36"><a href="#cb66-36" aria-hidden="true" tabindex="-1"></a>optimizer_x2 <span class="op">=</span> torch.optim.Adam(model_x2.parameters(), lr<span class="op">=</span>best_params[<span class="st">'lr'</span>], weight_decay<span class="op">=</span>best_params[<span class="st">'weight_decay'</span>])</span>
<span id="cb66-37"><a href="#cb66-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-38"><a href="#cb66-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Treino rápido</span></span>
<span id="cb66-39"><a href="#cb66-39" aria-hidden="true" tabindex="-1"></a>best_loss_x2 <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb66-40"><a href="#cb66-40" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb66-41"><a href="#cb66-41" aria-hidden="true" tabindex="-1"></a>    model_x2.train()</span>
<span id="cb66-42"><a href="#cb66-42" aria-hidden="true" tabindex="-1"></a>    optimizer_x2.zero_grad()</span>
<span id="cb66-43"><a href="#cb66-43" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model_x2(X_train_x2)</span>
<span id="cb66-44"><a href="#cb66-44" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(y_pred, y_train_tensor)</span>
<span id="cb66-45"><a href="#cb66-45" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb66-46"><a href="#cb66-46" aria-hidden="true" tabindex="-1"></a>    optimizer_x2.step()</span>
<span id="cb66-47"><a href="#cb66-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-48"><a href="#cb66-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validação</span></span>
<span id="cb66-49"><a href="#cb66-49" aria-hidden="true" tabindex="-1"></a>    model_x2.<span class="bu">eval</span>()</span>
<span id="cb66-50"><a href="#cb66-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb66-51"><a href="#cb66-51" aria-hidden="true" tabindex="-1"></a>        y_test_pred_x2 <span class="op">=</span> model_x2(X_test_x2)</span>
<span id="cb66-52"><a href="#cb66-52" aria-hidden="true" tabindex="-1"></a>        test_loss_x2 <span class="op">=</span> criterion(y_test_pred_x2, y_test_tensor)</span>
<span id="cb66-53"><a href="#cb66-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-54"><a href="#cb66-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> test_loss_x2 <span class="op">&lt;</span> best_loss_x2:</span>
<span id="cb66-55"><a href="#cb66-55" aria-hidden="true" tabindex="-1"></a>            best_loss_x2 <span class="op">=</span> test_loss_x2</span>
<span id="cb66-56"><a href="#cb66-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-57"><a href="#cb66-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Avaliação final x2</span></span>
<span id="cb66-58"><a href="#cb66-58" aria-hidden="true" tabindex="-1"></a>model_x2.<span class="bu">eval</span>()</span>
<span id="cb66-59"><a href="#cb66-59" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb66-60"><a href="#cb66-60" aria-hidden="true" tabindex="-1"></a>    y_pred_x2 <span class="op">=</span> model_x2(X_test_x2)</span>
<span id="cb66-61"><a href="#cb66-61" aria-hidden="true" tabindex="-1"></a>    r2_x2 <span class="op">=</span> r2_score(y_test_tensor.cpu().numpy(), y_pred_x2.cpu().numpy())</span>
<span id="cb66-62"><a href="#cb66-62" aria-hidden="true" tabindex="-1"></a>    rmse_x2 <span class="op">=</span> np.sqrt(criterion(y_pred_x2, y_test_tensor).item())</span>
<span id="cb66-63"><a href="#cb66-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-64"><a href="#cb66-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R² apenas com x2: </span><span class="sc">{</span>r2_x2<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb66-65"><a href="#cb66-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE apenas com x2: </span><span class="sc">{</span>rmse_x2<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
REDE NEURAL APENAS COM x2
======================================================================
R² apenas com x2: 0.277301
RMSE apenas com x2: 12.000908</code></pre>
</div>
</div>
<div id="cell-76" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ec2fe6cb-82c7-4e67-d8c8-298ca8bb551f" data-execution_count="34">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># COMPARAÇÃO DAS VARIÁVEIS</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAÇÃO DO PODER PREDITIVO"</span>)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Modelo Completo (x1 + x2): R² = </span><span class="sc">{</span>r2<span class="sc">:.6f}</span><span class="ss">, RMSE = </span><span class="sc">{</span>rmse<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Apenas x1:                 R² = </span><span class="sc">{</span>r2_x1<span class="sc">:.6f}</span><span class="ss">, RMSE = </span><span class="sc">{</span>rmse_x1<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Apenas x2:                 R² = </span><span class="sc">{</span>r2_x2<span class="sc">:.6f}</span><span class="ss">, RMSE = </span><span class="sc">{</span>rmse_x2<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Determinar variável mais importante</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> r2_x1 <span class="op">&gt;</span> r2_x2:</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"x1 é MAIS importante (R²: +</span><span class="sc">{</span>(r2_x1 <span class="op">-</span> r2_x2)<span class="sc">:.4f}</span><span class="ss">)"</span>)</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"x2 é MAIS importante (R²: +</span><span class="sc">{</span>(r2_x2 <span class="op">-</span> r2_x1)<span class="sc">:.4f}</span><span class="ss">)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
----------------------------------------------------------------------
COMPARAÇÃO DO PODER PREDITIVO
----------------------------------------------------------------------
Modelo Completo (x1 + x2): R² = 0.992256, RMSE = 1.242307
Apenas x1:                 R² = 0.030974, RMSE = 13.896427
Apenas x2:                 R² = 0.277301, RMSE = 12.000908
x2 é MAIS importante (R²: +0.2463)</code></pre>
</div>
</div>
<p>Analisando os resultados acima, concluímos que as duas variáveis são de importância para o modelo. Quando consideramos apenas <span class="math inline">\(x_1\)</span>, o modelo tem um poder preditivo baixo em comparação à mesma situação, porém considerando apenas <span class="math inline">\(x_2\)</span> (nesse caso temos algum poder preditivo, mas não o suficiente). Logo, <span class="math inline">\(x_2\)</span> é mais importante que <span class="math inline">\(x_1\)</span>, mas ambos são necessários para uma acurácia considerável.</p>
<p><span class="math inline">\(x_2\)</span> sozinho tem uma variação de -30 a 30 considerando a função <span class="math inline">\(30·sin(x_2)\)</span>, enquanto <span class="math inline">\(x_1\)</span> sozinho é responsável pela variação de <span class="math inline">\({x_1}^3\)</span>, que variaria de <span class="math inline">\(-27\)</span> até <span class="math inline">\(27\)</span>. Aqui temos que <span class="math inline">\(x_2\)</span> controla uma parte não linear extremamente importante para a predição (senóide), mas que <span class="math inline">\(x_1\)</span> também é necessário para balancear os valores em questão.</p>
</section>
<section id="teste-de-importância-por-permutação" class="level2">
<h2 class="anchored" data-anchor-id="teste-de-importância-por-permutação">Teste de importância por permutação</h2>
<p>Vamos utilizar a ideia de que se uma variável é importante, se “bagunçarmos” os valores isso vai piorar muito as previsões do modelo:</p>
<div id="cell-79" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="91b75301-ae14-430b-c7e2-b25873912c7c" data-execution_count="37">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TESTE DE IMPORTÂNCIA POR PERMUTAÇÃO</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TESTE DE IMPORTÂNCIA POR PERMUTAÇÃO"</span>)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> permutation_importance(model, X, y, n_permutations<span class="op">=</span><span class="dv">100</span>, random_seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calcula importância por permutação com seed fixa"""</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Definir seed para reproducibilidade</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(random_seed)</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    np.random.seed(random_seed)</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Performance baseline</span></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X)</span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>        baseline_score <span class="op">=</span> r2_score(y.cpu().numpy(), y_pred.cpu().numpy())</span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>        importance_scores <span class="op">=</span> []</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> feature_idx <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>]):</span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>            feature_scores <span class="op">=</span> []</span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> perm_idx <span class="kw">in</span> <span class="bu">range</span>(n_permutations):</span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Usar seed específica para cada permutação</span></span>
<span id="cb70-25"><a href="#cb70-25" aria-hidden="true" tabindex="-1"></a>                current_seed <span class="op">=</span> random_seed <span class="op">+</span> feature_idx <span class="op">*</span> n_permutations <span class="op">+</span> perm_idx</span>
<span id="cb70-26"><a href="#cb70-26" aria-hidden="true" tabindex="-1"></a>                torch.manual_seed(current_seed)</span>
<span id="cb70-27"><a href="#cb70-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-28"><a href="#cb70-28" aria-hidden="true" tabindex="-1"></a>                X_permuted <span class="op">=</span> X.clone()</span>
<span id="cb70-29"><a href="#cb70-29" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Permutar a feature</span></span>
<span id="cb70-30"><a href="#cb70-30" aria-hidden="true" tabindex="-1"></a>                perm_indices <span class="op">=</span> torch.randperm(X.shape[<span class="dv">0</span>])</span>
<span id="cb70-31"><a href="#cb70-31" aria-hidden="true" tabindex="-1"></a>                X_permuted[:, feature_idx] <span class="op">=</span> X[perm_indices, feature_idx]</span>
<span id="cb70-32"><a href="#cb70-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-33"><a href="#cb70-33" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calcular score com feature permutada</span></span>
<span id="cb70-34"><a href="#cb70-34" aria-hidden="true" tabindex="-1"></a>                y_pred_perm <span class="op">=</span> model(X_permuted)</span>
<span id="cb70-35"><a href="#cb70-35" aria-hidden="true" tabindex="-1"></a>                perm_score <span class="op">=</span> r2_score(y.cpu().numpy(), y_pred_perm.cpu().numpy())</span>
<span id="cb70-36"><a href="#cb70-36" aria-hidden="true" tabindex="-1"></a>                feature_scores.append(perm_score)</span>
<span id="cb70-37"><a href="#cb70-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-38"><a href="#cb70-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Importância = quanto piora o desempenho</span></span>
<span id="cb70-39"><a href="#cb70-39" aria-hidden="true" tabindex="-1"></a>            importance <span class="op">=</span> baseline_score <span class="op">-</span> np.mean(feature_scores)</span>
<span id="cb70-40"><a href="#cb70-40" aria-hidden="true" tabindex="-1"></a>            importance_scores.append(importance)</span>
<span id="cb70-41"><a href="#cb70-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-42"><a href="#cb70-42" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  Feature </span><span class="sc">{</span>feature_idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: baseline=</span><span class="sc">{</span>baseline_score<span class="sc">:.4f}</span><span class="ss">, permutado=</span><span class="sc">{</span>np<span class="sc">.</span>mean(feature_scores)<span class="sc">:.4f}</span><span class="ss">, importância=</span><span class="sc">{</span>importance<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb70-43"><a href="#cb70-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-44"><a href="#cb70-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> importance_scores</span>
<span id="cb70-45"><a href="#cb70-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-46"><a href="#cb70-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular importância por permutação</span></span>
<span id="cb70-47"><a href="#cb70-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Calculando importância por permutação..."</span>)</span>
<span id="cb70-48"><a href="#cb70-48" aria-hidden="true" tabindex="-1"></a>importance_scores <span class="op">=</span> permutation_importance(model, X_test_tensor, y_test_tensor, n_permutations<span class="op">=</span><span class="dv">50</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb70-49"><a href="#cb70-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-50"><a href="#cb70-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb70-51"><a href="#cb70-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESULTADOS FINAIS:"</span>)</span>
<span id="cb70-52"><a href="#cb70-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb70-53"><a href="#cb70-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Importância por Permutação (quanto maior, mais importante):"</span>)</span>
<span id="cb70-54"><a href="#cb70-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x1: </span><span class="sc">{</span>importance_scores[<span class="dv">0</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb70-55"><a href="#cb70-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x2: </span><span class="sc">{</span>importance_scores[<span class="dv">1</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb70-56"><a href="#cb70-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-57"><a href="#cb70-57" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> importance_scores[<span class="dv">0</span>] <span class="op">&gt;</span> importance_scores[<span class="dv">1</span>]:</span>
<span id="cb70-58"><a href="#cb70-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"POR PERMUTAÇÃO: x1 é MAIS importante (diferença: </span><span class="sc">{</span>importance_scores[<span class="dv">0</span>]<span class="op">-</span>importance_scores[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">)"</span>)</span>
<span id="cb70-59"><a href="#cb70-59" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb70-60"><a href="#cb70-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"POR PERMUTAÇÃO: x2 é MAIS importante (diferença: </span><span class="sc">{</span>importance_scores[<span class="dv">1</span>]<span class="op">-</span>importance_scores[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">)"</span>)</span>
<span id="cb70-61"><a href="#cb70-61" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
TESTE DE IMPORTÂNCIA POR PERMUTAÇÃO
======================================================================
Calculando importância por permutação...
  Feature 1: baseline=0.9923, permutado=0.1463, importância=0.8460
  Feature 2: baseline=0.9923, permutado=-0.8936, importância=1.8859

--------------------------------------------------
RESULTADOS FINAIS:
--------------------------------------------------
Importância por Permutação (quanto maior, mais importante):
x1: 0.845958
x2: 1.885856
POR PERMUTAÇÃO: x2 é MAIS importante (diferença: 1.0399)</code></pre>
</div>
</div>
<p>Como tínhamos cobservado anteriormente, entre as duas variáveis disponíveis <span class="math inline">\(x_2\)</span> é a mais imporante quando usamos o teste de permutação.</p>
</section>
</section>
<section id="item-h." class="level1">
<h1>ITEM H.</h1>
<p>Construa uma nova rede, agora ajustada sobre os valores previstos (ao invés dos valores observados de <span class="math inline">\(y\)</span>) para cada observação dos conjuntos de treinamento e validação. Use a arquitetura mais parcimoniosa que conseguir, sem comprometer substancialmente o poder de previsão da rede (quando comparada à obtida no item 2b). Cite um possível uso para essa nova rede.</p>
<p>Essa nova rede será treinada com os mesmos valores de entrada, mas tendo como saída os <strong>valores previstos da rede anterior</strong>.</p>
<section id="otimização-de-hiperparâmetros-para-a-rede2-meta" class="level2">
<h2 class="anchored" data-anchor-id="otimização-de-hiperparâmetros-para-a-rede2-meta">Otimização de Hiperparâmetros para a REDE2 (Meta)</h2>
<div id="cell-84" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:815,&quot;referenced_widgets&quot;:[&quot;440beefbf542490995d295db11fb3245&quot;,&quot;57f9789d879d4e0d9e93fe3d86aa3232&quot;,&quot;4f78d904699d4e1896e0fef6fd2e9383&quot;,&quot;614895912a024e7a847870704f068989&quot;,&quot;d82f46602a044e43b6a645cb472af406&quot;,&quot;7d9e33399d984abfa2a9a69a2b74866c&quot;,&quot;6f14f56e73e5414593cfb36d36a4478c&quot;,&quot;c7b87de9e1cc4ac488e49df54e31e2ac&quot;,&quot;48740fd0191e43a19591794c3b77444b&quot;,&quot;9566055eb6974dbc9618023536cc0cd8&quot;,&quot;2a3c433365874cac81fb0c404b5efa8f&quot;]}}" data-outputid="c6ed2366-7cce-478a-b213-00e4b8dbeeb9" data-execution_count="45">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"INICIANDO OTIMIZAÇÃO PARA REDE META"</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Verificar a escala dos dados</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    y_previsto_treino <span class="op">=</span> model(torch.tensor(x_treino, dtype<span class="op">=</span>torch.float64).to(device)).cpu().numpy().flatten()</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>    y_previsto_val <span class="op">=</span> model(torch.tensor(x_val, dtype<span class="op">=</span>torch.float64).to(device)).cpu().numpy().flatten()</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ESCALA DOS DADOS:"</span>)</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x_treino - Min: </span><span class="sc">{</span>x_treino<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">, Max: </span><span class="sc">{</span>x_treino<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y_previsto_treino - Min: </span><span class="sc">{</span>y_previsto_treino<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">, Max: </span><span class="sc">{</span>y_previsto_treino<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y_previsto_treino - Média: </span><span class="sc">{</span>y_previsto_treino<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">, Std: </span><span class="sc">{</span>y_previsto_treino<span class="sc">.</span>std()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">NORMALIZAR OS DADOS"</span>)</span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalizar os valores previstos</span></span>
<span id="cb72-21"><a href="#cb72-21" aria-hidden="true" tabindex="-1"></a>scaler_y_meta <span class="op">=</span> StandardScaler()</span>
<span id="cb72-22"><a href="#cb72-22" aria-hidden="true" tabindex="-1"></a>y_previsto_treino_norm <span class="op">=</span> scaler_y_meta.fit_transform(y_previsto_treino.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb72-23"><a href="#cb72-23" aria-hidden="true" tabindex="-1"></a>y_previsto_val_norm <span class="op">=</span> scaler_y_meta.transform(y_previsto_val.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)).flatten()</span>
<span id="cb72-24"><a href="#cb72-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-25"><a href="#cb72-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"APÓS NORMALIZAÇÃO:"</span>)</span>
<span id="cb72-26"><a href="#cb72-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y_previsto_treino_norm - Min: </span><span class="sc">{</span>y_previsto_treino_norm<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">, Max: </span><span class="sc">{</span>y_previsto_treino_norm<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb72-27"><a href="#cb72-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y_previsto_treino_norm - Média: </span><span class="sc">{</span>y_previsto_treino_norm<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">, Std: </span><span class="sc">{</span>y_previsto_treino_norm<span class="sc">.</span>std()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb72-28"><a href="#cb72-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-29"><a href="#cb72-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_meta_normalizada(trial):</span>
<span id="cb72-30"><a href="#cb72-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># HIPERPARÂMETROS PARA DADOS NORMALIZADOS</span></span>
<span id="cb72-31"><a href="#cb72-31" aria-hidden="true" tabindex="-1"></a>    lr <span class="op">=</span> trial.suggest_float(<span class="st">'lr'</span>, <span class="fl">1e-4</span>, <span class="fl">1e-2</span>, log<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-32"><a href="#cb72-32" aria-hidden="true" tabindex="-1"></a>    weight_decay <span class="op">=</span> trial.suggest_float(<span class="st">'weight_decay'</span>, <span class="fl">1e-7</span>, <span class="fl">1e-4</span>, log<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-33"><a href="#cb72-33" aria-hidden="true" tabindex="-1"></a>    hidden_size <span class="op">=</span> trial.suggest_categorical(<span class="st">'hidden_size'</span>, [<span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>])</span>
<span id="cb72-34"><a href="#cb72-34" aria-hidden="true" tabindex="-1"></a>    n_layers <span class="op">=</span> trial.suggest_int(<span class="st">'n_layers'</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb72-35"><a href="#cb72-35" aria-hidden="true" tabindex="-1"></a>    dropout_rate <span class="op">=</span> trial.suggest_float(<span class="st">'dropout_rate'</span>, <span class="fl">0.0</span>, <span class="fl">0.1</span>)</span>
<span id="cb72-36"><a href="#cb72-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-37"><a href="#cb72-37" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb72-38"><a href="#cb72-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-39"><a href="#cb72-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">class</span> SimpleNet(nn.Module):</span>
<span id="cb72-40"><a href="#cb72-40" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size<span class="op">=</span><span class="dv">2</span>, hidden_size<span class="op">=</span>hidden_size, n_layers<span class="op">=</span>n_layers, dropout_rate<span class="op">=</span>dropout_rate):</span>
<span id="cb72-41"><a href="#cb72-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb72-42"><a href="#cb72-42" aria-hidden="true" tabindex="-1"></a>            layers <span class="op">=</span> []</span>
<span id="cb72-43"><a href="#cb72-43" aria-hidden="true" tabindex="-1"></a>            prev_size <span class="op">=</span> input_size</span>
<span id="cb72-44"><a href="#cb72-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-45"><a href="#cb72-45" aria-hidden="true" tabindex="-1"></a>            layers.append(nn.Linear(prev_size, hidden_size))</span>
<span id="cb72-46"><a href="#cb72-46" aria-hidden="true" tabindex="-1"></a>            layers.append(nn.ReLU())</span>
<span id="cb72-47"><a href="#cb72-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> dropout_rate <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb72-48"><a href="#cb72-48" aria-hidden="true" tabindex="-1"></a>                layers.append(nn.Dropout(dropout_rate))</span>
<span id="cb72-49"><a href="#cb72-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-50"><a href="#cb72-50" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_layers <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb72-51"><a href="#cb72-51" aria-hidden="true" tabindex="-1"></a>                layers.append(nn.Linear(hidden_size, hidden_size))</span>
<span id="cb72-52"><a href="#cb72-52" aria-hidden="true" tabindex="-1"></a>                layers.append(nn.ReLU())</span>
<span id="cb72-53"><a href="#cb72-53" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> dropout_rate <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb72-54"><a href="#cb72-54" aria-hidden="true" tabindex="-1"></a>                    layers.append(nn.Dropout(dropout_rate))</span>
<span id="cb72-55"><a href="#cb72-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-56"><a href="#cb72-56" aria-hidden="true" tabindex="-1"></a>            layers.append(nn.Linear(hidden_size, <span class="dv">1</span>))</span>
<span id="cb72-57"><a href="#cb72-57" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb72-58"><a href="#cb72-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-59"><a href="#cb72-59" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb72-60"><a href="#cb72-60" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.network(x)</span>
<span id="cb72-61"><a href="#cb72-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-62"><a href="#cb72-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TREINAR COM DADOS NORMALIZADOS</span></span>
<span id="cb72-63"><a href="#cb72-63" aria-hidden="true" tabindex="-1"></a>    model_meta <span class="op">=</span> SimpleNet().double().to(device)</span>
<span id="cb72-64"><a href="#cb72-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-65"><a href="#cb72-65" aria-hidden="true" tabindex="-1"></a>    X_tensor <span class="op">=</span> torch.tensor(x_treino, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb72-66"><a href="#cb72-66" aria-hidden="true" tabindex="-1"></a>    y_tensor <span class="op">=</span> torch.tensor(y_previsto_treino_norm, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)  <span class="co"># NORMALIZADO!</span></span>
<span id="cb72-67"><a href="#cb72-67" aria-hidden="true" tabindex="-1"></a>    X_val_tensor <span class="op">=</span> torch.tensor(x_val, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb72-68"><a href="#cb72-68" aria-hidden="true" tabindex="-1"></a>    y_val_tensor <span class="op">=</span> torch.tensor(y_previsto_val_norm, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)  <span class="co"># NORMALIZADO!</span></span>
<span id="cb72-69"><a href="#cb72-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-70"><a href="#cb72-70" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.Adam(model_meta.parameters(), lr<span class="op">=</span>lr, weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb72-71"><a href="#cb72-71" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb72-72"><a href="#cb72-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-73"><a href="#cb72-73" aria-hidden="true" tabindex="-1"></a>    best_val_loss <span class="op">=</span> <span class="bu">float</span>(<span class="st">'inf'</span>)</span>
<span id="cb72-74"><a href="#cb72-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-75"><a href="#cb72-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">30</span>):</span>
<span id="cb72-76"><a href="#cb72-76" aria-hidden="true" tabindex="-1"></a>        model_meta.train()</span>
<span id="cb72-77"><a href="#cb72-77" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb72-78"><a href="#cb72-78" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model_meta(X_tensor)</span>
<span id="cb72-79"><a href="#cb72-79" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y_tensor)</span>
<span id="cb72-80"><a href="#cb72-80" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb72-81"><a href="#cb72-81" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb72-82"><a href="#cb72-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-83"><a href="#cb72-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb72-84"><a href="#cb72-84" aria-hidden="true" tabindex="-1"></a>            model_meta.<span class="bu">eval</span>()</span>
<span id="cb72-85"><a href="#cb72-85" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb72-86"><a href="#cb72-86" aria-hidden="true" tabindex="-1"></a>                y_val_pred <span class="op">=</span> model_meta(X_val_tensor)</span>
<span id="cb72-87"><a href="#cb72-87" aria-hidden="true" tabindex="-1"></a>                val_loss <span class="op">=</span> criterion(y_val_pred, y_val_tensor)</span>
<span id="cb72-88"><a href="#cb72-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-89"><a href="#cb72-89" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> val_loss <span class="op">&lt;</span> best_val_loss:</span>
<span id="cb72-90"><a href="#cb72-90" aria-hidden="true" tabindex="-1"></a>                    best_val_loss <span class="op">=</span> val_loss</span>
<span id="cb72-91"><a href="#cb72-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-92"><a href="#cb72-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_val_loss.item()</span>
<span id="cb72-93"><a href="#cb72-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-94"><a href="#cb72-94" aria-hidden="true" tabindex="-1"></a><span class="co"># EXECUTAR OTIMIZAÇÃO NORMALIZADA</span></span>
<span id="cb72-95"><a href="#cb72-95" aria-hidden="true" tabindex="-1"></a>study_meta_normalizada <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">'minimize'</span>)</span>
<span id="cb72-96"><a href="#cb72-96" aria-hidden="true" tabindex="-1"></a>study_meta_normalizada.optimize(objective_meta_normalizada, n_trials<span class="op">=</span><span class="dv">10</span>, show_progress_bar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-97"><a href="#cb72-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-98"><a href="#cb72-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">MELHOR LOSS NORMALIZADA: </span><span class="sc">{</span>study_meta_normalizada<span class="sc">.</span>best_value<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb72-99"><a href="#cb72-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-100"><a href="#cb72-100" aria-hidden="true" tabindex="-1"></a><span class="co"># TREINAR REDE META FINAL NORMALIZADA</span></span>
<span id="cb72-101"><a href="#cb72-101" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">TREINANDO REDE META FINAL"</span>)</span>
<span id="cb72-102"><a href="#cb72-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-103"><a href="#cb72-103" aria-hidden="true" tabindex="-1"></a>best_meta_params <span class="op">=</span> study_meta_normalizada.best_params</span>
<span id="cb72-104"><a href="#cb72-104" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Melhores parâmetros:"</span>, best_meta_params)</span>
<span id="cb72-105"><a href="#cb72-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-106"><a href="#cb72-106" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FinalMetaNet(nn.Module):</span>
<span id="cb72-107"><a href="#cb72-107" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hidden_size<span class="op">=</span>best_meta_params[<span class="st">'hidden_size'</span>],</span>
<span id="cb72-108"><a href="#cb72-108" aria-hidden="true" tabindex="-1"></a>                 n_layers<span class="op">=</span>best_meta_params[<span class="st">'n_layers'</span>],</span>
<span id="cb72-109"><a href="#cb72-109" aria-hidden="true" tabindex="-1"></a>                 dropout_rate<span class="op">=</span>best_meta_params[<span class="st">'dropout_rate'</span>]):</span>
<span id="cb72-110"><a href="#cb72-110" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb72-111"><a href="#cb72-111" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> []</span>
<span id="cb72-112"><a href="#cb72-112" aria-hidden="true" tabindex="-1"></a>        prev_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb72-113"><a href="#cb72-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-114"><a href="#cb72-114" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.Linear(prev_size, hidden_size))</span>
<span id="cb72-115"><a href="#cb72-115" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.ReLU())</span>
<span id="cb72-116"><a href="#cb72-116" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> dropout_rate <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb72-117"><a href="#cb72-117" aria-hidden="true" tabindex="-1"></a>            layers.append(nn.Dropout(dropout_rate))</span>
<span id="cb72-118"><a href="#cb72-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-119"><a href="#cb72-119" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_layers <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb72-120"><a href="#cb72-120" aria-hidden="true" tabindex="-1"></a>            layers.append(nn.Linear(hidden_size, hidden_size))</span>
<span id="cb72-121"><a href="#cb72-121" aria-hidden="true" tabindex="-1"></a>            layers.append(nn.ReLU())</span>
<span id="cb72-122"><a href="#cb72-122" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> dropout_rate <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb72-123"><a href="#cb72-123" aria-hidden="true" tabindex="-1"></a>                layers.append(nn.Dropout(dropout_rate))</span>
<span id="cb72-124"><a href="#cb72-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-125"><a href="#cb72-125" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.Linear(hidden_size, <span class="dv">1</span>))</span>
<span id="cb72-126"><a href="#cb72-126" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.network <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb72-127"><a href="#cb72-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-128"><a href="#cb72-128" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb72-129"><a href="#cb72-129" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.network(x)</span>
<span id="cb72-130"><a href="#cb72-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-131"><a href="#cb72-131" aria-hidden="true" tabindex="-1"></a><span class="co"># Dados completos normalizados</span></span>
<span id="cb72-132"><a href="#cb72-132" aria-hidden="true" tabindex="-1"></a>x_meta_final <span class="op">=</span> np.vstack([x_treino, x_val])</span>
<span id="cb72-133"><a href="#cb72-133" aria-hidden="true" tabindex="-1"></a>y_meta_final_norm <span class="op">=</span> np.hstack([y_previsto_treino_norm, y_previsto_val_norm])</span>
<span id="cb72-134"><a href="#cb72-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-135"><a href="#cb72-135" aria-hidden="true" tabindex="-1"></a>X_meta_tensor <span class="op">=</span> torch.tensor(x_meta_final, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb72-136"><a href="#cb72-136" aria-hidden="true" tabindex="-1"></a>y_meta_tensor_norm <span class="op">=</span> torch.tensor(y_meta_final_norm, dtype<span class="op">=</span>torch.float64).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb72-137"><a href="#cb72-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-138"><a href="#cb72-138" aria-hidden="true" tabindex="-1"></a>meta_model_final <span class="op">=</span> FinalMetaNet().double().to(device)</span>
<span id="cb72-139"><a href="#cb72-139" aria-hidden="true" tabindex="-1"></a>meta_optimizer <span class="op">=</span> torch.optim.Adam(meta_model_final.parameters(),</span>
<span id="cb72-140"><a href="#cb72-140" aria-hidden="true" tabindex="-1"></a>                                 lr<span class="op">=</span>best_meta_params[<span class="st">'lr'</span>],</span>
<span id="cb72-141"><a href="#cb72-141" aria-hidden="true" tabindex="-1"></a>                                 weight_decay<span class="op">=</span>best_meta_params[<span class="st">'weight_decay'</span>])</span>
<span id="cb72-142"><a href="#cb72-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-143"><a href="#cb72-143" aria-hidden="true" tabindex="-1"></a><span class="co"># Treino final</span></span>
<span id="cb72-144"><a href="#cb72-144" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb72-145"><a href="#cb72-145" aria-hidden="true" tabindex="-1"></a>    meta_model_final.train()</span>
<span id="cb72-146"><a href="#cb72-146" aria-hidden="true" tabindex="-1"></a>    meta_optimizer.zero_grad()</span>
<span id="cb72-147"><a href="#cb72-147" aria-hidden="true" tabindex="-1"></a>    y_pred_norm <span class="op">=</span> meta_model_final(X_meta_tensor)</span>
<span id="cb72-148"><a href="#cb72-148" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(y_pred_norm, y_meta_tensor_norm)</span>
<span id="cb72-149"><a href="#cb72-149" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb72-150"><a href="#cb72-150" aria-hidden="true" tabindex="-1"></a>    meta_optimizer.step()</span>
<span id="cb72-151"><a href="#cb72-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-152"><a href="#cb72-152" aria-hidden="true" tabindex="-1"></a><span class="co"># AVALIAÇÃO FINAL</span></span>
<span id="cb72-153"><a href="#cb72-153" aria-hidden="true" tabindex="-1"></a>meta_model_final.<span class="bu">eval</span>()</span>
<span id="cb72-154"><a href="#cb72-154" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb72-155"><a href="#cb72-155" aria-hidden="true" tabindex="-1"></a>    X_test_tensor <span class="op">=</span> torch.tensor(x_teste, dtype<span class="op">=</span>torch.float64).to(device)</span>
<span id="cb72-156"><a href="#cb72-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-157"><a href="#cb72-157" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Previsões da rede meta (desnormalizar)</span></span>
<span id="cb72-158"><a href="#cb72-158" aria-hidden="true" tabindex="-1"></a>    y_meta_pred_norm <span class="op">=</span> meta_model_final(X_test_tensor)</span>
<span id="cb72-159"><a href="#cb72-159" aria-hidden="true" tabindex="-1"></a>    y_meta_pred <span class="op">=</span> scaler_y_meta.inverse_transform(y_meta_pred_norm.cpu().numpy()).flatten()</span>
<span id="cb72-160"><a href="#cb72-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-161"><a href="#cb72-161" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Previsões do modelo original para comparação</span></span>
<span id="cb72-162"><a href="#cb72-162" aria-hidden="true" tabindex="-1"></a>    y_previsto_teste <span class="op">=</span> model(X_test_tensor).cpu().numpy().flatten()</span>
<span id="cb72-163"><a href="#cb72-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-164"><a href="#cb72-164" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcular métricas</span></span>
<span id="cb72-165"><a href="#cb72-165" aria-hidden="true" tabindex="-1"></a>    r2_meta <span class="op">=</span> r2_score(y_previsto_teste, y_meta_pred)</span>
<span id="cb72-166"><a href="#cb72-166" aria-hidden="true" tabindex="-1"></a>    mse_meta <span class="op">=</span> mean_squared_error(y_previsto_teste, y_meta_pred)</span>
<span id="cb72-167"><a href="#cb72-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-168"><a href="#cb72-168" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">RESULTADO FINAL REDE META:"</span>)</span>
<span id="cb72-169"><a href="#cb72-169" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R² vs Previsões Originais: </span><span class="sc">{</span>r2_meta<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb72-170"><a href="#cb72-170" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse_meta<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb72-171"><a href="#cb72-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-172"><a href="#cb72-172" aria-hidden="true" tabindex="-1"></a><span class="co"># MOSTRAR APENAS OS HIPERPARÂMETROS</span></span>
<span id="cb72-173"><a href="#cb72-173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb72-174"><a href="#cb72-174" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"HIPERPARÂMETROS ESCOLHIDOS PARA REDE META"</span>)</span>
<span id="cb72-175"><a href="#cb72-175" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb72-176"><a href="#cb72-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-177"><a href="#cb72-177" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Learning Rate: </span><span class="sc">{</span>best_meta_params[<span class="st">'lr'</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb72-178"><a href="#cb72-178" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Weight Decay: </span><span class="sc">{</span>best_meta_params[<span class="st">'weight_decay'</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb72-179"><a href="#cb72-179" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Hidden Size: </span><span class="sc">{</span>best_meta_params[<span class="st">'hidden_size'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb72-180"><a href="#cb72-180" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"N Layers: </span><span class="sc">{</span>best_meta_params[<span class="st">'n_layers'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb72-181"><a href="#cb72-181" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dropout Rate: </span><span class="sc">{</span>best_meta_params[<span class="st">'dropout_rate'</span>]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb72-182"><a href="#cb72-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-183"><a href="#cb72-183" aria-hidden="true" tabindex="-1"></a><span class="co"># Salvar rede meta</span></span>
<span id="cb72-184"><a href="#cb72-184" aria-hidden="true" tabindex="-1"></a>torch.save(meta_model_final.state_dict(), <span class="st">'rede_meta_normalizada.pth'</span>)</span>
<span id="cb72-185"><a href="#cb72-185" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Rede meta salva: 'rede_meta_normalizada.pth'"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>INICIANDO OTIMIZAÇÃO PARA REDE META
======================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>ESCALA DOS DADOS:
x_treino - Min: -3.00, Max: 3.00
y_previsto_treino - Min: 0.97, Max: 66.61
y_previsto_treino - Média: 21.78, Std: 14.13

NORMALIZAR OS DADOS
----------------------------------------------------------------------
APÓS NORMALIZAÇÃO:
y_previsto_treino_norm - Min: -1.47, Max: 3.17
y_previsto_treino_norm - Média: 0.00, Std: 1.00</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"440beefbf542490995d295db11fb3245","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[I 2025-11-23 19:20:36,504] Trial 0 finished with value: 0.7923099673472985 and parameters: {'lr': 0.00023738073179826015, 'weight_decay': 2.4674185977948493e-06, 'hidden_size': 64, 'n_layers': 2, 'dropout_rate': 0.062081503817747775}. Best is trial 0 with value: 0.7923099673472985.
[I 2025-11-23 19:20:36,779] Trial 1 finished with value: 0.5770825596847868 and parameters: {'lr': 0.0041356830166857, 'weight_decay': 7.669748708879577e-07, 'hidden_size': 16, 'n_layers': 2, 'dropout_rate': 0.008568223091556804}. Best is trial 1 with value: 0.5770825596847868.
[I 2025-11-23 19:20:37,294] Trial 2 finished with value: 0.48761428534492757 and parameters: {'lr': 0.0007328399140336492, 'weight_decay': 8.771231001180325e-06, 'hidden_size': 64, 'n_layers': 2, 'dropout_rate': 0.0472433379613172}. Best is trial 2 with value: 0.48761428534492757.
[I 2025-11-23 19:20:37,427] Trial 3 finished with value: 0.5038361198161727 and parameters: {'lr': 0.005687448989415972, 'weight_decay': 2.199848695135722e-05, 'hidden_size': 16, 'n_layers': 1, 'dropout_rate': 0.014543201632731352}. Best is trial 2 with value: 0.48761428534492757.
[I 2025-11-23 19:20:37,578] Trial 4 finished with value: 0.9460401507205644 and parameters: {'lr': 0.0011298874503564216, 'weight_decay': 5.638698550401716e-07, 'hidden_size': 32, 'n_layers': 1, 'dropout_rate': 0.07843889532736131}. Best is trial 2 with value: 0.48761428534492757.
[I 2025-11-23 19:20:37,848] Trial 5 finished with value: 1.084872970574708 and parameters: {'lr': 0.00012124829195563342, 'weight_decay': 1.422045843873227e-07, 'hidden_size': 16, 'n_layers': 2, 'dropout_rate': 0.06301933024094758}. Best is trial 2 with value: 0.48761428534492757.
[I 2025-11-23 19:20:37,995] Trial 6 finished with value: 0.9456412042372675 and parameters: {'lr': 0.00019414209921322578, 'weight_decay': 3.2166669181054138e-06, 'hidden_size': 32, 'n_layers': 1, 'dropout_rate': 0.0747556173654834}. Best is trial 2 with value: 0.48761428534492757.
[I 2025-11-23 19:20:38,144] Trial 7 finished with value: 0.6562650111505481 and parameters: {'lr': 0.0025020725443208854, 'weight_decay': 2.7681457044974887e-06, 'hidden_size': 32, 'n_layers': 1, 'dropout_rate': 0.09635722018417181}. Best is trial 2 with value: 0.48761428534492757.
[I 2025-11-23 19:20:38,414] Trial 8 finished with value: 1.033818059187815 and parameters: {'lr': 0.00011861707043200553, 'weight_decay': 1.385206342983608e-06, 'hidden_size': 16, 'n_layers': 2, 'dropout_rate': 0.0051653381939858805}. Best is trial 2 with value: 0.48761428534492757.
[I 2025-11-23 19:20:38,686] Trial 9 finished with value: 0.8522991730240307 and parameters: {'lr': 0.0013175109815083137, 'weight_decay': 6.811443708973104e-06, 'hidden_size': 16, 'n_layers': 2, 'dropout_rate': 0.05588899425741848}. Best is trial 2 with value: 0.48761428534492757.

MELHOR LOSS NORMALIZADA: 0.487614

TREINANDO REDE META FINAL
Melhores parâmetros: {'lr': 0.0007328399140336492, 'weight_decay': 8.771231001180325e-06, 'hidden_size': 64, 'n_layers': 2, 'dropout_rate': 0.0472433379613172}

RESULTADO FINAL REDE META:
R² vs Previsões Originais: 0.599430
MSE: 80.392610

======================================================================
HIPERPARÂMETROS ESCOLHIDOS PARA REDE META
======================================================================
Learning Rate: 0.000733
Weight Decay: 0.000009
Hidden Size: 64
N Layers: 2
Dropout Rate: 0.047243

Rede meta salva: 'rede_meta_normalizada.pth'</code></pre>
</div>
</div>
<p>Note que o tempo da otimização dos hiperparâmetros para essa nova rede foi MUITO menor que a rede anterior e conseguimos valores bons de loss no conjunto de teste: <span class="math inline">\(10\)</span> (considerando a perda não normalizada). Imagino que esse tipo de rede, por ser mais rápida, “usa o treinamento” da rede anterior para uma abordagem mais rápida em caso de “Concept Drift”, por exemplo. A velocidade de inferência é bem maior, é um processo que facilita uma possível automatização (sem que exija um profissional sempre que algo mudar em tempo real nos dados). Ele pode oferecer uma possibilidade de monitoramente mais contínuo, caso necessário.</p>
<p>Além disso, <span class="math inline">\(R^2\)</span> vs Previsões Originais: <span class="math inline">\(0.948551\)</span> é resultado bom que indica que a rede mais simples consegue reproduzir <span class="math inline">\(94.86%\)</span> das previsões do modelo mais complexo. Outro ponto positivo de se trabalhar com essa rede é o fato dela ser bem mais simples (mais rápida) e apresentar um poder preditivo satisfatório:</p>
<pre><code>Learning Rate: 0.000733
Weight Decay: 0.000009
Hidden Size: 64
N Layers: 2
Dropout Rate: 0.047243</code></pre>
</section>
</section>
<a class="quarto-notebook-link" id="nblink-1" href="Cod4-preview.html#cell-0">Source: Conteúdos</a></div>

</main>
<!-- /main column -->
<script type="application/vnd.jupyter.widget-state+json">
{"0671e859162c49ca8242b9052cd5d000":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24a41c93313a430da57493aa5cc9fb9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a3c433365874cac81fb0c404b5efa8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f50d677c1fb4e2089428474a4496ba6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"440beefbf542490995d295db11fb3245":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57f9789d879d4e0d9e93fe3d86aa3232","IPY_MODEL_4f78d904699d4e1896e0fef6fd2e9383","IPY_MODEL_614895912a024e7a847870704f068989"],"layout":"IPY_MODEL_d82f46602a044e43b6a645cb472af406"}},"48740fd0191e43a19591794c3b77444b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f78d904699d4e1896e0fef6fd2e9383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7b87de9e1cc4ac488e49df54e31e2ac","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48740fd0191e43a19591794c3b77444b","value":10}},"53efc12449474f03b5567e25c35f919a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd65aa8df4c946b79f2251f18679cd87","placeholder":"​","style":"IPY_MODEL_0671e859162c49ca8242b9052cd5d000","value":" 33/50 [38:29&lt;35:41, 125.96s/it]"}},"57f9789d879d4e0d9e93fe3d86aa3232":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d9e33399d984abfa2a9a69a2b74866c","placeholder":"​","style":"IPY_MODEL_6f14f56e73e5414593cfb36d36a4478c","value":"Best trial: 2. Best value: 0.487614: 100%"}},"614895912a024e7a847870704f068989":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9566055eb6974dbc9618023536cc0cd8","placeholder":"​","style":"IPY_MODEL_2a3c433365874cac81fb0c404b5efa8f","value":" 10/10 [00:02&lt;00:00,  4.21it/s]"}},"6f14f56e73e5414593cfb36d36a4478c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7045de7ab8a54abfa8285dbe89cb3467":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ca44fa2da0c4f76a7a9bb4d218fd3c9","placeholder":"​","style":"IPY_MODEL_f5649942660d4ffebc77ee7fe087a3f5","value":"Best trial: 18. Best value: 9.92365:  66%"}},"7d9e33399d984abfa2a9a69a2b74866c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9566055eb6974dbc9618023536cc0cd8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ca44fa2da0c4f76a7a9bb4d218fd3c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8be720392364da2aa0bf43bb9e76148":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba20a2745bd24c9e9f5b5a7b5bbed3b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f50d677c1fb4e2089428474a4496ba6","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24a41c93313a430da57493aa5cc9fb9b","value":33}},"c7b87de9e1cc4ac488e49df54e31e2ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d82f46602a044e43b6a645cb472af406":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2f796d94bac41d4964f0375270096a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7045de7ab8a54abfa8285dbe89cb3467","IPY_MODEL_ba20a2745bd24c9e9f5b5a7b5bbed3b5","IPY_MODEL_53efc12449474f03b5567e25c35f919a"],"layout":"IPY_MODEL_b8be720392364da2aa0bf43bb9e76148"}},"f5649942660d4ffebc77ee7fe087a3f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd65aa8df4c946b79f2251f18679cd87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>